{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830b6570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:43:58.591399Z",
     "start_time": "2022-03-04T12:43:56.407764Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import regex\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests\n",
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cab5c",
   "metadata": {},
   "source": [
    "# Project Aims and Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728208c",
   "metadata": {},
   "source": [
    "The primary aim of this project is to generate a predictive model for used car prices based on the predictors which are gathered on AutoTrader. The final model should be interpretable.\n",
    "\n",
    "\n",
    "Based on a small amount of domain knowledge, the secondary hypothesis is that of the car makes studied within this project, a Dacia car owns the smallest brand-price-factor, while a Volvo car own the largest brand-price-factor. This hypothesis will be evaluated on used cars only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e8b8b",
   "metadata": {},
   "source": [
    "# Web Scrape - AutoTrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07f6cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:43:58.633871Z",
     "start_time": "2022-03-04T12:43:58.593784Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Sample Autotrader used car scraping function, not to be run here! \n",
    "\n",
    "def get_used_cars(\n",
    "    postcode=\"KT12 2HG\",\n",
    "    radius=1500,\n",
    "    min_year=1995,\n",
    "    max_year=1995,\n",
    "    include_writeoff=\"include\",\n",
    "    max_attempts_per_page=5,\n",
    "    verbose=False):\n",
    "\n",
    "    # To bypass Cloudflare protection\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "\n",
    "    # Basic variables\n",
    "    results = []\n",
    "    n_this_year_results = 0\n",
    "    # If a search returns > 1000 results then only the first 1000 are made available.\n",
    "    # These such searches are recorded in the extra_make_list for later attention \n",
    "    extra_make_list = []\n",
    "    url = \"https://www.autotrader.co.uk/results-car-search\"\n",
    "\n",
    "    # Keywords commonly used on Autotrader in each of the fields being scraped\n",
    "    keywords = {}\n",
    "    keywords[\"mileage\"] = [\"miles\"]\n",
    "    keywords[\"BHP\"] = [\"BHP\",\"PS\"]\n",
    "    keywords[\"transmission\"] = [\"Automatic\", \"Manual\"]\n",
    "    keywords[\"fuel\"] = [\"Petrol\", \"Diesel\", \"Electric\", \"Hybrid – Diesel/Electric Plug-in\", \n",
    "                        \"Hybrid – Petrol/Electric\", \"Hybrid – Petrol/Electric Plug-in\", \"Bi Fuel\",\n",
    "                        \"Diesel Hybrid\",\"Diesel Plug-in Hybrid\",\"Hydrogen\",\"Natural Gas\",\"Petrol Hybrid\"\n",
    "                        \"Petrol Plug-in Hybrid\"]\n",
    "    keywords[\"owners\"] = [\"owners\", \"owner\",\"own\"]\n",
    "    keywords[\"body\"] = [\"Coupe\", \"Convertible\", \"Estate\", \"Hatchback\", \"MPV\", \"Pickup\", \"SUV\", \"Saloon\"]\n",
    "    keywords[\"ULEZ\"] = [\"ULEZ\"]\n",
    "    keywords[\"year\"] = [\" reg)\",\"new\"]\n",
    "    keywords[\"engine\"] = [\"engine\"]\n",
    "\n",
    "    # Set up parameters for query to autotrader.co.uk\n",
    "    mpgall = ['OVER_60','OVER_50','OVER_40','OVER_30']\n",
    "    drivetrainall = ['Four Wheel Drive','Front Wheel Drive','Rear Wheel Drive']\n",
    "    makeall = ['AC','Abarth','Aixam','Alfa Romeo','Alpine','Ariel','Aston Martin','Audi','Austin',\n",
    "        'BAC','BMW','Beauford','Bentley','Bowler','Bugatti','Buick',\n",
    "        'CUPRA','Cadillac','Carbodies','Caterham','Chesil','Chevrolet','Chrysler','Citroen','Corvette',\n",
    "        'DAF','DFSK','DS Automobiles','Dacia','Daewoo','Daihatsu','Daimler','Datsun','Delorean','Dodge',\n",
    "        'Ferrari','Fiat','Ford','GMC','Great Wall',\n",
    "        'Hillman','Honda','Hummer','Hyundai','Infiniti','Isuzu','Iveco','Jaguar','Jeep','Jensen','KIA',\n",
    "        'LEVC','Lada','Lamborghini','Lancia','Land Rover','Lexus','Lincoln','London Taxis International','Lotus',\n",
    "        'MG','MINI','Mahindra','Maserati','Maybach','Mazda','McLaren','Mercedes-Benz','Microcar','Mitsubishi',\n",
    "        'Mitsuoka','Morgan','Morris','Nissan','Noble','Opel','Packard','Perodua','Peugeot','Pilgrim','Polestar',\n",
    "        'Pontiac','Porsche','Proton','REO','Radical','Rage','Raptor','Reliant','Renault','Replica','Reva','Riley',\n",
    "        'Rolls-Royce','Rover','SEAT','SKODA','Saab','Sebring','Singer','Smart','Spyker','Ssangyong','Subaru',\n",
    "        'Sunbeam','Suzuki','TVR','Tesla','Tiger','Toyota','Triumph','Ultima','Vauxhall','Venturi','Volkswagen',\n",
    "        'Volvo','Westfield','Wolseley','Yamaha','Zenos']\n",
    "    body = [\"Coupe\", \"Convertible\", \"Estate\", \"Hatchback\", \"MPV\", \"Pickup\", \"SUV\", \"Saloon\"]\n",
    "    trans = [\"Automatic\", \"Manual\"]\n",
    "    sort = [\"price-asc\",\"price-desc\"]\n",
    "    \n",
    "    # Iterate over combinations of the search key words. We make such specific searches in an aim\n",
    "    # to return <1000 results per search\n",
    "    for divide in tqdm(list(itertools.product(mpgall, drivetrainall, submake, body, trans, sort))):  \n",
    "        params = {\n",
    "            \"sort\": divide[5],\n",
    "            \"postcode\": postcode,\n",
    "            \"radius\": radius,\n",
    "            \"make\": divide[2],\n",
    "            \"search-results-price-type\": \"total-price\",\n",
    "            \"search-results-year\": \"select-year\",\n",
    "            \"exclude-writeoff-categories\":\"on\",\n",
    "            \"fuel-consumption\":divide[0],\n",
    "            \"drivetrain\":divide[1],\n",
    "            \"body-type\":divide[3],\n",
    "            \"transmission\":divide[4]\n",
    "             }    \n",
    "    \n",
    "        # Set up writeoff parameters for query. Included by default args. \n",
    "        if (include_writeoff == \"include\"):\n",
    "            params[\"writeoff-categories\"] = \"on\"\n",
    "        elif (include_writeoff == \"exclude\"):\n",
    "            params[\"exclude-writeoff-categories\"] = \"on\"\n",
    "        elif (include_writeoff == \"writeoff-only\"):\n",
    "            params[\"only-writeoff-categories\"] = \"on\"\n",
    "\n",
    "        # Set up year parameters for query. Start at year_min and grow to year_max  \n",
    "        year = min_year\n",
    "        page = 1\n",
    "        attempt = 1\n",
    "\n",
    "        try:\n",
    "            while year <= max_year:\n",
    "                params[\"year-from\"] = year\n",
    "                params[\"year-to\"] = year\n",
    "                params[\"page\"] = page\n",
    "\n",
    "                #Sleep timer was not required with VPN cloudscraper combination.\n",
    "                #time.sleep(random.randint(1,9))\n",
    "                r = scraper.get(url, params=params)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"Year:     \", year,\"\\t Page:     \", page,\"\\t Response: \", r)\n",
    "\n",
    "                try:\n",
    "                    if r.status_code != 200: # if not successful (e.g. due to bot protection), log as an attempt\n",
    "                        attempt = attempt + 1\n",
    "                        if attempt <= max_attempts_per_page: # break if max_attempts reached\n",
    "                            if verbose:\n",
    "                                print(\"Exception. Starting attempt #\", attempt, \"and keeping at page #\", page)\n",
    "                        if r.status_code == 500: # break if internal website error\n",
    "                            break\n",
    "                        else:\n",
    "                            page = page + 1\n",
    "                            attempt = 1\n",
    "                            if verbose:\n",
    "                                print(\"Exception. All attempts exhausted for this page. Skipping to next page #\", page)\n",
    "                            if page > 100: # Autotrader does not return sensible results beyond 100 pages\n",
    "                                break\n",
    "                    else:\n",
    "\n",
    "                        j = r.json()\n",
    "                        s = BeautifulSoup(j[\"html\"], features=\"html.parser\")\n",
    "\n",
    "                        # Use beautifulsoup to generate list of cars on each page - called articles \n",
    "                        articles = s.find_all(\"article\", attrs={\"data-standout-type\":\"\"})\n",
    "\n",
    "                        # if no results or reached end of results, report this then increment for next search\n",
    "                        if len(articles) == 0 or r.url[r.url.find(\"page=\")+5:] != str(page):\n",
    "                            if verbose:\n",
    "                                print(\"Found total\", n_this_year_results, \"results for year\", year, \"and brand\", divide, \"across\", page-1, \"pages\")\n",
    "                                # If search returnd > 1000 cars, add car band to the list.\n",
    "                                if n_this_year_results == 1000:\n",
    "                                    extra_make_list.append(params[\"make\"])\n",
    "                                if year+1 <= max_year:\n",
    "                                    print(\"Moving on to year\", year + 1)\n",
    "                                    print(\"---------------------------------\")\n",
    "\n",
    "                            # Increment year and reset relevant variables\n",
    "                            year = year + 1\n",
    "                            page = 1\n",
    "                            attempt = 1\n",
    "                            n_this_year_results = 0\n",
    "                        else:\n",
    "                            # For each car, build a dictionary. Some from seach parameters, some from produced article\n",
    "                            for article in articles:\n",
    "                                car = {}\n",
    "                                seller_href=[]\n",
    "                                car[\"name\"] = article.find(\"h3\", {\"class\": \"product-card-details__title\"}).text.strip()\n",
    "                                car[\"name_subtitle\"] = article.find(\"h3\", {\"class\": \"product-card-details__title\"}).findNext('p').text.strip()                       \n",
    "                                car[\"link\"] = \"https://www.autotrader.co.uk\" + article.find(\"a\", {\"class\": \"tracking-standard-link\"})[\"href\"][: article.find(\"a\", {\"class\": \"tracking-standard-link\"})[\"href\"].find(\"?\")]\n",
    "                                car[\"price\"] = article.find(\"div\", {\"class\": \"product-card-pricing__price\"}).text.strip()\n",
    "                                car[\"mpg\"] = divide[0]\n",
    "                                car[\"drivertrain\"] = divide[1]\n",
    "                                car[\"make\"] = divide[2]\n",
    "                                seller = article.find_all(\"span\", {\"class\": \"product-card-seller-info__spec-item-copy\"})#.text.strip()\n",
    "                                seller=reversed(seller)\n",
    "                                for count,sel in enumerate(seller):\n",
    "                                    car[\"seller\"+str(count)] = sel.text.strip()\n",
    "                                for a in article.find_all(\"a\", {\"class\": \"product-card-seller-info__review-count dealer-profile-link\", \"href\":True}):\n",
    "                                    seller_href.append(a[\"href\"])\n",
    "                                for count,ref in enumerate(seller_href):\n",
    "                                    car[\"href\"+str(count)] = ref\n",
    "\n",
    "                                # The key specs are in a bulleted list\n",
    "                                key_specs_bs_list = article.find(\"ul\", {\"class\": \"listing-key-specs\"}).find_all(\"li\")\n",
    "\n",
    "                                for key_spec_bs_li in key_specs_bs_list:\n",
    "\n",
    "                                    key_spec_bs = key_spec_bs_li.text                              \n",
    "\n",
    "                                    if any(keyword in key_spec_bs for keyword in keywords[\"mileage\"]):\n",
    "                                        car[\"mileage\"] = int(key_spec_bs[:key_spec_bs.find(\" miles\")].replace(\",\",\"\"))\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"BHP\"]):\n",
    "                                        car[\"BHP\"] = key_spec_bs\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"transmission\"]):\n",
    "                                        car[\"transmission\"] = key_spec_bs\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"fuel\"]):\n",
    "                                        car[\"fuel\"] = key_spec_bs\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"owners\"]):\n",
    "                                        car[\"owners\"] = int(key_spec_bs[:key_spec_bs.find(\" own\")])\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"body\"]):\n",
    "                                        car[\"body\"] = key_spec_bs\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"ULEZ\"]):\n",
    "                                        car[\"ULEZ\"] = key_spec_bs\n",
    "                                    elif any(keyword in key_spec_bs for keyword in keywords[\"year\"]):\n",
    "                                        car[\"year\"] = key_spec_bs\n",
    "                                    elif key_spec_bs[1] == \".\" and key_spec_bs[3] == \"L\":\n",
    "                                        car[\"engine\"] = key_spec_bs\n",
    "                                \n",
    "                                # Set any missing dictionary keys to NA for complete car details.\n",
    "                                for key in keywords.keys():\n",
    "                                    if key in car.keys():\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        car[key]='NA'\n",
    "                                # Add complete car dictionary to results list.\n",
    "                                results.append(car)\n",
    "                                n_this_year_results = n_this_year_results + 1\n",
    "\n",
    "                            page = page + 1\n",
    "                            attempt = 1\n",
    "\n",
    "                            if verbose:\n",
    "                                print(\"Car count: \", len(results))\n",
    "                                print(\"---------------------------------\")\n",
    "\n",
    "                except KeyboardInterrupt:\n",
    "                    break\n",
    "\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    attempt = attempt + 1\n",
    "                    if attempt <= max_attempts_per_page:\n",
    "                        if verbose:\n",
    "                            print(\"Exception. Starting attempt #\", attempt, \"and keeping at page #\", page)\n",
    "                    else:\n",
    "                        page = page + 1\n",
    "                        attempt = 1\n",
    "                        if verbose:\n",
    "                            print(\"Exception. All attempts exhausted for this page. Skipping to next page #\", page)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "    \n",
    "    # Make df of results and output to csv\n",
    "    results = pd.DataFrame(results)\n",
    "    now = (datetime.datetime.now().strftime(\"%d%B_%I%M%p\"))\n",
    "    filepathdf=f'/Users/robertdavies/Desktop/DSI/GA_P2/DSI21-lessons/projects/project-capstone/df_detailed/{now}_{min_year}-{max_year}_used.csv'\n",
    "    results.to_csv(filepathdf, index=False, header=results.columns )\n",
    "\n",
    "    return results, list(set(extra_make_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ae169",
   "metadata": {},
   "source": [
    "# Import and clean cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef393a5c",
   "metadata": {},
   "source": [
    "## Used cars - not electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49f0c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:44:11.313508Z",
     "start_time": "2022-03-04T12:44:02.363713Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374854, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all detailed files and make cars df, including year \n",
    "\n",
    "path = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/raw/df_detailed'\n",
    "\n",
    "li=[]\n",
    "for year in range(1990,2022):\n",
    "    year_files = glob.glob(path + f\"/*{year}*used.csv\")\n",
    "    #print(len(year_files),'file(s) to load from', year)\n",
    "    for filename in year_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0 )\n",
    "        df['YR'] = year\n",
    "        df.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "        li.append(df)\n",
    "\n",
    "ucars = pd.concat(li, axis=0, ignore_index=True)\n",
    "ucars.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f7ca2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:45:52.738919Z",
     "start_time": "2022-03-04T12:44:11.316288Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374854, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean cars.body \n",
    "\n",
    "#Create df of cars will null body\n",
    "nabody = ucars[ucars['body'].isnull()].copy()\n",
    "\n",
    "#Encode body column but don't overwrite\n",
    "to_encode = ['body']\n",
    "cars_e = ucars.copy()\n",
    "for col in to_encode:\n",
    "    le = LabelEncoder()\n",
    "    cars_e[col] = le.fit_transform(cars_e[col]) \n",
    "\n",
    "#Iterate through null-body cars and replace with corresponding modal body value based on name column grouping\n",
    "for index, car in nabody.iterrows():\n",
    "    carname=nabody.loc[index,'name']\n",
    "    body=nabody.loc[index,'body']\n",
    "    nabody.loc[index,'body'] = cars_e[cars_e['name']==carname].body.mode()[0]\n",
    "    cars_e.loc[index,'body'] = cars_e[cars_e['name']==carname].body.mode()[0]     \n",
    "\n",
    "#Reverse the encoding    \n",
    "for col in to_encode:\n",
    "    ucars[col] = le.inverse_transform(cars_e[col]) \n",
    "\n",
    "#After checking the remaining cars without a body, it is clear that they are all vans!    \n",
    "ucars.body = ['Van' if pd.Series(x).isnull()[0]==True else x for x in ucars.body]        \n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb7fbd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:45:54.047172Z",
     "start_time": "2022-03-04T12:45:52.741725Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374590, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean cars.BHP, taking values from cars.engine where necessary. Drop remaining NaN. \n",
    "\n",
    "# Unmerge some of the BHP entries which have engine size in there too.\n",
    "for index, car in ucars[ucars['BHP'].str.contains('L', regex=True, na=False)].iterrows():\n",
    "    ucars.loc[index, 'engine'] = str(ucars.loc[index, 'BHP']).split(' ')[0]\n",
    "    ucars.loc[index, 'BHP'] = str(ucars.loc[index, 'BHP']).split(' ')[1].strip('()') \n",
    "\n",
    "# Drop NaN BHP\n",
    "ucars.dropna(subset=['BHP'],inplace=True)\n",
    "\n",
    "def standardise_bhp(x):\n",
    "    lenbhp = len(str(x).split(' '))\n",
    "    bhp=x\n",
    "    if lenbhp == 1:\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])       \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014        \n",
    "    elif lenbhp == 2:\n",
    "        x=str(x.split(' ')[-1])\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])      \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014\n",
    "    else:\n",
    "        bhp=np.nan   \n",
    "    return bhp    \n",
    "\n",
    "#Standardise remaining BHP (convert from PS)\n",
    "ucars.BHP = ucars.BHP.apply(lambda x: standardise_bhp(x))\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd1bd36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:52:04.572000Z",
     "start_time": "2022-03-04T12:51:39.389347Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/l422441d07d4l2q1nfyrjk740000gn/T/ipykernel_23688/3069121021.py:10: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  ucars[ucars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller1 = ucars[ucars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller0\n",
      "/var/folders/1h/l422441d07d4l2q1nfyrjk740000gn/T/ipykernel_23688/3069121021.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ucars[ucars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller1 = ucars[ucars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(374590, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the best location variable. Retain dealer_city and dealer_area. Don't drop remaining NaN. \n",
    "\n",
    "#split href0 into city and area\n",
    "ucars['dealer_city_temp'] = [x.split('/')[3] if type(x)==str and len(x.split('/'))>3 else x for x in ucars.href0]\n",
    "ucars['dealer_area'] = [x.split('/')[2] if type(x)==str and len(x.split('/'))>3 else x for x in ucars.href0]\n",
    "\n",
    "#If there are some seller ratings in seller0, move them to seller1\n",
    "#This piece of code causes warnings but after all this I don't use the\n",
    "#Seller rating anyway as it was not populated enough.\n",
    "ucars[ucars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller1 = ucars[ucars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller0\n",
    "\n",
    "#Make seller ratings in seller0 np.nan\n",
    "ucars.seller0 =[np.nan if '4' in str(x) or '5' in str(x) else x for x in ucars.seller0]\n",
    "\n",
    "# #If the seller0 column is np.nan, use the dealer_city \n",
    "for index, car in ucars.iterrows():\n",
    "    if pd.isnull(ucars.loc[index,'seller0']):\n",
    "        ucars.loc[index,'seller0']=ucars.loc[index,'dealer_city_temp']\n",
    "        \n",
    "ucars['dealer_city'] = ucars['seller0']\n",
    "ucars.drop(['seller0','dealer_city_temp'],inplace=True, axis=1)\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340e413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:21:21.082366Z",
     "start_time": "2022-03-03T21:21:04.602766Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Iterate over missing engine rows and use RegEx on name_subtitle to extract engine size where possible. \n",
    "\n",
    "for index, car in ucars[ucars['engine'].isnull()].iterrows():\n",
    "    car_subname = ucars.loc[index, 'name_subtitle']\n",
    "    try:\n",
    "        enginesize = re.findall('([0-9][.][0-9]+)',car_subname)[0]\n",
    "    except: \n",
    "        enginesize = np.nan\n",
    "    ucars.loc[index,'engine'] = float(enginesize)\n",
    "\n",
    "# Remove L from each engine size.\n",
    "ucars.engine= ucars.engine.apply(lambda x: float(str(x).replace('L','')))\n",
    "\n",
    "# Drop remaining 105 used cars without engine size.\n",
    "ucars.dropna(subset=['engine'],inplace=True)\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a63b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:18.457137Z",
     "start_time": "2022-03-03T21:21:21.084948Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Make cars.doors \n",
    "\n",
    "def extract_drs(x):\n",
    "    drs = re.findall('( [1-8]d[Rr]?)',x, re.I)\n",
    "    if len(drs) > 0:\n",
    "        drs = str(drs[0]).lower()\n",
    "    else:\n",
    "        drs = re.findall('([1-8][ ]?door)',x, re.I)\n",
    "        if len(drs) > 0:\n",
    "            drs = str(drs[0])[0]+'dr'\n",
    "        else:\n",
    "            drs = re.findall('([1-8]dr)',x, re.I)\n",
    "            if len(drs) > 0:\n",
    "                drs = str(drs[0])[0]+'dr'\n",
    "            else:\n",
    "                drs = re.findall('(D-4D)',x, re.I)\n",
    "                if len(drs) > 0:\n",
    "                    drs = '4dr'\n",
    "                else:\n",
    "                    drs='0dr'\n",
    "                \n",
    "    if ('r' or 'R') not in drs:\n",
    "        drs = drs.replace('d','dr')\n",
    "    return drs.strip()\n",
    "     \n",
    "ucars['doors'] = ucars.name_subtitle.apply(lambda x: extract_drs(x))\n",
    "\n",
    "#Create df of cars with 0 doors\n",
    "zerodoors = ucars[ucars['doors']=='0dr'].copy()\n",
    "\n",
    "#Encode doors column but don't overwrite\n",
    "to_encode = ['doors']\n",
    "cars_e = ucars.copy()\n",
    "for col in to_encode:\n",
    "    le = LabelEncoder()\n",
    "    cars_e[col] = le.fit_transform(cars_e[col]) \n",
    "\n",
    "#Iterate through zero door cars and replace with corresponding num doors based on name column grouping\n",
    "for index, car in zerodoors.iterrows():\n",
    "    carname=zerodoors.loc[index,'name']\n",
    "    cars_e.loc[index,'doors'] = cars_e[cars_e['name']==carname].doors.mode()[0]     \n",
    "\n",
    "#Reverse the encoding    \n",
    "for col in to_encode:\n",
    "    ucars[col] = le.inverse_transform(cars_e[col]) \n",
    "\n",
    "#Drop the remaining 226 cars without door information    \n",
    "ucars=ucars[ucars.doors!='0dr'].copy()\n",
    "ucars.dropna(subset=['doors'],inplace=True)\n",
    "    \n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c34a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:18.552017Z",
     "start_time": "2022-03-03T21:22:18.459592Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean cars.mileage \n",
    "\n",
    "#Drop them - only 283\n",
    "ucars.dropna(subset=['mileage'],inplace=True)\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a623f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:18.674161Z",
     "start_time": "2022-03-03T21:22:18.560126Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean cars.fuel \n",
    "\n",
    "#Drop them - only 12\n",
    "ucars.dropna(subset=['fuel'],inplace=True)\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96352500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:19.603103Z",
     "start_time": "2022-03-03T21:22:18.678313Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clean cars.price, make cars.ID, clean cars.year \n",
    "\n",
    "to_dummy=['mpg','drivetrain','make','body','transmission','fuel']\n",
    "\n",
    "ucars.price=ucars.price.apply(lambda x: x.replace('£',''))\n",
    "ucars.price=ucars.price.apply(lambda x: float(x.replace(',','')))\n",
    "ucars['id'] =[x.split('/')[-1] for x in ucars.link]\n",
    "ucars['year_reg']=ucars.year\n",
    "ucars['year']=ucars.YR\n",
    "ucars.drop('YR',inplace=True, axis=1)\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc504bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:21.797735Z",
     "start_time": "2022-03-03T21:22:19.605331Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Have a nosey at the price and mileage distribution\n",
    "\n",
    "ucars['log_price']=ucars.price.apply(lambda x: np.log(x))\n",
    "ucars['log_mileage']=ucars.mileage.apply(lambda x: np.log(x))\n",
    "\n",
    "#mask = np.abs((ucars.price - ucars.price.mean(0)) / ucars.price.std(0)) > 3\n",
    "#ucars= ucars[~mask]\n",
    "#ucars.price.plot(kind='hist', bins=50, title='Car Price after outlier removal', xlabel='£');\n",
    "\n",
    "#mask = np.abs((ucars.mileage - ucars.mileage.mean(0)) / ucars.mileage.std(0)) > 3\n",
    "#ucars= ucars[~mask]\n",
    "#ucars.mileage.plot(kind='hist', bins=50, title='Car Mileage');\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,8))\n",
    "ax[0,0].hist(ucars.price, bins=60)\n",
    "ax[0,1].hist(ucars.log_price, bins=60)\n",
    "ax[1,0].hist(ucars.mileage, bins=60)\n",
    "ax[1,1].hist(ucars.log_mileage, bins=60)\n",
    "ax[0,0].set_xlabel('£')\n",
    "ax[0,1].set_xlabel('£')\n",
    "ax[1,0].set_xlabel('Miles')\n",
    "ax[1,1].set_xlabel('Miles')\n",
    "ax[0,0].set_title('Price')\n",
    "ax[0,1].set_title('Log price')\n",
    "ax[1,0].set_title('Mileage')\n",
    "ax[1,1].set_title('Log-mileage')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eac958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:57.132792Z",
     "start_time": "2022-03-03T21:22:21.800779Z"
    },
    "code_folding": [
     5,
     7
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simplify the cars.name column. Probably not perfect \n",
    "\n",
    "ucars['orig_name'] = ucars.name\n",
    "ucars['lname']=ucars.name.apply(lambda x: x.lower())\n",
    "\n",
    "body =[\"coupe\", \"convertible\", \"estate\", \"hatchback\", \"MPV\", \"pickup\", \n",
    "       \"SUV\", \"saloon\",\"cabriolet\",\"sedan\"]\n",
    "name_list_from_carsized = ['abarth 500', 'acura nsx', 'alfa-romeo 147', 'alfa-romeo 156',\n",
    "       'alfa-romeo 159', 'alfa-romeo 164', 'alfa-romeo 4c',\n",
    "       'alfa-romeo giulia', 'alfa-romeo giulietta', 'alfa-romeo mito',\n",
    "       'alfa-romeo sprint', 'alfa-romeo stelvio', 'alvis tc 108',\n",
    "       'aston-martin db11', 'aston-martin dbx', 'aston-martin rapide',\n",
    "       'aston-martin vantage', 'audi 100', 'audi a1', 'audi a2',\n",
    "       'audi a3', 'audi a4', 'audi a5', 'audi a6', 'audi a7', 'audi a8',\n",
    "       'audi e tron', 'audi e tron gt', 'audi q2', 'audi q3',\n",
    "       'audi q4 e tron', 'audi q5', 'audi q7', 'audi q8', 'audi r8',\n",
    "       'audi tt', 'austin 7', 'austin healey 3000', 'bentley 3 5 litre',\n",
    "       'bentley bentayga', 'bentley continental flying spur',\n",
    "       'bentley continental gt', 'bentley flying spur', 'bmw 1 series', 'bmw 2 series',\n",
    "       'bmw 3 series', 'bmw 4 series', 'bmw 5 series', 'bmw 6 series', 'bmw 7 series', 'bmw 8 series',\n",
    "       'bmw i3', 'bmw i8', 'bmw isetta', 'bmw ix', 'bmw x1', 'bmw x2',\n",
    "       'bmw x3', 'bmw x4', 'bmw x5', 'bmw x6', 'bmw x7', 'bmw z4',\n",
    "       'buick skylark', 'cadillac ats', 'cadillac bls', 'cadillac cts',\n",
    "       'cadillac eldorado', 'cadillac escalade', 'cadillac seville',\n",
    "       'cadillac srx', 'cadillac xt5', 'chevrolet aveo',\n",
    "       'chevrolet bel air', 'chevrolet camaro', 'chevrolet caprice',\n",
    "       'chevrolet captiva', 'chevrolet corvette', 'chevrolet cruze',\n",
    "       'chevrolet epica', 'chevrolet equinox', 'chevrolet impala',\n",
    "       'chevrolet malibu', 'chevrolet matiz', 'chevrolet spark',\n",
    "       'chevrolet tahoe', 'chrysler 300', 'chrysler pt cruiser',\n",
    "       'chrysler sebring', 'chrysler voyager', 'citroen b14',\n",
    "       'citroen berlingo', 'citroen c crosser', 'citroen c elysee',\n",
    "       'citroen c1', 'citroen c3', 'citroen c3 aircross', 'citroen c4',\n",
    "       'citroen c4 cactus', 'citroen c4 picasso', 'citroen c5',\n",
    "       'citroen c5 aircross', 'citroen c8', 'citroen ds', 'citroen ds5',\n",
    "       'citroen jumpy', 'citroen space tourer', 'cupra ateca',\n",
    "       'cupra born', 'cupra formentor', 'cupra leon', 'dacia dokker',\n",
    "       'dacia duster', 'dacia lodgy', 'dacia logan', 'dacia sandero',\n",
    "       'daewoo lacetti', 'daihatsu sirion', 'daihatsu terios',\n",
    "       'daimler 250 v8', 'daimler six', 'dodge 880', 'dodge caliber',\n",
    "       'dodge challenger', 'dodge charger', 'dodge durango',\n",
    "       'dodge journey', 'dodge nitro', 'dodge ram', 'dodge viper', 'ds 3',\n",
    "       'ds 3 crossback', 'ds 4', 'ds 7 crossback', 'excalibur series ii',\n",
    "       'ferrari 458', 'ferrari 488', 'ferrari 512', 'ferrari california',\n",
    "       'ferrari california t', 'ferrari ff', 'ferrari gtc4lusso',\n",
    "       'ferrari sf90', 'ferrari testarossa', 'fiat 1100', 'fiat 500',\n",
    "       'fiat 500l', 'fiat 500x', 'fiat 600', 'fiat bravo', 'fiat croma',\n",
    "       'fiat freemont', 'fiat fullback', 'fiat panda', 'fiat punto',\n",
    "       'fiat qubo', 'fiat tipo', 'fisker karma', 'ford b max','fiat ducato'\n",
    "       'ford c max', 'ford cougar', 'ford ecosport', 'ford edge',\n",
    "       'ford escape', 'ford explorer', 'ford f150',\n",
    "       'ford fairlane 500 skyliner', 'ford fiesta', 'ford focus',\n",
    "       'ford galaxy', 'ford ka', 'ford kuga', 'ford model 48',\n",
    "       'ford model t', 'ford mondeo', 'ford mustang',\n",
    "       'ford mustang mach e', 'ford puma', 'ford ranger', 'ford s max',\n",
    "       'ford scorpio', 'ford taurus', 'ford tourneo',\n",
    "       'ford tourneo connect', 'ford tourneo courier', 'genesis g70',\n",
    "       'genesis g80', 'genesis gv70', 'genesis gv80', 'gmc sierra',\n",
    "       'gmc terrain', 'gmc yukon xl', 'honda accord', 'honda city',\n",
    "       'honda civic', 'honda cr v', 'honda e', 'honda hr v',\n",
    "       'honda jazz fit', 'honda nsx', 'honda odyssey', 'honda s',\n",
    "       'hummer h2', 'hyundai getz', 'hyundai i10', 'hyundai i20',\n",
    "       'hyundai i30', 'hyundai i40', 'hyundai ioniq', 'hyundai ioniq 5',\n",
    "       'hyundai ix20', 'hyundai kona', 'hyundai nexo', 'hyundai santa fe',\n",
    "       'hyundai tiburon', 'hyundai tucson', 'hyundai veloster',\n",
    "       'infinity fx', 'infinity q30', 'infiniti q50 sedan',\n",
    "       'infinity qx80', 'isuzu d max', 'jac refine e s2', 'jaguar e pace',\n",
    "       'jaguar e type', 'jaguar f pace', 'jaguar f type', 'jaguar i pace',\n",
    "       'jaguar x type', 'jaguar xe', 'jaguar xf', 'jaguar xj',\n",
    "       'jaguar xk', 'jaguar xk120', 'jeep cherokee', 'jeep compass',\n",
    "       'jeep wrangler', 'jeep grand cherokee', 'jeep renegade',\n",
    "       'kia carens', 'kia ceed', 'kia ev6', 'kia magentis', 'kia niro',\n",
    "       'kia picanto', 'kia rio', 'kia sorento', 'kia soul',\n",
    "       'kia sportage', 'kia stinger', 'kia stonic', 'kia venga',\n",
    "       'lada 2102', 'lada 4x4', 'lamborghini aventador',\n",
    "       'lamborghini huracan', 'lamborghini urus', 'lancia delta',\n",
    "       'lancia phedra', 'lancia ypsilon', 'land rover defender',\n",
    "       'land rover discovery', 'land rover discovery sport',\n",
    "       'land rover freelander', 'land rover range rover',\n",
    "       'land rover range rover evoque', 'land rover range rover sport',\n",
    "       'land rover range rover velar', 'lexus ct', 'lexus gs', 'lexus is',\n",
    "       'lexus ls', 'lexus lx', 'lexus nx', 'lexus rx', 'lexus sc',\n",
    "       'lexus ux', 'lincoln mkx', 'lincoln navigator', 'lincoln town car',\n",
    "       'lotus elan', 'lotus elise', 'maserati ghibli',\n",
    "       'maserati granturismo', 'maserati levante',\n",
    "       'maserati quattroporte', 'maybach 57', 'mazda 2', 'mazda 3',\n",
    "       'mazda 5', 'mazda 6', 'mazda cx 3', 'mazda cx 30', 'mazda cx 5',\n",
    "       'mazda cx 7', 'mazda cx 9', 'mazda mx 30', 'mazda mx 5',\n",
    "       'mclaren 12c', 'mclaren 650s', 'mclaren 720s', 'mercedes-benz 123',\n",
    "       'mercedes-benz 170 s', 'mercedes-benz 220', 'mercedes-benz 220 s',\n",
    "       'mercedes-benz a class', 'mercedes-benz amg gt', 'mercedes-benz b class',\n",
    "       'mercedes-benz c class', 'mercedes-benz citan', 'mercedes-benz cl class',\n",
    "       'mercedes-benz cla class', 'mercedes-benz clk class', 'mercedes-benz cls class',\n",
    "       'mercedes-benz e class', 'mercedes-benz 3', 'mercedes-benz eqa',\n",
    "       'mercedes-benz eqc class', 'mercedes-benz eqs class', 'mercedes-benz g class',\n",
    "       'mercedes-benz gl class', 'mercedes-benz gla class', 'mercedes-benz glb class',\n",
    "       'mercedes-benz glc class', 'mercedes-benz gle class', 'mercedes-benz glk class',\n",
    "       'mercedes-benz gls class', 'mercedes-benz m class', 'mercedes-benz r class',\n",
    "       'mercedes-benz s class', 'mercedes-benz sl', 'mercedes-benz slk',\n",
    "       'mercedes-benz v class', 'mercedes-benz vito', 'mercedes-benz w114',\n",
    "       'mercedes-benz x class', 'mercury cougar', 'mg f', 'mg mgb', 'mg tf',\n",
    "       'mini clubman', 'mini cooper', 'mini countryman', 'mini paceman',\n",
    "       'mitsubishi asx', 'mitsubishi colt', 'mitsubishi i miev',\n",
    "       'mitsubishi l200', 'mitsubishi lancer', 'mitsubishi mirage',\n",
    "       'mitsubishi outlander', 'mitsubishi pajero', 'moskvitch 400',\n",
    "       'nissan 370z', 'nissan altima', 'nissan juke', 'nissan leaf',\n",
    "       'nissan micra', 'nissan murano', 'nissan navara', 'nissan note',\n",
    "       'nissan nv200', 'nissan pathfinder', 'nissan pixo',\n",
    "       'nissan qashqai', 'nissan x trail', 'oldsmobile 88',\n",
    "       'oldsmobile cutlass supreme', 'vauxhall adam', 'vauxhall agila',\n",
    "       'vauxhall ampera', 'vauxhall astra', 'vauxhall calibra', 'vauxhall cascada',\n",
    "       'vauxhall corsa', 'vauxhall crossland x', 'vauxhall grandland',\n",
    "       'vauxhall insignia', 'vauxhall karl', 'vauxhall meriva', 'vauxhall mokka',\n",
    "       'vauxhall tigra', 'vauxhall vectra', 'vauxhall zafira', 'peugeot 1007',\n",
    "       'peugeot 108', 'peugeot 206', 'peugeot 207', 'peugeot 208', 'peugeot 2008'\n",
    "       'peugeot 3008', 'peugeot 306', 'peugeot 307', 'peugeot 308',\n",
    "       'peugeot 4007', 'peugeot 4008', 'peugeot 406', 'peugeot 407',\n",
    "       'peugeot 5008', 'peugeot 508', 'peugeot 807', 'peugeot expert',\n",
    "       'peugeot partner', 'peugeot traveller', 'plymouth volare',\n",
    "       'polestar 2', 'pontiac firebird', 'pontiac gto', 'porsche 356',\n",
    "       'porsche 718', 'porsche 718 cayman', 'porsche 911', 'porsche 928',\n",
    "       'porsche cayenne 5 door coupe suv', 'porsche cayenne',\n",
    "       'porsche macan', 'porsche panamera', 'porsche taycan',\n",
    "       'renault captur', 'renault clio', 'renault espace',\n",
    "       'renault fluence', 'renault fuego', 'renault kadjar',\n",
    "       'renault kangoo', 'renault koleos', 'renault laguna',\n",
    "       'renault megane', 'renault modus', 'renault scenic',\n",
    "       'renault talisman', 'renault twingo', 'renault twizy',\n",
    "       'renault zoe', 'rolls-royce corniche', 'rolls-royce cullinan',\n",
    "       'rolls-royce ghost', 'rolls-royce phantom',\n",
    "       'rolls-royce silver shadow', 'rolls-royce silver spirit',\n",
    "       'rolls-royce wraith', 'rover sd1', 'saab 9 3', 'saab 9 5',\n",
    "       'seat alhambra', 'seat altea', 'seat arona', 'seat ateca',\n",
    "       'seat exeo', 'seat ibiza', 'seat leon', 'seat mii', 'seat tarraco',\n",
    "       'skoda citigo', 'skoda enyaq iv', 'skoda fabia', 'skoda kamiq',\n",
    "       'skoda karoq', 'skoda kodiaq', 'skoda octavia', 'skoda rapid',\n",
    "       'skoda scala', 'skoda superb', 'skoda yeti', 'smart forfour',\n",
    "       'smart fortwo', 'smart roadster', 'ssang yong korando',\n",
    "       'ssang yong kyron', 'ssang yong rexton', 'ssang yong tivoli',\n",
    "       'subaru forester', 'subaru impreza', 'subaru justy',\n",
    "       'subaru legacy', 'subaru levorg', 'subaru outback',\n",
    "       'subaru xv crosstrek', 'suzuki across', 'suzuki ignis',\n",
    "       'suzuki jimny', 'suzuki liana', 'suzuki swift', 'suzuki sx4',\n",
    "       'suzuki vitara', 'tatra 603', 'tesla model 3', 'tesla model s',\n",
    "       'tesla model x', 'tesla model y', 'toyota auris', 'toyota avensis',\n",
    "       'toyota aygo', 'toyota c hr', 'toyota celica', 'toyota corolla',\n",
    "       'toyota corolla verso', 'toyota gt 86', 'toyota highlander',\n",
    "       'toyota hilux', 'toyota iq', 'toyota land cruiser prado',\n",
    "       'toyota landcruiser', 'toyota previa', 'toyota prius',\n",
    "       'toyota prius plus', 'toyota proace verso', 'toyota rav4',\n",
    "       'toyota sienna', 'toyota supra', 'toyota tundra',\n",
    "       'toyota urban cruiser', 'toyota verso', 'toyota yaris',\n",
    "       'toyota yaris cross', 'triumph spitfire', 'triumph tr7',\n",
    "       'tvr cerbera', 'volkswagen 1600', 'volkswagen amarok',\n",
    "       'volkswagen arteon', 'volkswagen beetle', 'volkswagen bora',\n",
    "       'volkswagen caddy', 'volkswagen california',\n",
    "       'volkswagen caravelle', 'volkswagen eos', 'volkswagen fox',\n",
    "       'volkswagen golf', 'volkswagen id3', 'volkswagen id4',\n",
    "       'volkswagen jetta', 'volkswagen passat', 'volkswagen passat cc',\n",
    "       'volkswagen phaeton', 'volkswagen polo', 'volkswagen scirocco',\n",
    "       'volkswagen sharan', 'volkswagen t cross', 'volkswagen t roc',\n",
    "       'volkswagen tiguan', 'volkswagen touareg', 'volkswagen touran',\n",
    "       'volkswagen up', 'volvo 780', 'volvo 900', 'volvo c30',\n",
    "       'volvo s60', 'volvo s80', 'volvo s90', 'volvo v40', 'volvo v50',\n",
    "       'volvo v60', 'volvo v70', 'volvo v90', 'volvo xc40', 'volvo xc60',\n",
    "       'volvo xc70', 'volvo xc90', 'wartburg 353']\n",
    "\n",
    "results = []\n",
    "for index, car in ucars.iterrows():\n",
    "    lname = car[-1]\n",
    "    dummy = lname\n",
    "    for cname in name_list_from_carsized:\n",
    "        if cname in lname:\n",
    "            dummy = cname\n",
    "    for bod in body:\n",
    "        if bod in dummy:\n",
    "            dummy = re.sub(' '+bod,'',dummy)\n",
    "    results.append(dummy)\n",
    "results\n",
    "\n",
    "ucars['name']=results\n",
    "ucars=ucars.drop('lname', axis=1)\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7080e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:57.142256Z",
     "start_time": "2022-03-03T21:22:57.135022Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Add cars.used and cars.e_engine_kWh columns to be compatible with other datasets \n",
    "\n",
    "ucars['used']=1\n",
    "ucars['e_engine_kWh']= np.nan\n",
    "\n",
    "ucars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee8ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:57.414969Z",
     "start_time": "2022-03-03T21:22:57.144145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove SKODA 911 which stands as an aggressive outlier - data entry error\n",
    "\n",
    "ucars[ucars.make=='SKODA'].sort_values(by='price',ascending=False).head(1)\n",
    "dropindex = ucars[ucars.make=='SKODA'].sort_values(by='price',ascending=False).head(1).index.tolist()\n",
    "ucars.drop(index=dropindex, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9d6a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:22:57.641302Z",
     "start_time": "2022-03-03T21:22:57.417396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Mercedes missing a decimal which stands as an aggressive outlier - data entry error\n",
    "\n",
    "ucars[ucars.make=='Mercedes-Benz'].sort_values(by='price',ascending=False).head(1)\n",
    "dropindex = ucars[ucars.make=='Mercedes-Benz'].sort_values(by='price',ascending=False).head(1).index.tolist()\n",
    "ucars.drop(index=dropindex, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70104d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:03.553258Z",
     "start_time": "2022-03-03T21:22:57.643797Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Output clean used cars data \n",
    "ucars=ucars[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','dealer_area','dealer_city','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0']]\n",
    "ucars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_clean_used_cars.csv'\n",
    "ucars.to_csv(ucars_abspath, index=False, header=ucars.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6dd19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:03.853237Z",
     "start_time": "2022-03-03T21:23:03.555432Z"
    }
   },
   "outputs": [],
   "source": [
    "ucars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3b1fe",
   "metadata": {},
   "source": [
    "## Used cars - electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89142ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:04.089240Z",
     "start_time": "2022-03-03T21:23:03.854916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all detailed files and make cars df, including year \n",
    "\n",
    "path = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/raw/df_detailed_ev/'\n",
    "\n",
    "li=[]\n",
    "year_files = glob.glob(path + f\"/*electric_used.csv\")\n",
    "for filename in year_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0 )\n",
    "    df.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "    li.append(df)\n",
    "\n",
    "uecars = pd.concat(li, axis=0, ignore_index=True)\n",
    "uecars.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "uecars.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedc1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:04.096697Z",
     "start_time": "2022-03-03T21:23:04.091380Z"
    }
   },
   "outputs": [],
   "source": [
    "uecars.body.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2918d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:04.104080Z",
     "start_time": "2022-03-03T21:23:04.099126Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Body is fine. No cleaning needed.\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5e9b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:04.133581Z",
     "start_time": "2022-03-03T21:23:04.106031Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean BHP.\n",
    "\n",
    "# Drop NaN BHP\n",
    "uecars.dropna(subset=['BHP'],inplace=True)\n",
    "\n",
    "def standardise_bhp(x):\n",
    "    lenbhp = len(str(x).split(' '))\n",
    "    bhp=x\n",
    "    if lenbhp == 1:\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])       \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014        \n",
    "    elif lenbhp == 2:\n",
    "        x=str(x.split(' ')[-1])\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])      \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014\n",
    "    else:\n",
    "        bhp=np.nan   \n",
    "    return bhp    \n",
    "\n",
    "#Standardise remaining BHP (convert from PS)\n",
    "uecars.BHP = uecars.BHP.apply(lambda x: standardise_bhp(x))\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffdbd93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:04.699152Z",
     "start_time": "2022-03-03T21:23:04.135687Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compile the best location variable. Retain dealer_city and dealer_area. Don't drop remaining NaN.\n",
    "\n",
    "#split href0 into city and area\n",
    "uecars['dealer_city_temp'] = [x.split('/')[3] if type(x)==str and len(x.split('/'))>3 else x for x in uecars.href0]\n",
    "uecars['dealer_area'] = [x.split('/')[2] if type(x)==str and len(x.split('/'))>3 else x for x in uecars.href0]\n",
    "\n",
    "#If there are some seller ratings in seller0, move them to seller1\n",
    "uecars[uecars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller1 = uecars[uecars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller0\n",
    "\n",
    "#Make seller ratings in seller0 np.nan\n",
    "uecars.seller0 =[np.nan if '4' in str(x) or '5' in str(x) else x for x in uecars.seller0]\n",
    "\n",
    "#If the seller0 column is np.nan, use the dealer_city \n",
    "for index, car in uecars.iterrows():\n",
    "    if pd.isnull(uecars.loc[index,'seller0']):\n",
    "        uecars.loc[index,'seller0']=uecars.loc[index,'dealer_city_temp']\n",
    "    #Tiny number of cars don't have a location, and they're all from one dealer in Oldbury.    \n",
    "    if pd.isnull(uecars.loc[index,'seller0']):\n",
    "        uecars.loc[index,'seller0']= 'Oldbury'\n",
    "        \n",
    "uecars['dealer_city'] = uecars['seller0']\n",
    "uecars.drop(['seller0','dealer_city_temp'],inplace=True, axis=1)\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c26d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:06.798941Z",
     "start_time": "2022-03-03T21:23:04.701277Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Populate uecars.e_engine_kWh from name_subtitle ~20% NaN. Not great but BHP supersedes it.\n",
    "\n",
    "uecars['e_engine_kWh']=''\n",
    "uecars['engine']=np.nan\n",
    "\n",
    "for index, car in uecars.iterrows():\n",
    "    car_subname = uecars.loc[index, 'name_subtitle']\n",
    "    try:\n",
    "        eenginesize = re.findall('[\\d]+[.]?[\\d]+[ ]?kwh',car_subname, flags=re.I)[0]\n",
    "    except: \n",
    "        eenginesize = np.nan\n",
    "    uecars.loc[index,'e_engine_kWh'] = eenginesize\n",
    "    \n",
    "uecars.e_engine_kWh= uecars.e_engine_kWh.apply(lambda x: float(str(x).lower().replace('kwh','')))\n",
    "#uecars.dropna(subset=['engine'],inplace=True)\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b66e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:06.833964Z",
     "start_time": "2022-03-03T21:23:06.801332Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make doors column. Drop 53 without info. \n",
    "     \n",
    "uecars['doors'] = uecars.name_subtitle.apply(lambda x: extract_drs(x))\n",
    "\n",
    "# Drop the remaining 53 uecars without door information    \n",
    "uecars.drop(uecars[uecars.doors=='0dr'].index, inplace=True)\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad4d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:06.872829Z",
     "start_time": "2022-03-03T21:23:06.836630Z"
    }
   },
   "outputs": [],
   "source": [
    "uecars.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268752c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:06.907787Z",
     "start_time": "2022-03-03T21:23:06.875936Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean uecars.price, make uecars.ID, clean uecars.year. Fix uecars.ULEZ \n",
    "to_dummy=['mpg','drivetrain','make','body','transmission','fuel']\n",
    "\n",
    "uecars.price=uecars.price.apply(lambda x: x.replace('£',''))\n",
    "uecars.price=uecars.price.apply(lambda x: float(x.replace(',','')))\n",
    "uecars['id'] =[x.split('/')[-1] for x in uecars.link]\n",
    "uecars['year_reg']=uecars['year']\n",
    "uecars['year']=uecars['YR']\n",
    "uecars.drop('YR',inplace=True, axis=1)\n",
    "uecars.owners=int(0)\n",
    "uecars.ULEZ='ULEZ'\n",
    "\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2f945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:06.923789Z",
     "start_time": "2022-03-03T21:23:06.919613Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set uecars.used = 1.\n",
    "\n",
    "uecars['used']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e8645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:07.534918Z",
     "start_time": "2022-03-03T21:23:06.926348Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Have a nosey at the price and mileage distribution\n",
    "\n",
    "uecars.drop(uecars[uecars.mileage.isnull()].index, inplace=True)\n",
    "uecars['log_price']=uecars.price.apply(lambda x: np.log(x))\n",
    "uecars['mileage']=uecars.mileage.apply(lambda x: float(x))\n",
    "uecars['log_mileage']=uecars.mileage.apply(lambda x: np.log(x))\n",
    "\n",
    "#mask = np.abs((ncars.price - ncars.price.mean(0)) / ncars.price.std(0)) > 3\n",
    "#ncars= ncars[~mask]\n",
    "#ncars.price.plot(kind='hist', bins=50, title='Car Price after outlier removal', xlabel='£');\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16,4))\n",
    "ax[0].hist(uecars.price, bins=60)\n",
    "ax[1].hist(uecars.log_price, bins=60)\n",
    "ax[0].set_xlabel('£')\n",
    "ax[1].set_xlabel('£')\n",
    "ax[0].set_title('Price')\n",
    "ax[1].set_title('Log price')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362aad5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:08.066284Z",
     "start_time": "2022-03-03T21:23:07.537129Z"
    },
    "code_folding": [
     0,
     5
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simplify the name column a little. Probably not perfect \n",
    "\n",
    "uecars['orig_name'] = uecars.name\n",
    "uecars['lname']=uecars.name.apply(lambda x: x.lower())\n",
    "\n",
    "body =[\"coupe\", \"convertible\", \"estate\", \"hatchback\", \"MPV\", \"pickup\", \n",
    "        \"SUV\", \"saloon\",\"cabriolet\",\"sedan\"]\n",
    "name_list_from_carsized = ['abarth 500', 'acura nsx', 'alfa-romeo 147', 'alfa-romeo 156',\n",
    "       'alfa-romeo 159', 'alfa-romeo 164', 'alfa-romeo 4c',\n",
    "       'alfa-romeo giulia', 'alfa-romeo giulietta', 'alfa-romeo mito',\n",
    "       'alfa-romeo sprint', 'alfa-romeo stelvio', 'alvis tc 108',\n",
    "       'aston-martin db11', 'aston-martin dbx', 'aston-martin rapide',\n",
    "       'aston-martin vantage', 'audi 100', 'audi a1', 'audi a2',\n",
    "       'audi a3', 'audi a4', 'audi a5', 'audi a6', 'audi a7', 'audi a8',\n",
    "       'audi e tron', 'audi e tron gt', 'audi q2', 'audi q3',\n",
    "       'audi q4 e tron', 'audi q5', 'audi q7', 'audi q8', 'audi r8',\n",
    "       'audi tt', 'austin 7', 'austin healey 3000', 'bentley 3 5 litre',\n",
    "       'bentley bentayga', 'bentley continental flying spur',\n",
    "       'bentley continental gt', 'bentley flying spur', 'bmw 1 series', 'bmw 2 series',\n",
    "       'bmw 3 series', 'bmw 4 series', 'bmw 5 series', 'bmw 6 series', 'bmw 7 series', 'bmw 8 series',\n",
    "       'bmw i3', 'bmw i8', 'bmw isetta', 'bmw ix', 'bmw x1', 'bmw x2',\n",
    "       'bmw x3', 'bmw x4', 'bmw x5', 'bmw x6', 'bmw x7', 'bmw z4',\n",
    "       'buick skylark', 'cadillac ats', 'cadillac bls', 'cadillac cts',\n",
    "       'cadillac eldorado', 'cadillac escalade', 'cadillac seville',\n",
    "       'cadillac srx', 'cadillac xt5', 'chevrolet aveo',\n",
    "       'chevrolet bel air', 'chevrolet camaro', 'chevrolet caprice',\n",
    "       'chevrolet captiva', 'chevrolet corvette', 'chevrolet cruze',\n",
    "       'chevrolet epica', 'chevrolet equinox', 'chevrolet impala',\n",
    "       'chevrolet malibu', 'chevrolet matiz', 'chevrolet spark',\n",
    "       'chevrolet tahoe', 'chrysler 300', 'chrysler pt cruiser',\n",
    "       'chrysler sebring', 'chrysler voyager', 'citroen b14',\n",
    "       'citroen berlingo', 'citroen c crosser', 'citroen c elysee',\n",
    "       'citroen c1', 'citroen c3', 'citroen c3 aircross', 'citroen c4',\n",
    "       'citroen c4 cactus', 'citroen c4 picasso', 'citroen c5',\n",
    "       'citroen c5 aircross', 'citroen c8', 'citroen ds', 'citroen ds5',\n",
    "       'citroen jumpy', 'citroen space tourer', 'cupra ateca',\n",
    "       'cupra born', 'cupra formentor', 'cupra leon', 'dacia dokker',\n",
    "       'dacia duster', 'dacia lodgy', 'dacia logan', 'dacia sandero',\n",
    "       'daewoo lacetti', 'daihatsu sirion', 'daihatsu terios',\n",
    "       'daimler 250 v8', 'daimler six', 'dodge 880', 'dodge caliber',\n",
    "       'dodge challenger', 'dodge charger', 'dodge durango',\n",
    "       'dodge journey', 'dodge nitro', 'dodge ram', 'dodge viper', 'ds 3',\n",
    "       'ds 3 crossback', 'ds 4', 'ds 7 crossback', 'excalibur series ii',\n",
    "       'ferrari 458', 'ferrari 488', 'ferrari 512', 'ferrari california',\n",
    "       'ferrari california t', 'ferrari ff', 'ferrari gtc4lusso',\n",
    "       'ferrari sf90', 'ferrari testarossa', 'fiat 1100', 'fiat 500',\n",
    "       'fiat 500l', 'fiat 500x', 'fiat 600', 'fiat bravo', 'fiat croma',\n",
    "       'fiat freemont', 'fiat fullback', 'fiat panda', 'fiat punto',\n",
    "       'fiat qubo', 'fiat tipo', 'fisker karma', 'ford b max','fiat ducato'\n",
    "       'ford c max', 'ford cougar', 'ford ecosport', 'ford edge',\n",
    "       'ford escape', 'ford explorer', 'ford f150',\n",
    "       'ford fairlane 500 skyliner', 'ford fiesta', 'ford focus',\n",
    "       'ford galaxy', 'ford ka', 'ford kuga', 'ford model 48',\n",
    "       'ford model t', 'ford mondeo', 'ford mustang',\n",
    "       'ford mustang mach e', 'ford puma', 'ford ranger', 'ford s max',\n",
    "       'ford scorpio', 'ford taurus', 'ford tourneo',\n",
    "       'ford tourneo connect', 'ford tourneo courier', 'genesis g70',\n",
    "       'genesis g80', 'genesis gv70', 'genesis gv80', 'gmc sierra',\n",
    "       'gmc terrain', 'gmc yukon xl', 'honda accord', 'honda city',\n",
    "       'honda civic', 'honda cr v', 'honda e', 'honda hr v',\n",
    "       'honda jazz fit', 'honda nsx', 'honda odyssey', 'honda s',\n",
    "       'hummer h2', 'hyundai getz', 'hyundai i10', 'hyundai i20',\n",
    "       'hyundai i30', 'hyundai i40', 'hyundai ioniq', 'hyundai ioniq 5',\n",
    "       'hyundai ix20', 'hyundai kona', 'hyundai nexo', 'hyundai santa fe',\n",
    "       'hyundai tiburon', 'hyundai tucson', 'hyundai veloster',\n",
    "       'infinity fx', 'infinity q30', 'infiniti q50 sedan',\n",
    "       'infinity qx80', 'isuzu d max', 'jac refine e s2', 'jaguar e pace',\n",
    "       'jaguar e type', 'jaguar f pace', 'jaguar f type', 'jaguar i pace',\n",
    "       'jaguar x type', 'jaguar xe', 'jaguar xf', 'jaguar xj',\n",
    "       'jaguar xk', 'jaguar xk120', 'jeep cherokee', 'jeep compass',\n",
    "       'jeep wrangler', 'jeep grand cherokee', 'jeep renegade',\n",
    "       'kia carens', 'kia ceed', 'kia ev6', 'kia magentis', 'kia niro',\n",
    "       'kia picanto', 'kia rio', 'kia sorento', 'kia soul',\n",
    "       'kia sportage', 'kia stinger', 'kia stonic', 'kia venga',\n",
    "       'lada 2102', 'lada 4x4', 'lamborghini aventador',\n",
    "       'lamborghini huracan', 'lamborghini urus', 'lancia delta',\n",
    "       'lancia phedra', 'lancia ypsilon', 'land rover defender',\n",
    "       'land rover discovery', 'land rover discovery sport',\n",
    "       'land rover freelander', 'land rover range rover',\n",
    "       'land rover range rover evoque', 'land rover range rover sport',\n",
    "       'land rover range rover velar', 'lexus ct', 'lexus gs', 'lexus is',\n",
    "       'lexus ls', 'lexus lx', 'lexus nx', 'lexus rx', 'lexus sc',\n",
    "       'lexus ux', 'lincoln mkx', 'lincoln navigator', 'lincoln town car',\n",
    "       'lotus elan', 'lotus elise', 'maserati ghibli',\n",
    "       'maserati granturismo', 'maserati levante',\n",
    "       'maserati quattroporte', 'maybach 57', 'mazda 2', 'mazda 3',\n",
    "       'mazda 5', 'mazda 6', 'mazda cx 3', 'mazda cx 30', 'mazda cx 5',\n",
    "       'mazda cx 7', 'mazda cx 9', 'mazda mx 30', 'mazda mx 5',\n",
    "       'mclaren 12c', 'mclaren 650s', 'mclaren 720s', 'mercedes-benz 123',\n",
    "       'mercedes-benz 170 s', 'mercedes-benz 220', 'mercedes-benz 220 s',\n",
    "       'mercedes-benz a class', 'mercedes-benz amg gt', 'mercedes-benz b class',\n",
    "       'mercedes-benz c class', 'mercedes-benz citan', 'mercedes-benz cl class',\n",
    "       'mercedes-benz cla class', 'mercedes-benz clk class', 'mercedes-benz cls class',\n",
    "       'mercedes-benz e class', 'mercedes-benz 3', 'mercedes-benz eqa',\n",
    "       'mercedes-benz eqc class', 'mercedes-benz eqs class', 'mercedes-benz g class',\n",
    "       'mercedes-benz gl class', 'mercedes-benz gla class', 'mercedes-benz glb class',\n",
    "       'mercedes-benz glc class', 'mercedes-benz gle class', 'mercedes-benz glk class',\n",
    "       'mercedes-benz gls class', 'mercedes-benz m class', 'mercedes-benz r class',\n",
    "       'mercedes-benz s class', 'mercedes-benz sl', 'mercedes-benz slk',\n",
    "       'mercedes-benz v class', 'mercedes-benz vito', 'mercedes-benz w114',\n",
    "       'mercedes-benz x class', 'mercury cougar', 'mg f', 'mg mgb', 'mg tf',\n",
    "       'mini clubman', 'mini cooper', 'mini countryman', 'mini paceman',\n",
    "       'mitsubishi asx', 'mitsubishi colt', 'mitsubishi i miev',\n",
    "       'mitsubishi l200', 'mitsubishi lancer', 'mitsubishi mirage',\n",
    "       'mitsubishi outlander', 'mitsubishi pajero', 'moskvitch 400',\n",
    "       'nissan 370z', 'nissan altima', 'nissan juke', 'nissan leaf',\n",
    "       'nissan micra', 'nissan murano', 'nissan navara', 'nissan note',\n",
    "       'nissan nv200', 'nissan pathfinder', 'nissan pixo',\n",
    "       'nissan qashqai', 'nissan x trail', 'oldsmobile 88',\n",
    "       'oldsmobile cutlass supreme', 'vauxhall adam', 'vauxhall agila',\n",
    "       'vauxhall ampera', 'vauxhall astra', 'vauxhall calibra', 'vauxhall cascada',\n",
    "       'vauxhall corsa', 'vauxhall crossland x', 'vauxhall grandland',\n",
    "       'vauxhall insignia', 'vauxhall karl', 'vauxhall meriva', 'vauxhall mokka',\n",
    "       'vauxhall tigra', 'vauxhall vectra', 'vauxhall zafira', 'peugeot 1007',\n",
    "       'peugeot 108', 'peugeot 206', 'peugeot 207', 'peugeot 208', 'peugeot 2008'\n",
    "       'peugeot 3008', 'peugeot 306', 'peugeot 307', 'peugeot 308',\n",
    "       'peugeot 4007', 'peugeot 4008', 'peugeot 406', 'peugeot 407',\n",
    "       'peugeot 5008', 'peugeot 508', 'peugeot 807', 'peugeot expert',\n",
    "       'peugeot partner', 'peugeot traveller', 'plymouth volare',\n",
    "       'polestar 2', 'pontiac firebird', 'pontiac gto', 'porsche 356',\n",
    "       'porsche 718', 'porsche 718 cayman', 'porsche 911', 'porsche 928',\n",
    "       'porsche cayenne 5 door coupe suv', 'porsche cayenne',\n",
    "       'porsche macan', 'porsche panamera', 'porsche taycan',\n",
    "       'renault captur', 'renault clio', 'renault espace',\n",
    "       'renault fluence', 'renault fuego', 'renault kadjar',\n",
    "       'renault kangoo', 'renault koleos', 'renault laguna',\n",
    "       'renault megane', 'renault modus', 'renault scenic',\n",
    "       'renault talisman', 'renault twingo', 'renault twizy',\n",
    "       'renault zoe', 'rolls-royce corniche', 'rolls-royce cullinan',\n",
    "       'rolls-royce ghost', 'rolls-royce phantom',\n",
    "       'rolls-royce silver shadow', 'rolls-royce silver spirit',\n",
    "       'rolls-royce wraith', 'rover sd1', 'saab 9 3', 'saab 9 5',\n",
    "       'seat alhambra', 'seat altea', 'seat arona', 'seat ateca',\n",
    "       'seat exeo', 'seat ibiza', 'seat leon', 'seat mii', 'seat tarraco',\n",
    "       'skoda citigo', 'skoda enyaq iv', 'skoda fabia', 'skoda kamiq',\n",
    "       'skoda karoq', 'skoda kodiaq', 'skoda octavia', 'skoda rapid',\n",
    "       'skoda scala', 'skoda superb', 'skoda yeti', 'smart forfour',\n",
    "       'smart fortwo', 'smart roadster', 'ssang yong korando',\n",
    "       'ssang yong kyron', 'ssang yong rexton', 'ssang yong tivoli',\n",
    "       'subaru forester', 'subaru impreza', 'subaru justy',\n",
    "       'subaru legacy', 'subaru levorg', 'subaru outback',\n",
    "       'subaru xv crosstrek', 'suzuki across', 'suzuki ignis',\n",
    "       'suzuki jimny', 'suzuki liana', 'suzuki swift', 'suzuki sx4',\n",
    "       'suzuki vitara', 'tatra 603', 'tesla model 3', 'tesla model s',\n",
    "       'tesla model x', 'tesla model y', 'toyota auris', 'toyota avensis',\n",
    "       'toyota aygo', 'toyota c hr', 'toyota celica', 'toyota corolla',\n",
    "       'toyota corolla verso', 'toyota gt 86', 'toyota highlander',\n",
    "       'toyota hilux', 'toyota iq', 'toyota land cruiser prado',\n",
    "       'toyota landcruiser', 'toyota previa', 'toyota prius',\n",
    "       'toyota prius plus', 'toyota proace verso', 'toyota rav4',\n",
    "       'toyota sienna', 'toyota supra', 'toyota tundra',\n",
    "       'toyota urban cruiser', 'toyota verso', 'toyota yaris',\n",
    "       'toyota yaris cross', 'triumph spitfire', 'triumph tr7',\n",
    "       'tvr cerbera', 'volkswagen 1600', 'volkswagen amarok',\n",
    "       'volkswagen arteon', 'volkswagen beetle', 'volkswagen bora',\n",
    "       'volkswagen caddy', 'volkswagen california',\n",
    "       'volkswagen caravelle', 'volkswagen eos', 'volkswagen fox',\n",
    "       'volkswagen golf', 'volkswagen id3', 'volkswagen id4',\n",
    "       'volkswagen jetta', 'volkswagen passat', 'volkswagen passat cc',\n",
    "       'volkswagen phaeton', 'volkswagen polo', 'volkswagen scirocco',\n",
    "       'volkswagen sharan', 'volkswagen t cross', 'volkswagen t roc',\n",
    "       'volkswagen tiguan', 'volkswagen touareg', 'volkswagen touran',\n",
    "       'volkswagen up', 'volvo 780', 'volvo 900', 'volvo c30',\n",
    "       'volvo s60', 'volvo s80', 'volvo s90', 'volvo v40', 'volvo v50',\n",
    "       'volvo v60', 'volvo v70', 'volvo v90', 'volvo xc40', 'volvo xc60',\n",
    "       'volvo xc70', 'volvo xc90', 'wartburg 353']\n",
    "\n",
    "results = []\n",
    "for index, car in uecars.iterrows():\n",
    "    lname = car[-1]\n",
    "    dummy = lname\n",
    "    for cname in name_list_from_carsized:\n",
    "        if cname in lname:\n",
    "            dummy = cname\n",
    "    for bod in body:\n",
    "        if bod in dummy:\n",
    "            dummy = re.sub(' '+bod,'',dummy)\n",
    "    results.append(dummy)\n",
    "\n",
    "uecars['name']=results\n",
    "uecars=uecars.drop('lname', axis=1)\n",
    "\n",
    "uecars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6c621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:08.156076Z",
     "start_time": "2022-03-03T21:23:08.067963Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Output clean used cars data \n",
    "uecars=uecars[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','dealer_area','dealer_city','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0']]\n",
    "uecars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_clean_used_electric_cars.csv'\n",
    "uecars.to_csv(uecars_abspath, index=False, header=uecars.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57b1d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:08.165126Z",
     "start_time": "2022-03-03T21:23:08.157780Z"
    }
   },
   "outputs": [],
   "source": [
    "uecars.mpg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6e100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:08.183308Z",
     "start_time": "2022-03-03T21:23:08.167554Z"
    }
   },
   "outputs": [],
   "source": [
    "uecars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac1231",
   "metadata": {},
   "source": [
    "## New cars - not electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345796f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:09.730303Z",
     "start_time": "2022-03-03T21:23:08.185657Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import all detailed files and make new ncars df, including year\n",
    "\n",
    "path = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/raw/df_detailed/'\n",
    "\n",
    "li=[]\n",
    "year_files = glob.glob(path + f\"/*2023_new.csv\")\n",
    "#print(len(year_files),'file(s) to load from', year)\n",
    "for filename in year_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0 )\n",
    "    df['YR'] = '2022 new'\n",
    "    df.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "    li.append(df)\n",
    "\n",
    "ncars = pd.concat(li, axis=0, ignore_index=True)\n",
    "ncars.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "ncars.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe09ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:14.211176Z",
     "start_time": "2022-03-03T21:23:09.732958Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Clean ncars.body\n",
    "\n",
    "#Create df of ncars will null body\n",
    "nabody = ncars[ncars['body'].isnull()].copy()\n",
    "\n",
    "#Encode body column but don't overwrite\n",
    "to_encode = ['body']\n",
    "ncars_e = ncars.copy()\n",
    "for col in to_encode:\n",
    "    le = LabelEncoder()\n",
    "    ncars_e[col] = le.fit_transform(ncars_e[col]) \n",
    "\n",
    "#Iterate through null-body ncars and replace with corresponding modal body value based on name column grouping\n",
    "for index, car in nabody.iterrows():\n",
    "    carname=nabody.loc[index,'name']\n",
    "    body=nabody.loc[index,'body']\n",
    "    nabody.loc[index,'body'] = ncars_e[ncars_e['name']==carname].body.mode()[0]\n",
    "    ncars_e.loc[index,'body'] = ncars_e[ncars_e['name']==carname].body.mode()[0]     \n",
    "\n",
    "#Reverse the encoding    \n",
    "for col in to_encode:\n",
    "    ncars[col] = le.inverse_transform(ncars_e[col]) \n",
    "\n",
    "#After checking the remaining ncars without a body, it is clear that they are all vans!    \n",
    "ncars.body = ['Van' if pd.Series(x).isnull()[0]==True else x for x in ncars.body]        \n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfadc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:14.301978Z",
     "start_time": "2022-03-03T21:23:14.212942Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Clean ncars.BHP, taking values from ncars.engine where necessary. Drop remaining NaN.\n",
    "\n",
    "# Unmerge some of the BHP entries which have engine size in there too.\n",
    "for index, car in ncars[ncars['BHP'].str.contains('L', regex=True, na=False)].iterrows():\n",
    "    ncars.loc[index, 'engine'] = str(ncars.loc[index, 'BHP']).split(' ')[0]\n",
    "    ncars.loc[index, 'BHP'] = str(ncars.loc[index, 'BHP']).split(' ')[1].strip('()') \n",
    "\n",
    "# Drop NaN BHP\n",
    "ncars.dropna(subset=['BHP'],inplace=True)\n",
    "\n",
    "def standardise_bhp(x):\n",
    "    lenbhp = len(str(x).split(' '))\n",
    "    bhp=x\n",
    "    if lenbhp == 1:\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])       \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014        \n",
    "    elif lenbhp == 2:\n",
    "        x=str(x.split(' ')[-1])\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])      \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014\n",
    "    else:\n",
    "        bhp=np.nan   \n",
    "    return bhp    \n",
    "\n",
    "#Standardise remaining BHP (convert from PS)\n",
    "ncars.BHP = ncars.BHP.apply(lambda x: standardise_bhp(x))\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24877d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:15.770454Z",
     "start_time": "2022-03-03T21:23:14.306468Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Compile the best location variable. Retain dealer_city and dealer_area. Don't drop remaining NaN.\n",
    "\n",
    "#split href0 into city and area\n",
    "ncars['dealer_city_temp'] = [x.split('/')[3] if type(x)==str and len(x.split('/'))>3 else x for x in ncars.href0]\n",
    "ncars['dealer_area'] = [x.split('/')[2] if type(x)==str and len(x.split('/'))>3 else x for x in ncars.href0]\n",
    "\n",
    "#If there are some seller ratings in seller0, move them to seller1\n",
    "ncars[ncars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller1 = ncars[ncars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller0\n",
    "\n",
    "#Make seller ratings in seller0 np.nan\n",
    "ncars.seller0 =[np.nan if '4' in str(x) or '5' in str(x) else x for x in ncars.seller0]\n",
    "\n",
    "#If the seller0 column is np.nan, use the dealer_city \n",
    "for index, car in ncars.iterrows():\n",
    "    if pd.isnull(ncars.loc[index,'seller0']):\n",
    "        ncars.loc[index,'seller0']=ncars.loc[index,'dealer_city_temp']\n",
    "        \n",
    "ncars['dealer_city'] = ncars['seller0']\n",
    "ncars.drop(['seller0','dealer_city_temp'],inplace=True, axis=1)\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e72b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:15.808927Z",
     "start_time": "2022-03-03T21:23:15.772227Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Iterate over missing engine rows and use regex name_subtitle to extract engine size where possible. Convert to float\n",
    "\n",
    "for index, car in ncars[ncars['engine'].isnull()].iterrows():\n",
    "    car_subname = ncars.loc[index, 'name_subtitle']\n",
    "    try:\n",
    "        enginesize = re.findall('([0-9][.][0-9]+)',car_subname)[0]\n",
    "    except: \n",
    "        enginesize = np.nan\n",
    "    ncars.loc[index,'engine'] = float(enginesize)\n",
    "    \n",
    "ncars.engine= ncars.engine.apply(lambda x: float(str(x).replace('L','')))\n",
    "ncars.dropna(subset=['engine'],inplace=True)\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc39d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.126078Z",
     "start_time": "2022-03-03T21:23:15.810841Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make doors column\n",
    "\n",
    "def extract_drs(x):\n",
    "    drs = re.findall('( [1-8]d[Rr]?)',x, re.I)\n",
    "    if len(drs) > 0:\n",
    "        drs = str(drs[0]).lower()\n",
    "    else:\n",
    "        drs = re.findall('([1-8][ ]?door)',x, re.I)\n",
    "        if len(drs) > 0:\n",
    "            drs = str(drs[0])[0]+'dr'\n",
    "        else:\n",
    "            drs = re.findall('([1-8]dr)',x, re.I)\n",
    "            if len(drs) > 0:\n",
    "                drs = str(drs[0])[0]+'dr'\n",
    "            else:\n",
    "                drs = re.findall('(D-4D)',x, re.I)\n",
    "                if len(drs) > 0:\n",
    "                    drs = '4dr'\n",
    "                else:\n",
    "                    drs='0dr'\n",
    "                \n",
    "    if ('r' or 'R') not in drs:\n",
    "        drs = drs.replace('d','dr')\n",
    "    return drs.strip()\n",
    "     \n",
    "ncars['doors'] = ncars.name_subtitle.apply(lambda x: extract_drs(x))\n",
    "\n",
    "#Create df of ncars with 0 doors\n",
    "zerodoors = ncars[ncars['doors']=='0dr'].copy()\n",
    "\n",
    "#Encode doors column but don't overwrite\n",
    "to_encode = ['doors']\n",
    "ncars_e = ncars.copy()\n",
    "for col in to_encode:\n",
    "    le = LabelEncoder()\n",
    "    ncars_e[col] = le.fit_transform(ncars_e[col]) \n",
    "\n",
    "#Iterate through zero door ncars and replace with corresponding num doors based on name column grouping\n",
    "for index, car in zerodoors.iterrows():\n",
    "    carname=zerodoors.loc[index,'name']\n",
    "    ncars_e.loc[index,'doors'] = ncars_e[ncars_e['name']==carname].doors.mode()[0]     \n",
    "\n",
    "#Reverse the encoding    \n",
    "for col in to_encode:\n",
    "    ncars[col] = le.inverse_transform(ncars_e[col]) \n",
    "\n",
    "#Drop the remaining 226 ncars without door information    \n",
    "ncars.dropna(subset=['doors'],inplace=True)\n",
    "    \n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67849e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.133111Z",
     "start_time": "2022-03-03T21:23:16.128069Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean ncars.mileage\n",
    "\n",
    "#Drop them - only 283\n",
    "ncars.mileage = '0'\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29f9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.152842Z",
     "start_time": "2022-03-03T21:23:16.135180Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean ncars.fuel\n",
    "\n",
    "#Drop them - only 12\n",
    "ncars.dropna(subset=['fuel'],inplace=True)\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d763202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.205611Z",
     "start_time": "2022-03-03T21:23:16.154749Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clean ncars.price, make ncars.ID, clean ncars.year \n",
    "\n",
    "to_dummy=['mpg','drivetrain','make','body','transmission','fuel']\n",
    "\n",
    "ncars.price=ncars.price.apply(lambda x: x.replace('£',''))\n",
    "ncars.price=ncars.price.apply(lambda x: float(x.replace(',','')))\n",
    "ncars['id'] =[x.split('/')[-1] for x in ncars.link]\n",
    "ncars['year_reg']=ncars.year\n",
    "ncars['year']= 2022\n",
    "ncars.drop('YR',inplace=True, axis=1)\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbf9e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.210807Z",
     "start_time": "2022-03-03T21:23:16.207783Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Obtain ncars.ll_search <-- Doesn't actually work with nominatim openstreetmap. Probably not needed.\n",
    "\n",
    "# ncars['ll_search']=''\n",
    "# ll_search_series = []\n",
    "# for index, car in tqdm(ncars.iterrows()):\n",
    "#     dc = str(car[19])\n",
    "#     da = str(car[18])\n",
    "#     if dc == 'nan':\n",
    "#         dc = ''\n",
    "#     if da == 'nan':\n",
    "#         da = ''\n",
    "#     car[23] = dc+' '+da\n",
    "#     ll_search_series.append(car[23])\n",
    "# ncars['ll_search'] = ll_search_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2544e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.215811Z",
     "start_time": "2022-03-03T21:23:16.212760Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Iterate over ncars to convert dealer_city to lat/lon. 2s per car makes this a 2+day cell. Running in other workbook. \n",
    "\n",
    "# lat_series = []\n",
    "# lon_series = []\n",
    "\n",
    "# for index, car in tqdm(ncars.iterrows()):\n",
    "#     address = car[19] + ' UK'\n",
    "#     url = 'https://nominatim.openstreetmap.org/search/' + urllib.parse.quote(address) +'?format=json'\n",
    "#     response = requests.get(url).json()\n",
    "#     lat_series.append(response[0][\"lat\"])\n",
    "#     lon_series.append(response[0][\"lon\"])\n",
    "    \n",
    "# ncars['seller_lat']=lat_series\n",
    "# ncars['seller_lon']=lon_series\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6285246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:16.784145Z",
     "start_time": "2022-03-03T21:23:16.217579Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Have a nosey at the price and mileage distribution\n",
    "\n",
    "ncars['log_price']=ncars.price.apply(lambda x: np.log(x))\n",
    "ncars['mileage']=ncars.mileage.apply(lambda x: float(x))\n",
    "ncars['log_mileage']=ncars.mileage.apply(lambda x: np.log(x))\n",
    "\n",
    "#mask = np.abs((ncars.price - ncars.price.mean(0)) / ncars.price.std(0)) > 3\n",
    "#ncars= ncars[~mask]\n",
    "#ncars.price.plot(kind='hist', bins=50, title='Car Price after outlier removal', xlabel='£');\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16,4))\n",
    "ax[0].hist(ncars.price, bins=60)\n",
    "ax[1].hist(ncars.log_price, bins=60)\n",
    "ax[0].set_xlabel('£')\n",
    "ax[1].set_xlabel('£')\n",
    "ax[0].set_title('Price')\n",
    "ax[1].set_title('Log price')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804350d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:18.679844Z",
     "start_time": "2022-03-03T21:23:16.786701Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Simplify the name column a little. Probably not perfect \n",
    "\n",
    "ncars['orig_name'] = ncars.name\n",
    "ncars['lname']=ncars.name.apply(lambda x: x.lower())\n",
    "\n",
    "body =[\"coupe\", \"convertible\", \"estate\", \"hatchback\", \"MPV\", \"pickup\", \n",
    "       \"SUV\", \"saloon\",\"cabriolet\",\"sedan\"]\n",
    "name_list_from_carsized = ['abarth 500', 'acura nsx', 'alfa-romeo 147', 'alfa-romeo 156',\n",
    "       'alfa-romeo 159', 'alfa-romeo 164', 'alfa-romeo 4c',\n",
    "       'alfa-romeo giulia', 'alfa-romeo giulietta', 'alfa-romeo mito',\n",
    "       'alfa-romeo sprint', 'alfa-romeo stelvio', 'alvis tc 108',\n",
    "       'aston-martin db11', 'aston-martin dbx', 'aston-martin rapide',\n",
    "       'aston-martin vantage', 'audi 100', 'audi a1', 'audi a2',\n",
    "       'audi a3', 'audi a4', 'audi a5', 'audi a6', 'audi a7', 'audi a8',\n",
    "       'audi e tron', 'audi e tron gt', 'audi q2', 'audi q3',\n",
    "       'audi q4 e tron', 'audi q5', 'audi q7', 'audi q8', 'audi r8',\n",
    "       'audi tt', 'austin 7', 'austin healey 3000', 'bentley 3 5 litre',\n",
    "       'bentley bentayga', 'bentley continental flying spur',\n",
    "       'bentley continental gt', 'bentley flying spur', 'bmw 1 series', 'bmw 2 series',\n",
    "       'bmw 3 series', 'bmw 4 series', 'bmw 5 series', 'bmw 6 series', 'bmw 7 series', 'bmw 8 series',\n",
    "       'bmw i3', 'bmw i8', 'bmw isetta', 'bmw ix', 'bmw x1', 'bmw x2',\n",
    "       'bmw x3', 'bmw x4', 'bmw x5', 'bmw x6', 'bmw x7', 'bmw z4',\n",
    "       'buick skylark', 'cadillac ats', 'cadillac bls', 'cadillac cts',\n",
    "       'cadillac eldorado', 'cadillac escalade', 'cadillac seville',\n",
    "       'cadillac srx', 'cadillac xt5', 'chevrolet aveo',\n",
    "       'chevrolet bel air', 'chevrolet camaro', 'chevrolet caprice',\n",
    "       'chevrolet captiva', 'chevrolet corvette', 'chevrolet cruze',\n",
    "       'chevrolet epica', 'chevrolet equinox', 'chevrolet impala',\n",
    "       'chevrolet malibu', 'chevrolet matiz', 'chevrolet spark',\n",
    "       'chevrolet tahoe', 'chrysler 300', 'chrysler pt cruiser',\n",
    "       'chrysler sebring', 'chrysler voyager', 'citroen b14',\n",
    "       'citroen berlingo', 'citroen c crosser', 'citroen c elysee',\n",
    "       'citroen c1', 'citroen c3', 'citroen c3 aircross', 'citroen c4',\n",
    "       'citroen c4 cactus', 'citroen c4 picasso', 'citroen c5',\n",
    "       'citroen c5 aircross', 'citroen c8', 'citroen ds', 'citroen ds5',\n",
    "       'citroen jumpy', 'citroen space tourer', 'cupra ateca',\n",
    "       'cupra born', 'cupra formentor', 'cupra leon', 'dacia dokker',\n",
    "       'dacia duster', 'dacia lodgy', 'dacia logan', 'dacia sandero',\n",
    "       'daewoo lacetti', 'daihatsu sirion', 'daihatsu terios',\n",
    "       'daimler 250 v8', 'daimler six', 'dodge 880', 'dodge caliber',\n",
    "       'dodge challenger', 'dodge charger', 'dodge durango',\n",
    "       'dodge journey', 'dodge nitro', 'dodge ram', 'dodge viper', 'ds 3',\n",
    "       'ds 3 crossback', 'ds 4', 'ds 7 crossback', 'excalibur series ii',\n",
    "       'ferrari 458', 'ferrari 488', 'ferrari 512', 'ferrari california',\n",
    "       'ferrari california t', 'ferrari ff', 'ferrari gtc4lusso',\n",
    "       'ferrari sf90', 'ferrari testarossa', 'fiat 1100', 'fiat 500',\n",
    "       'fiat 500l', 'fiat 500x', 'fiat 600', 'fiat bravo', 'fiat croma',\n",
    "       'fiat freemont', 'fiat fullback', 'fiat panda', 'fiat punto',\n",
    "       'fiat qubo', 'fiat tipo', 'fisker karma', 'ford b max','fiat ducato'\n",
    "       'ford c max', 'ford cougar', 'ford ecosport', 'ford edge',\n",
    "       'ford escape', 'ford explorer', 'ford f150',\n",
    "       'ford fairlane 500 skyliner', 'ford fiesta', 'ford focus',\n",
    "       'ford galaxy', 'ford ka', 'ford kuga', 'ford model 48',\n",
    "       'ford model t', 'ford mondeo', 'ford mustang',\n",
    "       'ford mustang mach e', 'ford puma', 'ford ranger', 'ford s max',\n",
    "       'ford scorpio', 'ford taurus', 'ford tourneo',\n",
    "       'ford tourneo connect', 'ford tourneo courier', 'genesis g70',\n",
    "       'genesis g80', 'genesis gv70', 'genesis gv80', 'gmc sierra',\n",
    "       'gmc terrain', 'gmc yukon xl', 'honda accord', 'honda city',\n",
    "       'honda civic', 'honda cr v', 'honda e', 'honda hr v',\n",
    "       'honda jazz fit', 'honda nsx', 'honda odyssey', 'honda s',\n",
    "       'hummer h2', 'hyundai getz', 'hyundai i10', 'hyundai i20',\n",
    "       'hyundai i30', 'hyundai i40', 'hyundai ioniq', 'hyundai ioniq 5',\n",
    "       'hyundai ix20', 'hyundai kona', 'hyundai nexo', 'hyundai santa fe',\n",
    "       'hyundai tiburon', 'hyundai tucson', 'hyundai veloster',\n",
    "       'infinity fx', 'infinity q30', 'infiniti q50 sedan',\n",
    "       'infinity qx80', 'isuzu d max', 'jac refine e s2', 'jaguar e pace',\n",
    "       'jaguar e type', 'jaguar f pace', 'jaguar f type', 'jaguar i pace',\n",
    "       'jaguar x type', 'jaguar xe', 'jaguar xf', 'jaguar xj',\n",
    "       'jaguar xk', 'jaguar xk120', 'jeep cherokee', 'jeep compass',\n",
    "       'jeep wrangler', 'jeep grand cherokee', 'jeep renegade',\n",
    "       'kia carens', 'kia ceed', 'kia ev6', 'kia magentis', 'kia niro',\n",
    "       'kia picanto', 'kia rio', 'kia sorento', 'kia soul',\n",
    "       'kia sportage', 'kia stinger', 'kia stonic', 'kia venga',\n",
    "       'lada 2102', 'lada 4x4', 'lamborghini aventador',\n",
    "       'lamborghini huracan', 'lamborghini urus', 'lancia delta',\n",
    "       'lancia phedra', 'lancia ypsilon', 'land rover defender',\n",
    "       'land rover discovery', 'land rover discovery sport',\n",
    "       'land rover freelander', 'land rover range rover',\n",
    "       'land rover range rover evoque', 'land rover range rover sport',\n",
    "       'land rover range rover velar', 'lexus ct', 'lexus gs', 'lexus is',\n",
    "       'lexus ls', 'lexus lx', 'lexus nx', 'lexus rx', 'lexus sc',\n",
    "       'lexus ux', 'lincoln mkx', 'lincoln navigator', 'lincoln town car',\n",
    "       'lotus elan', 'lotus elise', 'maserati ghibli',\n",
    "       'maserati granturismo', 'maserati levante',\n",
    "       'maserati quattroporte', 'maybach 57', 'mazda 2', 'mazda 3',\n",
    "       'mazda 5', 'mazda 6', 'mazda cx 3', 'mazda cx 30', 'mazda cx 5',\n",
    "       'mazda cx 7', 'mazda cx 9', 'mazda mx 30', 'mazda mx 5',\n",
    "       'mclaren 12c', 'mclaren 650s', 'mclaren 720s', 'mercedes-benz 123',\n",
    "       'mercedes-benz 170 s', 'mercedes-benz 220', 'mercedes-benz 220 s',\n",
    "       'mercedes-benz a class', 'mercedes-benz amg gt', 'mercedes-benz b class',\n",
    "       'mercedes-benz c class', 'mercedes-benz citan', 'mercedes-benz cl class',\n",
    "       'mercedes-benz cla class', 'mercedes-benz clk class', 'mercedes-benz cls class',\n",
    "       'mercedes-benz e class', 'mercedes-benz 3', 'mercedes-benz eqa',\n",
    "       'mercedes-benz eqc class', 'mercedes-benz eqs class', 'mercedes-benz g class',\n",
    "       'mercedes-benz gl class', 'mercedes-benz gla class', 'mercedes-benz glb class',\n",
    "       'mercedes-benz glc class', 'mercedes-benz gle class', 'mercedes-benz glk class',\n",
    "       'mercedes-benz gls class', 'mercedes-benz m class', 'mercedes-benz r class',\n",
    "       'mercedes-benz s class', 'mercedes-benz sl', 'mercedes-benz slk',\n",
    "       'mercedes-benz v class', 'mercedes-benz vito', 'mercedes-benz w114',\n",
    "       'mercedes-benz x class', 'mercury cougar', 'mg f', 'mg mgb', 'mg tf',\n",
    "       'mini clubman', 'mini cooper', 'mini countryman', 'mini paceman',\n",
    "       'mitsubishi asx', 'mitsubishi colt', 'mitsubishi i miev',\n",
    "       'mitsubishi l200', 'mitsubishi lancer', 'mitsubishi mirage',\n",
    "       'mitsubishi outlander', 'mitsubishi pajero', 'moskvitch 400',\n",
    "       'nissan 370z', 'nissan altima', 'nissan juke', 'nissan leaf',\n",
    "       'nissan micra', 'nissan murano', 'nissan navara', 'nissan note',\n",
    "       'nissan nv200', 'nissan pathfinder', 'nissan pixo',\n",
    "       'nissan qashqai', 'nissan x trail', 'oldsmobile 88',\n",
    "       'oldsmobile cutlass supreme', 'vauxhall adam', 'vauxhall agila',\n",
    "       'vauxhall ampera', 'vauxhall astra', 'vauxhall calibra', 'vauxhall cascada',\n",
    "       'vauxhall corsa', 'vauxhall crossland x', 'vauxhall grandland',\n",
    "       'vauxhall insignia', 'vauxhall karl', 'vauxhall meriva', 'vauxhall mokka',\n",
    "       'vauxhall tigra', 'vauxhall vectra', 'vauxhall zafira', 'peugeot 1007',\n",
    "       'peugeot 108', 'peugeot 206', 'peugeot 207', 'peugeot 208', 'peugeot 2008'\n",
    "       'peugeot 3008', 'peugeot 306', 'peugeot 307', 'peugeot 308',\n",
    "       'peugeot 4007', 'peugeot 4008', 'peugeot 406', 'peugeot 407',\n",
    "       'peugeot 5008', 'peugeot 508', 'peugeot 807', 'peugeot expert',\n",
    "       'peugeot partner', 'peugeot traveller', 'plymouth volare',\n",
    "       'polestar 2', 'pontiac firebird', 'pontiac gto', 'porsche 356',\n",
    "       'porsche 718', 'porsche 718 cayman', 'porsche 911', 'porsche 928',\n",
    "       'porsche cayenne 5 door coupe suv', 'porsche cayenne',\n",
    "       'porsche macan', 'porsche panamera', 'porsche taycan',\n",
    "       'renault captur', 'renault clio', 'renault espace',\n",
    "       'renault fluence', 'renault fuego', 'renault kadjar',\n",
    "       'renault kangoo', 'renault koleos', 'renault laguna',\n",
    "       'renault megane', 'renault modus', 'renault scenic',\n",
    "       'renault talisman', 'renault twingo', 'renault twizy',\n",
    "       'renault zoe', 'rolls-royce corniche', 'rolls-royce cullinan',\n",
    "       'rolls-royce ghost', 'rolls-royce phantom',\n",
    "       'rolls-royce silver shadow', 'rolls-royce silver spirit',\n",
    "       'rolls-royce wraith', 'rover sd1', 'saab 9 3', 'saab 9 5',\n",
    "       'seat alhambra', 'seat altea', 'seat arona', 'seat ateca',\n",
    "       'seat exeo', 'seat ibiza', 'seat leon', 'seat mii', 'seat tarraco',\n",
    "       'skoda citigo', 'skoda enyaq iv', 'skoda fabia', 'skoda kamiq',\n",
    "       'skoda karoq', 'skoda kodiaq', 'skoda octavia', 'skoda rapid',\n",
    "       'skoda scala', 'skoda superb', 'skoda yeti', 'smart forfour',\n",
    "       'smart fortwo', 'smart roadster', 'ssang yong korando',\n",
    "       'ssang yong kyron', 'ssang yong rexton', 'ssang yong tivoli',\n",
    "       'subaru forester', 'subaru impreza', 'subaru justy',\n",
    "       'subaru legacy', 'subaru levorg', 'subaru outback',\n",
    "       'subaru xv crosstrek', 'suzuki across', 'suzuki ignis',\n",
    "       'suzuki jimny', 'suzuki liana', 'suzuki swift', 'suzuki sx4',\n",
    "       'suzuki vitara', 'tatra 603', 'tesla model 3', 'tesla model s',\n",
    "       'tesla model x', 'tesla model y', 'toyota auris', 'toyota avensis',\n",
    "       'toyota aygo', 'toyota c hr', 'toyota celica', 'toyota corolla',\n",
    "       'toyota corolla verso', 'toyota gt 86', 'toyota highlander',\n",
    "       'toyota hilux', 'toyota iq', 'toyota land cruiser prado',\n",
    "       'toyota landcruiser', 'toyota previa', 'toyota prius',\n",
    "       'toyota prius plus', 'toyota proace verso', 'toyota rav4',\n",
    "       'toyota sienna', 'toyota supra', 'toyota tundra',\n",
    "       'toyota urban cruiser', 'toyota verso', 'toyota yaris',\n",
    "       'toyota yaris cross', 'triumph spitfire', 'triumph tr7',\n",
    "       'tvr cerbera', 'volkswagen 1600', 'volkswagen amarok',\n",
    "       'volkswagen arteon', 'volkswagen beetle', 'volkswagen bora',\n",
    "       'volkswagen caddy', 'volkswagen california',\n",
    "       'volkswagen caravelle', 'volkswagen eos', 'volkswagen fox',\n",
    "       'volkswagen golf', 'volkswagen id3', 'volkswagen id4',\n",
    "       'volkswagen jetta', 'volkswagen passat', 'volkswagen passat cc',\n",
    "       'volkswagen phaeton', 'volkswagen polo', 'volkswagen scirocco',\n",
    "       'volkswagen sharan', 'volkswagen t cross', 'volkswagen t roc',\n",
    "       'volkswagen tiguan', 'volkswagen touareg', 'volkswagen touran',\n",
    "       'volkswagen up', 'volvo 780', 'volvo 900', 'volvo c30',\n",
    "       'volvo s60', 'volvo s80', 'volvo s90', 'volvo v40', 'volvo v50',\n",
    "       'volvo v60', 'volvo v70', 'volvo v90', 'volvo xc40', 'volvo xc60',\n",
    "       'volvo xc70', 'volvo xc90', 'wartburg 353']\n",
    "\n",
    "results = []\n",
    "for index, car in ncars.iterrows():\n",
    "    lname = car[-1]\n",
    "    dummy = lname\n",
    "    for cname in name_list_from_carsized:\n",
    "        if cname in lname:\n",
    "            dummy = cname\n",
    "    for bod in body:\n",
    "        if bod in dummy:\n",
    "            dummy = re.sub(' '+bod,'',dummy)\n",
    "    results.append(dummy)\n",
    "results\n",
    "\n",
    "ncars['name']=results\n",
    "ncars=ncars.drop('lname', axis=1)\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0f40a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:18.689044Z",
     "start_time": "2022-03-03T21:23:18.682238Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Add ncars.used and ncars.e_engine_kWh columns to be compatible with other datasets \n",
    "\n",
    "ncars['used']=0\n",
    "ncars['e_engine_kWh']= np.nan\n",
    "\n",
    "ncars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc1bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:19.005227Z",
     "start_time": "2022-03-03T21:23:18.691293Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Output clean used cars data \n",
    "ncars=ncars[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','dealer_area','dealer_city','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0']]\n",
    "ncars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_clean_new_cars.csv'\n",
    "ncars.to_csv(ncars_abspath, index=False, header=ncars.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6e2fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:19.033060Z",
     "start_time": "2022-03-03T21:23:19.007463Z"
    }
   },
   "outputs": [],
   "source": [
    "ncars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024e410",
   "metadata": {},
   "source": [
    "## New cars - electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e8ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:19.096617Z",
     "start_time": "2022-03-03T21:23:19.035510Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import all detailed files and make new ncars df, including year\n",
    "\n",
    "path = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/raw/df_detailed_ev/'\n",
    "\n",
    "li=[]\n",
    "year_files = glob.glob(path + f\"/*2023_electric_new.csv\")\n",
    "#print(len(year_files),'file(s) to load from', year)\n",
    "for filename in year_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0 )\n",
    "    df['YR'] = '2022 new'\n",
    "    df.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "    li.append(df)\n",
    "\n",
    "necars = pd.concat(li, axis=0, ignore_index=True)\n",
    "necars.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "necars.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409000f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:19.103380Z",
     "start_time": "2022-03-03T21:23:19.098330Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Body is fine. No cleaning needed.\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362f097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:19.127286Z",
     "start_time": "2022-03-03T21:23:19.105673Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Clean BHP.\n",
    "\n",
    "# Drop NaN BHP\n",
    "necars.dropna(subset=['BHP'],inplace=True)\n",
    "\n",
    "def standardise_bhp(x):\n",
    "    lenbhp = len(str(x).split(' '))\n",
    "    bhp=x\n",
    "    if lenbhp == 1:\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])       \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014        \n",
    "    elif lenbhp == 2:\n",
    "        x=str(x.split(' ')[-1])\n",
    "        if 'BHP' in x:\n",
    "            bhp=float(re.findall('[0-9]+', x)[0])      \n",
    "        elif 'PS' in x:\n",
    "            ps=float(re.findall('[0-9]+', x)[0])\n",
    "            bhp = ps/1.014\n",
    "    else:\n",
    "        bhp=np.nan   \n",
    "    return bhp    \n",
    "\n",
    "#Standardise remaining BHP (convert from PS)\n",
    "necars.BHP = necars.BHP.apply(lambda x: standardise_bhp(x))\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761771a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:19.429890Z",
     "start_time": "2022-03-03T21:23:19.129152Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Compile the best location variable. Retain dealer_city and dealer_area. Don't drop remaining NaN.\n",
    "\n",
    "#split href0 into city and area\n",
    "necars['dealer_city_temp'] = [x.split('/')[3] if type(x)==str and len(x.split('/'))>3 else x for x in necars.href0]\n",
    "necars['dealer_area'] = [x.split('/')[2] if type(x)==str and len(x.split('/'))>3 else x for x in necars.href0]\n",
    "\n",
    "#If there are some seller ratings in seller0, move them to seller1\n",
    "necars[necars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller1 = necars[necars['seller0'].str.contains('[+-]?([0-9]*[.])?[0-9]+', regex=True, na=False)].seller0\n",
    "\n",
    "#Make seller ratings in seller0 np.nan\n",
    "necars.seller0 =[np.nan if '4' in str(x) or '5' in str(x) else x for x in necars.seller0]\n",
    "\n",
    "#If the seller0 column is np.nan, use the dealer_city \n",
    "for index, car in necars.iterrows():\n",
    "    if pd.isnull(necars.loc[index,'seller0']):\n",
    "        necars.loc[index,'seller0']=necars.loc[index,'dealer_city_temp']\n",
    "    #Tiny number of cars don't have a location, and they're all from one dealer in Oldbury.    \n",
    "    if pd.isnull(necars.loc[index,'seller0']):\n",
    "        necars.loc[index,'seller0']= 'Oldbury'\n",
    "        \n",
    "necars['dealer_city'] = necars['seller0']\n",
    "necars.drop(['seller0','dealer_city_temp'],inplace=True, axis=1)\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c01111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:20.490286Z",
     "start_time": "2022-03-03T21:23:19.431976Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Populate necars.e_engine_kWh from name_subtitle ~20% NaN. Not great but BHP supersedes it.\n",
    "\n",
    "necars['e_engine_kWh']=''\n",
    "necars['engine']=np.nan\n",
    "\n",
    "for index, car in necars.iterrows():\n",
    "    car_subname = necars.loc[index, 'name_subtitle']\n",
    "    try:\n",
    "        eenginesize = re.findall('[\\d]+[.]?[\\d]+[ ]?kwh',car_subname, flags=re.I)[0]\n",
    "    except: \n",
    "        eenginesize = np.nan\n",
    "    necars.loc[index,'e_engine_kWh'] = eenginesize\n",
    "    \n",
    "necars.e_engine_kWh= necars.e_engine_kWh.apply(lambda x: float(str(x).lower().replace('kwh','')))\n",
    "#necars.dropna(subset=['engine'],inplace=True)\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80bc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:20.511766Z",
     "start_time": "2022-03-03T21:23:20.492523Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make doors column. Drop 4 without info. \n",
    "     \n",
    "necars['doors'] = necars.name_subtitle.apply(lambda x: extract_drs(x))\n",
    "\n",
    "# Drop the remaining 4 necars without door information    \n",
    "necars.drop(necars[necars.doors=='0dr'].index, inplace=True)\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65e9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:20.535742Z",
     "start_time": "2022-03-03T21:23:20.514537Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clean necars.price, make necars.ID, clean necars.year \n",
    "to_dummy=['mpg','drivetrain','make','body','transmission','fuel']\n",
    "\n",
    "necars.price=necars.price.apply(lambda x: x.replace('£',''))\n",
    "necars.price=necars.price.apply(lambda x: float(x.replace(',','')))\n",
    "necars['id'] =[x.split('/')[-1] for x in necars.link]\n",
    "necars['year_reg']=necars.YR\n",
    "necars['year']=2022\n",
    "necars.drop('YR',inplace=True, axis=1)\n",
    "necars.owners=int(0)\n",
    "necars.ULEZ='ULEZ'\n",
    "\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3b5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:20.543574Z",
     "start_time": "2022-03-03T21:23:20.538534Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set necars.mileage = 0. Set necars.used = 0.\n",
    "\n",
    "necars['mileage']= 0\n",
    "necars['used']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d8a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:21.086826Z",
     "start_time": "2022-03-03T21:23:20.546071Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Have a nosey at the price and mileage distribution\n",
    "\n",
    "necars['log_price']=necars.price.apply(lambda x: np.log(x))\n",
    "necars['mileage']=necars.mileage.apply(lambda x: float(x))\n",
    "necars['log_mileage']=necars.mileage.apply(lambda x: np.log(x))\n",
    "\n",
    "#mask = np.abs((ncars.price - ncars.price.mean(0)) / ncars.price.std(0)) > 3\n",
    "#ncars= ncars[~mask]\n",
    "#ncars.price.plot(kind='hist', bins=50, title='Car Price after outlier removal', xlabel='£');\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16,4))\n",
    "ax[0].hist(necars.price, bins=60)\n",
    "ax[1].hist(necars.log_price, bins=60)\n",
    "ax[0].set_xlabel('£')\n",
    "ax[1].set_xlabel('£')\n",
    "ax[0].set_title('Price')\n",
    "ax[1].set_title('Log price')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b40bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:21.513427Z",
     "start_time": "2022-03-03T21:23:21.089528Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Simplify the name column a little. Probably some room for improvement here but it will be used when merging \n",
    "\n",
    "necars['orig_name'] = necars.name\n",
    "necars['lname']=necars.name.apply(lambda x: x.lower())\n",
    "\n",
    "body =[\"coupe\", \"convertible\", \"estate\", \"hatchback\", \"MPV\", \"pickup\", \n",
    "        \"SUV\", \"saloon\",\"cabriolet\",\"sedan\"]\n",
    "name_list_from_carsized = ['abarth 500', 'acura nsx', 'alfa-romeo 147', 'alfa-romeo 156',\n",
    "       'alfa-romeo 159', 'alfa-romeo 164', 'alfa-romeo 4c',\n",
    "       'alfa-romeo giulia', 'alfa-romeo giulietta', 'alfa-romeo mito',\n",
    "       'alfa-romeo sprint', 'alfa-romeo stelvio', 'alvis tc 108',\n",
    "       'aston-martin db11', 'aston-martin dbx', 'aston-martin rapide',\n",
    "       'aston-martin vantage', 'audi 100', 'audi a1', 'audi a2',\n",
    "       'audi a3', 'audi a4', 'audi a5', 'audi a6', 'audi a7', 'audi a8',\n",
    "       'audi e tron', 'audi e tron gt', 'audi q2', 'audi q3',\n",
    "       'audi q4 e tron', 'audi q5', 'audi q7', 'audi q8', 'audi r8',\n",
    "       'audi tt', 'austin 7', 'austin healey 3000', 'bentley 3 5 litre',\n",
    "       'bentley bentayga', 'bentley continental flying spur',\n",
    "       'bentley continental gt', 'bentley flying spur', 'bmw 1 series', 'bmw 2 series',\n",
    "       'bmw 3 series', 'bmw 4 series', 'bmw 5 series', 'bmw 6 series', 'bmw 7 series', 'bmw 8 series',\n",
    "       'bmw i3', 'bmw i8', 'bmw isetta', 'bmw ix', 'bmw x1', 'bmw x2',\n",
    "       'bmw x3', 'bmw x4', 'bmw x5', 'bmw x6', 'bmw x7', 'bmw z4',\n",
    "       'buick skylark', 'cadillac ats', 'cadillac bls', 'cadillac cts',\n",
    "       'cadillac eldorado', 'cadillac escalade', 'cadillac seville',\n",
    "       'cadillac srx', 'cadillac xt5', 'chevrolet aveo',\n",
    "       'chevrolet bel air', 'chevrolet camaro', 'chevrolet caprice',\n",
    "       'chevrolet captiva', 'chevrolet corvette', 'chevrolet cruze',\n",
    "       'chevrolet epica', 'chevrolet equinox', 'chevrolet impala',\n",
    "       'chevrolet malibu', 'chevrolet matiz', 'chevrolet spark',\n",
    "       'chevrolet tahoe', 'chrysler 300', 'chrysler pt cruiser',\n",
    "       'chrysler sebring', 'chrysler voyager', 'citroen b14',\n",
    "       'citroen berlingo', 'citroen c crosser', 'citroen c elysee',\n",
    "       'citroen c1', 'citroen c3', 'citroen c3 aircross', 'citroen c4',\n",
    "       'citroen c4 cactus', 'citroen c4 picasso', 'citroen c5',\n",
    "       'citroen c5 aircross', 'citroen c8', 'citroen ds', 'citroen ds5',\n",
    "       'citroen jumpy', 'citroen space tourer', 'cupra ateca',\n",
    "       'cupra born', 'cupra formentor', 'cupra leon', 'dacia dokker',\n",
    "       'dacia duster', 'dacia lodgy', 'dacia logan', 'dacia sandero',\n",
    "       'daewoo lacetti', 'daihatsu sirion', 'daihatsu terios',\n",
    "       'daimler 250 v8', 'daimler six', 'dodge 880', 'dodge caliber',\n",
    "       'dodge challenger', 'dodge charger', 'dodge durango',\n",
    "       'dodge journey', 'dodge nitro', 'dodge ram', 'dodge viper', 'ds 3',\n",
    "       'ds 3 crossback', 'ds 4', 'ds 7 crossback', 'excalibur series ii',\n",
    "       'ferrari 458', 'ferrari 488', 'ferrari 512', 'ferrari california',\n",
    "       'ferrari california t', 'ferrari ff', 'ferrari gtc4lusso',\n",
    "       'ferrari sf90', 'ferrari testarossa', 'fiat 1100', 'fiat 500',\n",
    "       'fiat 500l', 'fiat 500x', 'fiat 600', 'fiat bravo', 'fiat croma',\n",
    "       'fiat freemont', 'fiat fullback', 'fiat panda', 'fiat punto',\n",
    "       'fiat qubo', 'fiat tipo', 'fisker karma', 'ford b max','fiat ducato'\n",
    "       'ford c max', 'ford cougar', 'ford ecosport', 'ford edge',\n",
    "       'ford escape', 'ford explorer', 'ford f150',\n",
    "       'ford fairlane 500 skyliner', 'ford fiesta', 'ford focus',\n",
    "       'ford galaxy', 'ford ka', 'ford kuga', 'ford model 48',\n",
    "       'ford model t', 'ford mondeo', 'ford mustang',\n",
    "       'ford mustang mach e', 'ford puma', 'ford ranger', 'ford s max',\n",
    "       'ford scorpio', 'ford taurus', 'ford tourneo',\n",
    "       'ford tourneo connect', 'ford tourneo courier', 'genesis g70',\n",
    "       'genesis g80', 'genesis gv70', 'genesis gv80', 'gmc sierra',\n",
    "       'gmc terrain', 'gmc yukon xl', 'honda accord', 'honda city',\n",
    "       'honda civic', 'honda cr v', 'honda e', 'honda hr v',\n",
    "       'honda jazz fit', 'honda nsx', 'honda odyssey', 'honda s',\n",
    "       'hummer h2', 'hyundai getz', 'hyundai i10', 'hyundai i20',\n",
    "       'hyundai i30', 'hyundai i40', 'hyundai ioniq', 'hyundai ioniq 5',\n",
    "       'hyundai ix20', 'hyundai kona', 'hyundai nexo', 'hyundai santa fe',\n",
    "       'hyundai tiburon', 'hyundai tucson', 'hyundai veloster',\n",
    "       'infinity fx', 'infinity q30', 'infiniti q50 sedan',\n",
    "       'infinity qx80', 'isuzu d max', 'jac refine e s2', 'jaguar e pace',\n",
    "       'jaguar e type', 'jaguar f pace', 'jaguar f type', 'jaguar i pace',\n",
    "       'jaguar x type', 'jaguar xe', 'jaguar xf', 'jaguar xj',\n",
    "       'jaguar xk', 'jaguar xk120', 'jeep cherokee', 'jeep compass',\n",
    "       'jeep wrangler', 'jeep grand cherokee', 'jeep renegade',\n",
    "       'kia carens', 'kia ceed', 'kia ev6', 'kia magentis', 'kia niro',\n",
    "       'kia picanto', 'kia rio', 'kia sorento', 'kia soul',\n",
    "       'kia sportage', 'kia stinger', 'kia stonic', 'kia venga',\n",
    "       'lada 2102', 'lada 4x4', 'lamborghini aventador',\n",
    "       'lamborghini huracan', 'lamborghini urus', 'lancia delta',\n",
    "       'lancia phedra', 'lancia ypsilon', 'land rover defender',\n",
    "       'land rover discovery', 'land rover discovery sport',\n",
    "       'land rover freelander', 'land rover range rover',\n",
    "       'land rover range rover evoque', 'land rover range rover sport',\n",
    "       'land rover range rover velar', 'lexus ct', 'lexus gs', 'lexus is',\n",
    "       'lexus ls', 'lexus lx', 'lexus nx', 'lexus rx', 'lexus sc',\n",
    "       'lexus ux', 'lincoln mkx', 'lincoln navigator', 'lincoln town car',\n",
    "       'lotus elan', 'lotus elise', 'maserati ghibli',\n",
    "       'maserati granturismo', 'maserati levante',\n",
    "       'maserati quattroporte', 'maybach 57', 'mazda 2', 'mazda 3',\n",
    "       'mazda 5', 'mazda 6', 'mazda cx 3', 'mazda cx 30', 'mazda cx 5',\n",
    "       'mazda cx 7', 'mazda cx 9', 'mazda mx 30', 'mazda mx 5',\n",
    "       'mclaren 12c', 'mclaren 650s', 'mclaren 720s', 'mercedes-benz 123',\n",
    "       'mercedes-benz 170 s', 'mercedes-benz 220', 'mercedes-benz 220 s',\n",
    "       'mercedes-benz a class', 'mercedes-benz amg gt', 'mercedes-benz b class',\n",
    "       'mercedes-benz c class', 'mercedes-benz citan', 'mercedes-benz cl class',\n",
    "       'mercedes-benz cla class', 'mercedes-benz clk class', 'mercedes-benz cls class',\n",
    "       'mercedes-benz e class', 'mercedes-benz 3', 'mercedes-benz eqa',\n",
    "       'mercedes-benz eqc class', 'mercedes-benz eqs class', 'mercedes-benz g class',\n",
    "       'mercedes-benz gl class', 'mercedes-benz gla class', 'mercedes-benz glb class',\n",
    "       'mercedes-benz glc class', 'mercedes-benz gle class', 'mercedes-benz glk class',\n",
    "       'mercedes-benz gls class', 'mercedes-benz m class', 'mercedes-benz r class',\n",
    "       'mercedes-benz s class', 'mercedes-benz sl', 'mercedes-benz slk',\n",
    "       'mercedes-benz v class', 'mercedes-benz vito', 'mercedes-benz w114',\n",
    "       'mercedes-benz x class', 'mercury cougar', 'mg f', 'mg mgb', 'mg tf',\n",
    "       'mini clubman', 'mini cooper', 'mini countryman', 'mini paceman',\n",
    "       'mitsubishi asx', 'mitsubishi colt', 'mitsubishi i miev',\n",
    "       'mitsubishi l200', 'mitsubishi lancer', 'mitsubishi mirage',\n",
    "       'mitsubishi outlander', 'mitsubishi pajero', 'moskvitch 400',\n",
    "       'nissan 370z', 'nissan altima', 'nissan juke', 'nissan leaf',\n",
    "       'nissan micra', 'nissan murano', 'nissan navara', 'nissan note',\n",
    "       'nissan nv200', 'nissan pathfinder', 'nissan pixo',\n",
    "       'nissan qashqai', 'nissan x trail', 'oldsmobile 88',\n",
    "       'oldsmobile cutlass supreme', 'vauxhall adam', 'vauxhall agila',\n",
    "       'vauxhall ampera', 'vauxhall astra', 'vauxhall calibra', 'vauxhall cascada',\n",
    "       'vauxhall corsa', 'vauxhall crossland x', 'vauxhall grandland',\n",
    "       'vauxhall insignia', 'vauxhall karl', 'vauxhall meriva', 'vauxhall mokka',\n",
    "       'vauxhall tigra', 'vauxhall vectra', 'vauxhall zafira', 'peugeot 1007',\n",
    "       'peugeot 108', 'peugeot 206', 'peugeot 207', 'peugeot 208', 'peugeot 2008'\n",
    "       'peugeot 3008', 'peugeot 306', 'peugeot 307', 'peugeot 308',\n",
    "       'peugeot 4007', 'peugeot 4008', 'peugeot 406', 'peugeot 407',\n",
    "       'peugeot 5008', 'peugeot 508', 'peugeot 807', 'peugeot expert',\n",
    "       'peugeot partner', 'peugeot traveller', 'plymouth volare',\n",
    "       'polestar 2', 'pontiac firebird', 'pontiac gto', 'porsche 356',\n",
    "       'porsche 718', 'porsche 718 cayman', 'porsche 911', 'porsche 928',\n",
    "       'porsche cayenne 5 door coupe suv', 'porsche cayenne',\n",
    "       'porsche macan', 'porsche panamera', 'porsche taycan',\n",
    "       'renault captur', 'renault clio', 'renault espace',\n",
    "       'renault fluence', 'renault fuego', 'renault kadjar',\n",
    "       'renault kangoo', 'renault koleos', 'renault laguna',\n",
    "       'renault megane', 'renault modus', 'renault scenic',\n",
    "       'renault talisman', 'renault twingo', 'renault twizy',\n",
    "       'renault zoe', 'rolls-royce corniche', 'rolls-royce cullinan',\n",
    "       'rolls-royce ghost', 'rolls-royce phantom',\n",
    "       'rolls-royce silver shadow', 'rolls-royce silver spirit',\n",
    "       'rolls-royce wraith', 'rover sd1', 'saab 9 3', 'saab 9 5',\n",
    "       'seat alhambra', 'seat altea', 'seat arona', 'seat ateca',\n",
    "       'seat exeo', 'seat ibiza', 'seat leon', 'seat mii', 'seat tarraco',\n",
    "       'skoda citigo', 'skoda enyaq iv', 'skoda fabia', 'skoda kamiq',\n",
    "       'skoda karoq', 'skoda kodiaq', 'skoda octavia', 'skoda rapid',\n",
    "       'skoda scala', 'skoda superb', 'skoda yeti', 'smart forfour',\n",
    "       'smart fortwo', 'smart roadster', 'ssang yong korando',\n",
    "       'ssang yong kyron', 'ssang yong rexton', 'ssang yong tivoli',\n",
    "       'subaru forester', 'subaru impreza', 'subaru justy',\n",
    "       'subaru legacy', 'subaru levorg', 'subaru outback',\n",
    "       'subaru xv crosstrek', 'suzuki across', 'suzuki ignis',\n",
    "       'suzuki jimny', 'suzuki liana', 'suzuki swift', 'suzuki sx4',\n",
    "       'suzuki vitara', 'tatra 603', 'tesla model 3', 'tesla model s',\n",
    "       'tesla model x', 'tesla model y', 'toyota auris', 'toyota avensis',\n",
    "       'toyota aygo', 'toyota c hr', 'toyota celica', 'toyota corolla',\n",
    "       'toyota corolla verso', 'toyota gt 86', 'toyota highlander',\n",
    "       'toyota hilux', 'toyota iq', 'toyota land cruiser prado',\n",
    "       'toyota landcruiser', 'toyota previa', 'toyota prius',\n",
    "       'toyota prius plus', 'toyota proace verso', 'toyota rav4',\n",
    "       'toyota sienna', 'toyota supra', 'toyota tundra',\n",
    "       'toyota urban cruiser', 'toyota verso', 'toyota yaris',\n",
    "       'toyota yaris cross', 'triumph spitfire', 'triumph tr7',\n",
    "       'tvr cerbera', 'volkswagen 1600', 'volkswagen amarok',\n",
    "       'volkswagen arteon', 'volkswagen beetle', 'volkswagen bora',\n",
    "       'volkswagen caddy', 'volkswagen california',\n",
    "       'volkswagen caravelle', 'volkswagen eos', 'volkswagen fox',\n",
    "       'volkswagen golf', 'volkswagen id3', 'volkswagen id4',\n",
    "       'volkswagen jetta', 'volkswagen passat', 'volkswagen passat cc',\n",
    "       'volkswagen phaeton', 'volkswagen polo', 'volkswagen scirocco',\n",
    "       'volkswagen sharan', 'volkswagen t cross', 'volkswagen t roc',\n",
    "       'volkswagen tiguan', 'volkswagen touareg', 'volkswagen touran',\n",
    "       'volkswagen up', 'volvo 780', 'volvo 900', 'volvo c30',\n",
    "       'volvo s60', 'volvo s80', 'volvo s90', 'volvo v40', 'volvo v50',\n",
    "       'volvo v60', 'volvo v70', 'volvo v90', 'volvo xc40', 'volvo xc60',\n",
    "       'volvo xc70', 'volvo xc90', 'wartburg 353']\n",
    "\n",
    "\n",
    "results = []\n",
    "for index, car in necars.iterrows():\n",
    "    lname = car[-1]\n",
    "    dummy = lname\n",
    "    for cname in name_list_from_carsized:\n",
    "        if cname in lname:\n",
    "            dummy = cname\n",
    "    for bod in body:\n",
    "        if bod in dummy:\n",
    "            dummy = re.sub(' '+bod,'',dummy)\n",
    "    results.append(dummy)\n",
    "\n",
    "necars['name']=results\n",
    "necars=necars.drop('lname', axis=1)\n",
    "\n",
    "necars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c6ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:21.568903Z",
     "start_time": "2022-03-03T21:23:21.516173Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Output clean used cars data \n",
    "necars=necars[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','dealer_area','dealer_city','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0']]\n",
    "necars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_clean_new_electric_cars.csv'\n",
    "necars.to_csv(necars_abspath, index=False, header=necars.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37e1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:21.586617Z",
     "start_time": "2022-03-03T21:23:21.571248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "necars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f1bcb",
   "metadata": {},
   "source": [
    "# Combine dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83abfbb2",
   "metadata": {},
   "source": [
    "## Combine input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be26c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:25.038339Z",
     "start_time": "2022-03-03T21:23:21.589628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read and cat clean cars data \n",
    "\n",
    "path = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/'\n",
    "car_dataframes = [ucars_abspath, ncars_abspath, necars_abspath, uecars_abspath]\n",
    "li=[]\n",
    "for filename in car_dataframes:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0 )\n",
    "    df.drop_duplicates(subset=['link'], keep='first', inplace=True)\n",
    "    li.append(df)\n",
    "\n",
    "cars = pd.concat(li, axis=0, ignore_index=True)\n",
    "cars.drop_duplicates(subset=['id'], keep='first', inplace=True)\n",
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2d3ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:25.045516Z",
     "start_time": "2022-03-03T21:23:25.040096Z"
    }
   },
   "outputs": [],
   "source": [
    "car_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348f659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:25.338801Z",
     "start_time": "2022-03-03T21:23:25.048260Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ac440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:31.912237Z",
     "start_time": "2022-03-03T21:23:25.342219Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Output all cars data - still containsa a few NaNs\n",
    "cars=cars[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','dealer_area','dealer_city','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0']]\n",
    "cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "cars.to_csv(cars_abspath, index=False, header=cars.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33de7d",
   "metadata": {},
   "source": [
    "## Join county, latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d65bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:32.372876Z",
     "start_time": "2022-03-03T21:23:31.914675Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import all latlon files and make ll dataframe \n",
    "\n",
    "path = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/latlon/'\n",
    "\n",
    "li=[]\n",
    "files = glob.glob(path + f\"/*.csv\")\n",
    "for filename in files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0 )\n",
    "    li.append(df)\n",
    "\n",
    "ll = pd.concat(li, axis=0, ignore_index=True)\n",
    "ll.drop_duplicates(subset=['id'], keep='first', inplace=True)\n",
    "ll = ll[['id','dealer_lat','dealer_lon']]\n",
    "ll.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b122372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:33.405749Z",
     "start_time": "2022-03-03T21:23:32.375939Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Merge cars and ll df on 'id'\n",
    "\n",
    "cars = pd.merge(\n",
    "    cars,\n",
    "    ll,\n",
    "    how=\"left\",\n",
    "    on='id',\n",
    "    sort=False,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59543522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:33.720678Z",
     "start_time": "2022-03-03T21:23:33.408205Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2b263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:33.740968Z",
     "start_time": "2022-03-03T21:23:33.723869Z"
    }
   },
   "outputs": [],
   "source": [
    "counties = pd.read_csv('/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/04_merge_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fafa712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:33.750283Z",
     "start_time": "2022-03-03T21:23:33.744238Z"
    }
   },
   "outputs": [],
   "source": [
    "counties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801faf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:33.758537Z",
     "start_time": "2022-03-03T21:23:33.753268Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea998e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:34.377320Z",
     "start_time": "2022-03-03T21:23:33.761703Z"
    }
   },
   "outputs": [],
   "source": [
    "cars['dealer_lat_rnd']=cars.dealer_lat.apply(lambda x: round(x,5))\n",
    "cars['dealer_lon_rnd']=cars.dealer_lon.apply(lambda x: round(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07e4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:34.712029Z",
     "start_time": "2022-03-03T21:23:34.379379Z"
    }
   },
   "outputs": [],
   "source": [
    "cars = pd.merge(\n",
    "    cars,\n",
    "    counties,\n",
    "    how=\"left\",\n",
    "    left_on=['dealer_lat_rnd','dealer_lon_rnd'],\n",
    "    right_on=['dealer_lat_rnd','dealer_lon_rnd'],\n",
    "    sort=False,\n",
    "    suffixes=(\"\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de30b93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:35.101376Z",
     "start_time": "2022-03-03T21:23:34.716787Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5a0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:35.496204Z",
     "start_time": "2022-03-03T21:23:35.104635Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.drop(labels=['dealer_lat_rnd', 'dealer_lon_rnd', 'original_ll',\n",
    "       'dealer_lat_y', 'dealer_lon_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d2db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:55.414132Z",
     "start_time": "2022-03-03T21:23:35.498539Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Add shortest postcode column\n",
    "postcode_shortest = []\n",
    "for index, car in cars.iterrows():\n",
    "    try: \n",
    "        postcode_shortest.append(re.findall('[A-Z][A-Z]?', car[-3])[0])\n",
    "    except: \n",
    "        postcode_shortest.append('no result')\n",
    "        \n",
    "cars['postcode_shortest']=postcode_shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411348a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:55.421450Z",
     "start_time": "2022-03-03T21:23:55.416764Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ceeed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:23:55.457395Z",
     "start_time": "2022-03-03T21:23:55.424771Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.county.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afc053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:04.740891Z",
     "start_time": "2022-03-03T21:23:55.459496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output all cars data with lat&lon - still containsa a few NaNs\n",
    "cars=cars[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','county','dealer_area','dealer_city'\n",
    "            ,'dealer_lat','dealer_lon','geocode'\n",
    "            ,'county', 'postcode', 'postcode_short','postcode_shortest','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0']]\n",
    "cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "cars.to_csv(cars_abspath, index=False, header=cars.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e8704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:05.993157Z",
     "start_time": "2022-03-03T21:24:04.743742Z"
    }
   },
   "outputs": [],
   "source": [
    "tableaudf= cars.sample(50000, random_state=1)\n",
    "tableau_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/06_tableau_50000_cars.csv'\n",
    "tableaudf.to_csv(tableau_abspath, index=False, header=tableaudf.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:06.458459Z",
     "start_time": "2022-03-03T21:24:05.995829Z"
    }
   },
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8ee90",
   "metadata": {},
   "source": [
    "## Condition the EV charging .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34925ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:06.887733Z",
     "start_time": "2022-03-03T21:24:06.476164Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import big ugly chargepoint file. Trim to relevant columns.\n",
    "\n",
    "filename = '/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/national-charge-point-registry.csv'\n",
    "charge_points = pd.read_csv(filename, index_col=None, header=0, lineterminator='\\n')\n",
    "\n",
    "charge_points=charge_points[['town','county','latitude','longitude','postcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22655d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:06.961791Z",
     "start_time": "2022-03-03T21:24:06.890125Z"
    }
   },
   "outputs": [],
   "source": [
    "charge_points_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_charge_points.csv'\n",
    "charge_points.to_csv(charge_points_abspath, index=False, header=charge_points.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec097b60",
   "metadata": {},
   "source": [
    "## Merging the car size details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e789f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:06.967782Z",
     "start_time": "2022-03-03T21:24:06.964304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Could review carsized notebook here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ba2c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:29.299545Z",
     "start_time": "2022-03-03T21:24:06.971746Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Read all car data \n",
    "\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "dfcars = pd.read_csv(abspath)\n",
    "\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_carsized_dims_for_merge.csv'\n",
    "dfsize = pd.read_csv(abspath)\n",
    "\n",
    "\n",
    "match_name=[]\n",
    "for index, car in dfcars.iterrows():\n",
    "    name = car[0]\n",
    "    name = name.replace('series','')\n",
    "    name = name.replace('-',' ')\n",
    "    name = name.replace('class','')\n",
    "    name = name.replace('hatch','cooper')\n",
    "    name = name.replace('mini','mini cooper')\n",
    "    name = name.replace('cooper cooper','cooper')\n",
    "    name = name.replace('cooper clubman','clubman')\n",
    "    name = name.replace('cooper countryman','countryman')\n",
    "    name = name.replace('jazz','jazz fit')\n",
    "    name = name.strip()\n",
    "    name = name.replace('mercedes benz','mercedes-benz')\n",
    "    match_name.append(name)\n",
    "dfcars['match_name']=match_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee16a1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:29.308787Z",
     "start_time": "2022-03-03T21:24:29.302349Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06eb321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:30.889785Z",
     "start_time": "2022-03-03T21:24:29.311269Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Merge dfcars with dfsize on \n",
    "\n",
    "cars_size = pd.merge(\n",
    "    dfcars,\n",
    "    dfsize,\n",
    "    how=\"left\",\n",
    "    left_on=['match_name','body','year'],\n",
    "    right_on=['name','body','year'],\n",
    "    sort=False,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    ")\n",
    "\n",
    "cars_size.drop_duplicates(subset='id', keep='first',inplace=True)\n",
    "print('All data size',cars_size.shape)\n",
    "\n",
    "failed_match = cars_size[cars_size.cargo_volume_L.isnull()].copy()\n",
    "failed_match.drop_duplicates(subset='id', keep='first',inplace=True)\n",
    "print('Null cargo data size',failed_match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265edc90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:30.951108Z",
     "start_time": "2022-03-03T21:24:30.891403Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are a few failed matches, but at this stage I have to let it go. If I was being paid I could fix these.\n",
    "failed_match[failed_match.cargo_volume_L.isnull()].match_name.value_counts(dropna=False).head(50)\n",
    "failed_match[failed_match.match_name=='bmw 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3aba43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:30.967106Z",
     "start_time": "2022-03-03T21:24:30.954021Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Failed match value counts\n",
    "failed_match['name_x'].value_counts(dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55133be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:30.975066Z",
     "start_time": "2022-03-03T21:24:30.969830Z"
    }
   },
   "outputs": [],
   "source": [
    "# cars_size shape before dropping nans\n",
    "cars_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ca2fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:31.713320Z",
     "start_time": "2022-03-03T21:24:30.977726Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# cars_size shape after dropping nans\n",
    "\n",
    "cars_size.dropna(subset = ['cargo_volume_L'], inplace=True)\n",
    "cars_size.dropna(subset = ['dealer_lat'], inplace=True)\n",
    "cars_size.dropna(subset = ['dealer_lon'], inplace=True)\n",
    "cars_size.dropna(subset = ['county'], inplace=True)\n",
    "\n",
    "cars_size = cars_size[cars_size.cargo_volume_L!=0.0].copy()\n",
    "cars_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f0326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:31.721125Z",
     "start_time": "2022-03-03T21:24:31.715571Z"
    }
   },
   "outputs": [],
   "source": [
    "cars_size.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128e403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:40.254206Z",
     "start_time": "2022-03-03T21:24:31.722900Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Output all cars data with lat&lon and volume stats - still containsa a few NaNs - dealer_area could be better\n",
    "\n",
    "cars_size.columns = ['name', 'name_subtitle', 'year', 'price', 'body', 'mileage', 'BHP',\n",
    "       'doors', 'transmission', 'make', 'fuel', 'mpg', 'drivertrain', 'engine',\n",
    "       'owners', 'ULEZ', 'county', 'dealer_area', 'dealer_city', 'dealer_lat',\n",
    "       'dealer_lon', 'geocode', 'county', 'postcode', 'postcode_short','postcode_shortest',\n",
    "       'seller1', 'used', 'e_engine_kWh', 'log_price', 'log_mileage',\n",
    "       'orig_name', 'id', 'year_reg', 'link', 'href0', 'match_name', 'name_y',\n",
    "       'wheelbase_cm', 'length_cm', 'width_cm', 'height_cm',\n",
    "       'ground_clearance_cm', 'cargo_volume_L', 'max_cargo_volume_L']\n",
    "\n",
    "cars_size=cars_size[['name','name_subtitle','year','price','body','mileage','BHP','doors'\n",
    "            ,'transmission','make','fuel','mpg','drivertrain','engine','owners'\n",
    "            ,'ULEZ','dealer_area','dealer_city','geocode', 'county', 'postcode', 'postcode_short','postcode_shortest'\n",
    "            ,'dealer_lat','dealer_lon','seller1','used', 'e_engine_kWh'\n",
    "            ,'log_price','log_mileage','orig_name','id','year_reg','link','href0'\n",
    "            ,'wheelbase_cm', 'length_cm', 'width_cm'\n",
    "            ,'height_cm', 'ground_clearance_cm', 'cargo_volume_L']]\n",
    "cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "cars_size.to_csv(cars_abspath, index=False, header=cars_size.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5a163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:40.591592Z",
     "start_time": "2022-03-03T21:24:40.256054Z"
    }
   },
   "outputs": [],
   "source": [
    "cars_size.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60b123",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EDA on used cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d961271",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pretty general interest plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99696302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:44.097883Z",
     "start_time": "2022-03-03T21:24:40.593828Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Read clean used cars data \n",
    "\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "df = pd.read_csv(abspath)\n",
    "print('All cars',df.shape)\n",
    "df = df[df['used']==1]\n",
    "print('Used cars',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7f554-9c5c-49cc-99d6-54c7fbeaa7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:44.973919Z",
     "start_time": "2022-03-03T21:24:44.100480Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot of make frequency \n",
    "\n",
    "df.groupby(by='make')['name'].count().sort_values(ascending=False).head(30).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(16,6))\n",
    "sns.barplot(x=\"make\", y=\"name\", data=df.groupby(by='make')['name'].count().sort_values(ascending=False).head(30).reset_index()\n",
    "            ,palette='husl').set_title('Top 30 most common used cars brands for sale on AutoTrader')\n",
    "ax.set_xlabel('Make')\n",
    "ax.set_ylabel('Count')\n",
    "ax.tick_params(axis='x', rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.savefig('carbrandcount.pdf',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a23a7",
   "metadata": {},
   "source": [
    "*94% of cars can be described by the top 23 makes - should I drop the other 40? Tbc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f973748-d1b0-4652-b1c2-02488b1fa4a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:48.311619Z",
     "start_time": "2022-03-03T21:24:44.975982Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot of pridce distributions by categorical variables - remove outliers first \n",
    "\n",
    "dfo=df.copy()\n",
    "mask = np.abs((dfo.log_price - dfo.log_price.mean(0)) / dfo.log_price.std(0)) > 3\n",
    "dfo= dfo[~mask]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, figsize=(16,15))\n",
    "sns.histplot(data=dfo[dfo.year>2020], x=\"log_price\",hue=\"body\",palette='husl',bins=50, legend=True, ax=ax[0]).set_title('Distribution of log-price by body type for cars < 2 years old')\n",
    "ax[0].set_xlabel('Log-price (£)')\n",
    "ax[0].set_ylabel('Count')\n",
    "sns.histplot(data=dfo[dfo.year>2020], x=\"log_price\",hue=\"transmission\",palette='husl',bins=50, legend=True, ax=ax[1]).set_title('Distribution of log-price by transmission type for cars < 2 years old')\n",
    "ax[1].set_xlabel('Log-price (£)')\n",
    "ax[1].set_ylabel('Count')\n",
    "sns.histplot(data=dfo[dfo.year>2020], x=\"log_price\",hue=\"fuel\",palette='husl',bins=50, legend=True, ax=ax[2]).set_title('Distribution of log-price by fuel type for cars < 2 years old')\n",
    "ax[2].set_xlabel('Log-price (£)')\n",
    "ax[2].set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae134d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:49.960346Z",
     "start_time": "2022-03-03T21:24:48.313154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of pridce distributions by categorical variables - remove outliers first \n",
    "\n",
    "dfo=df.copy()\n",
    "mask = np.abs((dfo.log_price - dfo.log_price.mean(0)) / dfo.log_price.std(0)) > 3\n",
    "dfo= dfo[~mask]\n",
    "dfo['drivetrain']=dfo.drivertrain\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.histplot(data=dfo[dfo.year>2020], x=\"price\",hue=\"drivertrain\",palette='husl',bins=50, legend=True, ax=ax).set_title('Distribution of price by drivetrain type ')\n",
    "ax.set_xlabel('Price (£)')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('drivetraindist.pdf',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ce230",
   "metadata": {},
   "source": [
    "*In these three categorical variables presented it looks like transmission variable provides the best information on car price. Automatic cars are clearly more expensive than manual cars.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7c88f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:50.657169Z",
     "start_time": "2022-03-03T21:24:49.962319Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot of avergae price and mileage figures for categorical variables - Failed \n",
    "\n",
    "plotdf1 = df[df.year>2020].groupby(by='fuel')[['price','mileage']].mean().reset_index()\n",
    "plotdf1 = plotdf1[plotdf1.fuel!='Bi Fuel']\n",
    "plotdf2 = df[df.year>2020].groupby(by='transmission')[['price','mileage']].mean().reset_index()\n",
    "plotdf3 = df[df.year>2020].groupby(by='body')[['price','mileage']].mean().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.scatterplot(data=plotdf1, x=\"price\", y=\"mileage\", hue=\"fuel\",palette='husl', marker='s').set_title('Average mileage and average price by fuel type')\n",
    "sns.scatterplot(data=plotdf2, x=\"price\", y=\"mileage\", hue=\"transmission\",palette='husl', marker='d').set_title('Average mileage and average price by transmission type')\n",
    "sns.scatterplot(data=plotdf3, x=\"price\", y=\"mileage\", hue=\"body\",palette='husl', marker='X').set_title('Average mileage and average price by body type')\n",
    "ax.set_xlabel('Mean price (£)')\n",
    "ax.set_ylabel('Mean mileage (miles)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_ylim(3000,7000)\n",
    "ax.set_xlim(15000,60000)\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52190661",
   "metadata": {},
   "source": [
    "*This plot hasn't really worked - I wanted to get the shape of the marker in the legend but no luck. The plots below are broken up and detail it better.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e5625-04fb-462c-81a1-f6da559288e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:51.998063Z",
     "start_time": "2022-03-03T21:24:50.658799Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot of avergae price and mileage figures for categorical variables\n",
    "\n",
    "plotdf1 = df[df.year>2020].groupby(by='fuel')[['price','mileage','doors']].agg({'price':'mean', 'mileage':'mean','doors':'count'}).reset_index()\n",
    "plotdf1 = plotdf1[plotdf1.fuel!='Bi Fuel']\n",
    "plotdf1.columns = ['Fuel','price','mileage','Count']\n",
    "plotdf2 = df[df.year>2020].groupby(by='transmission')[['price','mileage','doors']].agg({'price':'mean', 'mileage':'mean','doors':'count'}).reset_index()\n",
    "plotdf2.columns = ['Transmission','price','mileage','Count']\n",
    "\n",
    "plotdf3 = df[df.year>2020].groupby(by='body')[['price','mileage','doors']].agg({'price':'mean', 'mileage':'mean','doors':'count'}).reset_index()\n",
    "plotdf3.columns = ['Body','price','mileage','Count']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3,figsize=(10,15))\n",
    "sns.scatterplot(data=plotdf1, x=\"price\", y=\"mileage\", hue=\"Fuel\", size='Count',\n",
    "                sizes=(300, 1500), alpha=.5,palette='husl', ax=ax[2], \n",
    "                ).set_title('Average mileage and average price by fuel type for cars < 2 years old')\n",
    "ax[2].set_xlabel('Mean price (£)')\n",
    "ax[2].set_ylabel('Mean mileage')\n",
    "sns.scatterplot(data=plotdf2, x=\"price\", y=\"mileage\", hue=\"Transmission\",\n",
    "                size='Count',sizes=(300, 1500), alpha=.5,palette='husl', ax=ax[1], \n",
    "                ).set_title('Average mileage and average price by transmission type for cars < 2 years old')\n",
    "ax[1].set_xlabel('Mean price (£)')\n",
    "ax[1].set_ylabel('Mean mileage')\n",
    "sns.scatterplot(data=plotdf3, x=\"price\", y=\"mileage\", hue=\"Body\",size='Count',\n",
    "                sizes=(300, 1500), alpha=.5,palette='husl', ax=ax[0], \n",
    "                ).set_title('Average mileage and average price by body type for cars < 2 years old')\n",
    "ax[0].set_xlabel('Mean price (£)')\n",
    "ax[0].set_ylabel('Mean mileage')\n",
    "for i in range(0,3):\n",
    "    ax[i].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax[i].set_ylim(3000,7000)\n",
    "    ax[i].set_xlim(15000,60000)\n",
    "    ax[i].tick_params(axis='x', rotation=30)   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fadacd",
   "metadata": {},
   "source": [
    "*I don't really like these plots much. I was trying to show where the average car in each of these categories lies in terms of price and mileage. I'm not sure if I should filter based on year or not.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86c62c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:56.907883Z",
     "start_time": "2022-03-03T21:24:51.999872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot top 16 car brands - outliers removed in log-space\n",
    "top15makes = list(df.make.value_counts().head(16).reset_index()['index'])\n",
    "plotdf1 = df[df.make.isin(top15makes)]\n",
    "# Remove outliers from log_price data - check this\n",
    "mask = np.abs((plotdf1.log_price - plotdf1.log_price.mean(0)) / plotdf1.log_price.std(0)) > 3\n",
    "plotdf1= plotdf1[~mask]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 1, figsize=(16,20))\n",
    "sns.boxplot(x='make', y='price', data=plotdf1, ax=ax[0],palette='husl').set_title('Make vs Price for 16 most common used cars')\n",
    "ax[0].set_xlabel('Make')\n",
    "ax[0].set_ylabel('Price (£)')\n",
    "sns.boxplot(x='make', y='log_price', data=plotdf1,ax=ax[1],palette='husl').set_title('Make vs Log-Price for 16 most common used cars')\n",
    "ax[1].set_xlabel('Make')\n",
    "ax[1].set_ylabel('Log-Price (£)')\n",
    "sns.barplot(x=\"make\", y=\"price\", data=plotdf1, ax=ax[2],palette='husl').set_title('Make vs average Price for 16 most common used cars')\n",
    "ax[2].set_xlabel('Make')\n",
    "ax[2].set_ylabel('Price (£)')\n",
    "for i in range(0,3):\n",
    "    ax[i].tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a16449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:24:58.137381Z",
     "start_time": "2022-03-03T21:24:56.909470Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot top 16 car brands - outliers removed in log-space\n",
    "top15makes = list(df.make.value_counts().head(16).reset_index()['index'])\n",
    "plotdf1 = df[df.make.isin(top15makes)]\n",
    "# Remove outliers from log_price data - check this\n",
    "mask = np.abs((plotdf1.log_price - plotdf1.log_price.mean(0)) / plotdf1.log_price.std(0)) > 3\n",
    "plotdf1= plotdf1[~mask]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(16,6))\n",
    "sns.boxplot(x='make', y='price', data=plotdf1, ax=ax,palette='husl').set_title('Car brand vs price for 16 most common used cars')\n",
    "ax.set_xlabel('Make')\n",
    "ax.set_ylabel('Price (£)')\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig('branddist.pdf',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ec0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:25:03.651668Z",
     "start_time": "2022-03-03T21:24:58.139768Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot by body type - outliers removed in log-space\n",
    "\n",
    "# Remove outliers from log_price data - check this\n",
    "mask = np.abs((df.log_price - df.log_price.mean(0)) / df.log_price.std(0)) > 3\n",
    "plotdf2= df[~mask]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 1, figsize=(16,20))\n",
    "sns.color_palette(\"husl\", 8)\n",
    "sns.boxplot(x='body', y='price', data=plotdf2, ax=ax[0], palette='husl').set_title('Body vs Price')\n",
    "ax[0].set_xlabel('Body')\n",
    "ax[0].set_ylabel('Price (£)')\n",
    "sns.boxplot(x='body', y='log_price', data=plotdf2,ax=ax[1],palette='husl').set_title('Body vs Log-Price')\n",
    "ax[1].set_xlabel('Body')\n",
    "ax[1].set_ylabel('Log-Price (£)')\n",
    "sns.barplot(x=\"body\", y=\"price\", data=plotdf2, ax=ax[2],palette='husl').set_title('Body vs average Price')\n",
    "ax[2].set_xlabel('Body')\n",
    "ax[2].set_ylabel('Price (£)')\n",
    "for i in range(0,3):\n",
    "    ax[i].tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946614b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:25:03.762426Z",
     "start_time": "2022-03-03T21:25:03.653494Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Checking outlier code\n",
    "f= df[df.year==2013].sort_values(by='log_price',ascending=False).head(1)\n",
    "for index, car in f.iterrows():\n",
    "    print(car)\n",
    "    print(car[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9340cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:25:09.778691Z",
     "start_time": "2022-03-03T21:25:03.764720Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot by year - outliers removed in log-space \n",
    "\n",
    "# Remove outliers from log_price data - check this\n",
    "mask = np.abs((df.log_price - df.log_price.mean(0)) / df.log_price.std(0)) > 3\n",
    "plotdf2= df[~mask]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 1, figsize=(16,20))\n",
    "sns.boxplot(x='year', y='price', data=plotdf2, ax=ax[0]).set_title('Year vs Price')\n",
    "ax[0].set_xlabel('Year')\n",
    "ax[0].set_ylabel('Price (£)')\n",
    "sns.boxplot(x='year', y='log_price', data=plotdf2,ax=ax[1]).set_title('Year vs Log-Price')\n",
    "ax[1].set_xlabel('Year')\n",
    "ax[1].set_ylabel('Log-Price (£)')\n",
    "sns.barplot(x=\"year\", y=\"price\", data=plotdf2, ax=ax[2]).set_title('Year vs average Price')\n",
    "ax[2].set_xlabel('Year')\n",
    "ax[2].set_ylabel('Price (£)')\n",
    "for i in range(0,3):\n",
    "    ax[i].tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea63fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:25:14.554452Z",
     "start_time": "2022-03-03T21:25:09.780834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot by year - outliers removed in log-space \n",
    "\n",
    "# Remove outliers from log_price data - check this\n",
    "mask = np.abs((df.log_price - df.log_price.mean(0)) / df.log_price.std(0)) > 3\n",
    "plotdf2= df[~mask]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize=(16,6))\n",
    "sns.barplot(x=\"year\", y=\"price\", data=plotdf2, ax=ax).set_title('Car year produced vs average price')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Price (£)')\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig('yearprice.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba54008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:25:14.612373Z",
     "start_time": "2022-03-03T21:25:14.556076Z"
    }
   },
   "outputs": [],
   "source": [
    "plotdf2[plotdf2['drivertrain']=='Rear Wheel Drive'].name.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a97a4",
   "metadata": {},
   "source": [
    "*These plots help describe the relationship between price and age of a car. It can be seen to decease as the car year approaches 2003, before a slight increase in average price. This must be the vintage car factor being introduced. Note that confidence bounds are wider for newer cars and older cars as the sample size within each year is greatly reduced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749c5e",
   "metadata": {},
   "source": [
    "## Distribution and collinearity evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b06b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:33:41.271688Z",
     "start_time": "2022-03-04T12:33:41.221824Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bafad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:26:57.278882Z",
     "start_time": "2022-03-03T21:26:53.050476Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seaborn plots of continuous variables\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(12,16))\n",
    "sns.histplot(data=df.price, bins=60, color='skyblue',ax=ax[0,0]).set_title('Price distribution')\n",
    "sns.histplot(data=df.log_price, bins=60, color='skyblue',ax=ax[0,1]).set_title('Log of Price distribution')\n",
    "sns.histplot(data=df.mileage, bins=60, color='skyblue',ax=ax[1,0]).set_title('Mileage distribution')\n",
    "sns.histplot(data=df.log_mileage, bins=60, color='skyblue',ax=ax[1,1]).set_title('Log of Mileage distribution')\n",
    "sns.histplot(data=df.BHP, bins=60, color='skyblue',ax=ax[2,0]).set_title('BHP distribution')\n",
    "sns.histplot(data=df.BHP.apply(lambda x: np.log(x)), bins=60, color='skyblue',ax=ax[2,1]).set_title('Log of BHP distribution')\n",
    "sns.histplot(data=df.engine, bins=20, color='skyblue',ax=ax[3,0]).set_title('Engine size distribution (L)')\n",
    "sns.histplot(data=df.year, bins=22, color='skyblue',ax=ax[3,1]).set_title('Year distribution')\n",
    "ax[3,1].set_xlim(2000,2022)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503a877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:01.893992Z",
     "start_time": "2022-03-03T21:26:57.281189Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "dfplot= df[~mask]\n",
    "\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "dfplot= dfplot[~mask]\n",
    "\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "dfplot= dfplot[~mask]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(12,16))\n",
    "sns.histplot(data=dfplot.price, bins=60, color='skyblue',ax=ax[0,0]).set_title('Price distribution after outlier removal')\n",
    "sns.histplot(data=dfplot.log_price, bins=60, color='skyblue',ax=ax[0,1]).set_title('Log of Price distribution after outlier removal')\n",
    "sns.histplot(data=dfplot.mileage, bins=60, color='skyblue',ax=ax[1,0]).set_title('Mileage distribution after outlier removal')\n",
    "sns.histplot(data=dfplot.log_mileage, bins=60, color='skyblue',ax=ax[1,1]).set_title('Log of Mileage distribution after outlier removal')\n",
    "sns.histplot(data=dfplot.BHP, bins=60, color='skyblue',ax=ax[2,0]).set_title('BHP distribution')\n",
    "sns.histplot(data=dfplot.BHP.apply(lambda x: np.log(x)), bins=60, color='skyblue',ax=ax[2,1]).set_title('Log of BHP distribution')\n",
    "sns.histplot(data=dfplot.engine, bins=20, color='skyblue',ax=ax[3,0]).set_title('Engine size distribution (L)')\n",
    "sns.histplot(data=dfplot.year, bins=22, color='skyblue',ax=ax[3,1]).set_title('Year distribution')\n",
    "ax[3,1].set_xlim(2000,2022)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438ff0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:02.260293Z",
     "start_time": "2022-03-03T21:27:01.895660Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deea96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:02.671272Z",
     "start_time": "2022-03-03T21:27:02.263086Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Heatmap before dummies\n",
    "\n",
    "tocorr=['log_price','log_mileage','year','engine','BHP','owners']\n",
    "plt.rcParams[\"figure.figsize\"] = (8,7)\n",
    "mask =np.zeros_like(df[tocorr].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(df[tocorr].corr(), vmin=-1, vmax=1, cmap='vlag', annot=True, mask=mask)\n",
    "plt.title('Heatmap before dummies added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96ef9c",
   "metadata": {},
   "source": [
    "*Looks like there's some significant correlation between engine and BHP. I don't want to use highly correlated predictors so I'm going to have to drop one - Engine. This is fortunate actually because engine units are inconsistent between electric cars and conventional cars. I will drop the engine column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85429bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:02.688897Z",
     "start_time": "2022-03-03T21:27:02.673312Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Checking for null values \n",
    "df[tocorr].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde26e3b",
   "metadata": {},
   "source": [
    "*As well as dropping the engine column, I'm going to have to drop the owners column. This just wasn't populated enough on AutoTrader and has 45% NaN values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efede237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:02.979403Z",
     "start_time": "2022-03-03T21:27:02.691444Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Heatmap after dropping engine and owners\n",
    "\n",
    "tocorr=['log_price','log_mileage','year','BHP']\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)\n",
    "mask =np.zeros_like(df[tocorr].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(df[tocorr].corr(), vmin=-1, vmax=1, cmap='vlag', annot=True, mask=mask)\n",
    "plt.title('Heatmap with final continuous variables for modelling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0d526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:03.243256Z",
     "start_time": "2022-03-03T21:27:02.981412Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Modelling without dummies  - assess VIF \n",
    "\n",
    "# Define X and y\n",
    "X = df[['log_mileage','year','BHP']]\n",
    "\n",
    "# Great link on multicollinearity\n",
    "# https://blog.minitab.com/en/understanding-statistics/handling-multicollinearity-in-regression-analysis\n",
    "\n",
    "# If VIF=1 then there's no multicollinearity\n",
    "# If VIF>5 then there's significant multicollinearity and it will be a problem\n",
    "\n",
    "Xvif = add_constant(X)\n",
    "VIF = pd.Series([variance_inflation_factor(Xvif.values, i) \n",
    "               for i in range(Xvif.shape[1])], \n",
    "              index=Xvif.columns)\n",
    "print('VIF stats: \\n',VIF,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb37cc",
   "metadata": {},
   "source": [
    "*The remaining continuous variables are not overly correlated. This bodes well for model building.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582564c-2cbe-413c-b08a-7695138555df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:34:05.979309Z",
     "start_time": "2022-03-04T12:34:05.974603Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf5e90-8b34-4360-929a-3c12da3082a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:05.056409Z",
     "start_time": "2022-03-03T21:27:03.252757Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chi2 stats for categorical variables\n",
    "results=[]\n",
    "categoricals = ['mpg','drivertrain','make','body','transmission','fuel','doors']\n",
    "for x in itertools.combinations(('mpg','drivertrain','make','body','transmission','fuel','doors'), 2):\n",
    "    categoricalv1 = x[0]\n",
    "    categoricalv2 = x[1]\n",
    "    cross_tab = pd.crosstab(df[categoricalv1], df[categoricalv2])\n",
    "    chi2 = stats.chi2_contingency(cross_tab)\n",
    "    results.append([x[0],x[1],chi2[0],round(chi2[1],4),chi2[2]])\n",
    "    chi2df = pd.DataFrame(results, columns = ['categorical1','categorical2','chi2_statistic','p-value','degrees_of_freedom'])\n",
    "\n",
    "chi2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0562ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:05.063031Z",
     "start_time": "2022-03-03T21:27:05.060556Z"
    }
   },
   "outputs": [],
   "source": [
    "# I NEED TO FIND A STATISTICAL REASON TO NOT USE THE MPG VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a972a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:05.099446Z",
     "start_time": "2022-03-03T21:27:05.065265Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('mpg')['BHP'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707c4f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:06.679671Z",
     "start_time": "2022-03-03T21:27:05.101188Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOTS OF DISTRIBUTION FOR MPG variable\n",
    "\n",
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unique_mpg = df['mpg'].unique()\n",
    "for mpg in unique_mpg:\n",
    "    stats.probplot(df[df['mpg'] == mpg]['log_price'], dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Probability Plot - \" +  mpg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0548a03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:07.553847Z",
     "start_time": "2022-03-03T21:27:06.682287Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Heatmap after dummies - choose the categorical  \n",
    "to_dummy=['mpg','drivertrain','make','body','transmission','fuel','doors']\n",
    "\n",
    "categorical = 'mpg'\n",
    "\n",
    "X = df[['log_price','log_mileage','year','BHP',categorical]]\n",
    "to_dummy=[categorical]\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,14)\n",
    "mask =np.zeros_like(X.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(X.corr(), vmin=-1, vmax=1, cmap='vlag', mask=mask, annot=True)\n",
    "plt.title(f'Continuous and {categorical} categorical heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdcb343",
   "metadata": {},
   "source": [
    "# Modeling on 50,000 used cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c9260",
   "metadata": {},
   "source": [
    "<b>EXECUTIVE SUMMARY</b>\n",
    "\n",
    "\n",
    "<b>1. Project Goals</b>\n",
    "* Generate a predictive model for used car prices which can be interpreted.\n",
    "* Test the hypothesis that when all other car features are equal, a Dacia branded car is cheaper than a Volvo branded car. Learn what the model can tell us about car brands.\n",
    "* Investigate how the car sale location affects asking price.\n",
    "\n",
    "\n",
    "<b>2. Metrics Utilised</b>\n",
    "* The main metric used will be R2-score, which is the amount of unexplained variance above the baseline which can be explained by the model. \n",
    "* Supplementary metrics of Root Mean Squared Error (RMSE) and Mean Squared Error (MSE) will be used to further evaluate models. \n",
    "\n",
    "<b>3. Results</b>\n",
    "* A comprehensive used car dataset was scraped from autoTrader.co.uk, holding 374,000 used cars appropriate for modelling.\n",
    "* Base versions of 10 different models were evaluated and ranked using a 50,000 row subset of the used car dataset. Two models - LinearRegression() and GradientBoostingRegression() were then selected for further model optimisation on the full dataset and subsequent model evaluation. \n",
    "    * Final LinearRegression() R2 score on the price target was 0.881. \n",
    "    * <b>Final GradientBoostingRegression() R2 score on the price target was 0.953</b>. \n",
    "    * Both models proved to generalise well, with test and train R2 scores within 0.003.\n",
    "    * Of the top 10 predictors/features for each model, 6 of them were predictors/features in common.\n",
    "* ELI5 permutation importance feature has been used to explain and interpret granular detail contained within the GradientBoostingRegression() model which is not evident from the standard gini-based feature importance. \n",
    "* Dummy cars were fed into the GradientBoostingRegression() model and analysed with ELI5 to confirm that <b>a Dacia branded car is indeed cheaper than a Volvo branded car</b>.\n",
    "* No strong evidence has been found to suggest that car sale location impacts sale price, although further work is recommended.\n",
    "    \n",
    "<b>4. Risks/limitations/assumptions</b>\n",
    "* All used car data were gathered over two weeks between January and February 2022. At this moment the second hand car market is artificially inflated due to 'ongoing chip shortages'. As such, the accuracy of all conclusions and insights will fall with time as market conditions change. \n",
    "* Outlier analysis has revealed some data-entry mistakes on autotrader.co.uk. Data-entry mistakes which can be observed as statistical anomalies have been removed from the dataset however this by no means confirms that others don't remain.\n",
    "* When buying a new car there are often a number of tiers to choose from in terms of 'car spec'. Although some engine attributes may be incorporated in the 'BHP' statistic, much of this information is not captured at a used car sale and is not accounted for in this project. For example there is no information on whether a used car has a leather interior with rear view cameras and parking sensors.\n",
    "* Car size variables could be obtained more accurately. At this stage they have been scraped from carsized.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcdf1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:39:10.609522Z",
     "start_time": "2022-03-04T12:39:01.136473Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modelling libraries\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score \n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5 import show_prediction\n",
    "import eli5\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d4800",
   "metadata": {},
   "source": [
    "First of all, I evaluate a range of models on a subset of 50,000 rows from the used cars data\n",
    "\n",
    "* Outliers from the used car dataset are removed from the normally distributed log-price target variable.\n",
    "* Car makes with < 50 cars within the subset are dropped to ensure robust predictions.\n",
    "* Columns used for modelling are price/log_price, mileage/log_mileage, BHP, year, drivetrain, make, body, transmission, fuel and doors. \n",
    "    * price/log_price, mileage/log_mileage, BHP and year are continuous.\n",
    "    * drivetrain, make, body, transmission, fuel and doors are one-hot encoded.\n",
    "    * log_price and log_mileage are used for linear regression models, whilst price and mileage are used for tree-based models.\n",
    "    * Standard scaling is applied to predictors for the linear regression models whilst no scaling is applied for the tree-based models.\n",
    "* Models tested are:\n",
    "    * Linear Regression\n",
    "    * Linear Regression with L1 regularization\n",
    "    * Linear Regression with L2 regularization\n",
    "    * Linear Regression with Elastic Net regularization\n",
    "    * Decision Tree Regression\n",
    "    * Random Forest Regression\n",
    "    * Gradient Boosting Regression\n",
    "    * Ada Boosting Regression with a Decision Tree base model\n",
    "    * Extreme Gradient Boosting Regression\n",
    "* Each model is evaluated by mean R2 score after 5-fold cross validation on the training set as well as R2 score on the test set.\n",
    "* Residuals are described using Mean Squared Error (MSE).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001f339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:23.589636Z",
     "start_time": "2022-03-03T21:27:19.883422Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Read clean used cars data \n",
    "\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "df = pd.read_csv(abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_outliers',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610f67c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:23.673932Z",
     "start_time": "2022-03-03T21:27:23.592178Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Drop columns not useful in modelling\n",
    "\n",
    "df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "                     'href0','dealer_city','dealer_area','year_reg',\n",
    "                     'orig_name','e_engine_kWh','dealer_lat',\n",
    "                     'dealer_lon','ULEZ','id','used'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913683a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:23.892694Z",
     "start_time": "2022-03-03T21:27:23.678027Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b789d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:23.955446Z",
     "start_time": "2022-03-03T21:27:23.894847Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Drop car makes which have less than 50 cars in the model evaluation subset\n",
    "# This is done to prevent the model interpreting a small number of data points as statistically significant\n",
    "dfsample = df.sample(50000, random_state=1)\n",
    "carnums = dfsample.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>50].make.to_list()\n",
    "dfsample = dfsample[dfsample.make.isin(carmakes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c72a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:23.962013Z",
     "start_time": "2022-03-03T21:27:23.957430Z"
    }
   },
   "outputs": [],
   "source": [
    "dfsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e36b7a",
   "metadata": {},
   "source": [
    "## LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30731690",
   "metadata": {},
   "source": [
    "*Why might I look to use a linear regression model?*\n",
    "\n",
    "Having taken a log of the target variable (price) and the mileage predictor there now appears to be a number of linear relationships between the continuous predictors in the dataset. Although it comes loaded with assumptions, linear regression can be one of the most simple ML models to understand and so is a nice place to start. \n",
    "\n",
    "Linear regression within Sklearn implements an ordinary least squares regression, which works to minimise the residual sum of squares (RSS) to best fit the data. i.e. RSS is the loss function for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125fcd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:24.911800Z",
     "start_time": "2022-03-03T21:27:23.964077Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LinearRegression()\n",
    "pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "#pipelr.get_params()\n",
    "\n",
    "params = {'model__copy_X': [True],\n",
    "          'model__fit_intercept': [True],\n",
    "          'model__n_jobs': [2],\n",
    "          'model__normalize': [False],\n",
    "          'model__positive': [False]}\n",
    "\n",
    "gridsearchlr = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "gridsearchlr.fit(X_train, y_train)\n",
    "\n",
    "# LinearRegression Model\n",
    "train_preds = gridsearchlr.predict(X_train)\n",
    "test_preds = gridsearchlr.predict(X_test)\n",
    "printmd('**LINEAR REGRESSION**')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_train), np.exp(train_preds)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_test), np.exp(test_preds)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_train), np.exp(train_preds)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_test), np.exp(test_preds)))))\n",
    "print('R2 train on log_price:',gridsearchlr.score(X_train, y_train))\n",
    "print('R2 test on log_price:',gridsearchlr.score(X_test, y_test))\n",
    "print('R2 train on price:',r2_score(np.exp(y_train), np.exp(train_preds)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_test), np.exp(test_preds)))\n",
    "print('\\n')\n",
    "print(gridsearchlr.best_estimator_)\n",
    "\n",
    "lrdict = {'Model': 'Linear Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_train), np.exp(train_preds)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_test), np.exp(test_preds)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_train), np.exp(train_preds))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_test), np.exp(test_preds))),\n",
    "          'R2 Train': r2_score(np.exp(y_train), np.exp(train_preds)),\n",
    "          'R2 Test': r2_score(np.exp(y_test), np.exp(test_preds)),\n",
    "          'Params': gridsearchlr.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20de1b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:25.172496Z",
     "start_time": "2022-03-03T21:27:24.915984Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "lr_resid_50 = np.exp(y_test) - np.exp(test_preds)\n",
    "lr_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b78b2e",
   "metadata": {},
   "source": [
    "## Lasso()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19124821",
   "metadata": {},
   "source": [
    "Why might I look to use a Lasso regression model? Or a linear regression with L1 penalisation added to the loss function.\n",
    "\n",
    "This builds on the RSS loss function in ordinary least squares regression by using the the RSS plus the sum of absolute values of all beta coefficients as the Lasso loss function. This form of regularisation can be useful when you have many predictors. \n",
    "\n",
    "<b>CHECK</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b23ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:27.264111Z",
     "start_time": "2022-03-03T21:27:25.176459Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN Lasso()\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "la = Lasso()\n",
    "pipela = Pipeline(steps=[('scaler',scaler),('model',la)])\n",
    "pipela.get_params()\n",
    "\n",
    "params = {'model__alpha': [0.0001],\n",
    "         'model__max_iter': [2000],\n",
    "         'model__tol': [0.001]}\n",
    "\n",
    "gridsearchla= GridSearchCV(pipela, params, cv=5, verbose=1)\n",
    "gridsearchla.fit(X_train, y_train)\n",
    "\n",
    "# Lasso Model\n",
    "train_preds = gridsearchla.predict(X_train)\n",
    "test_preds = gridsearchla.predict(X_test)\n",
    "printmd('**LASSO**')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_train), np.exp(train_preds)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_test), np.exp(test_preds)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_train), np.exp(train_preds)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_test), np.exp(test_preds)))))\n",
    "print('R2 train on log_price:',gridsearchla.score(X_train, y_train))\n",
    "print('R2 test on log_price:',gridsearchla.score(X_test, y_test))\n",
    "print('R2 train on price:',r2_score(np.exp(y_train), np.exp(train_preds)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_test), np.exp(test_preds)))\n",
    "print('\\n')\n",
    "print(gridsearchla.best_estimator_)\n",
    "\n",
    "ladict = {'Model': 'Lasso (L1) Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_train), np.exp(train_preds)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_test), np.exp(test_preds)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_train), np.exp(train_preds))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_test), np.exp(test_preds))), \n",
    "          'R2 Train': r2_score(np.exp(y_train), np.exp(train_preds)),\n",
    "          'R2 Test': r2_score(np.exp(y_test), np.exp(test_preds)),\n",
    "          'Params': gridsearchla.best_estimator_,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ba1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:27.519162Z",
     "start_time": "2022-03-03T21:27:27.266652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "la_resid_50 = np.exp(y_test) - np.exp(test_preds)\n",
    "la_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4e577",
   "metadata": {},
   "source": [
    "## Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d41782b",
   "metadata": {},
   "source": [
    "Why might I look to use a Ridge regression model? Or a linear regression with L2 penalisation added to the loss function.\n",
    "\n",
    "This builds on the RSS loss function in ordinary least squares regression by using the the RSS plus the sum of squares of all beta coefficients as the Ridge loss function. This form of regularisation can be useful when you have multi-collinnearity within the dataset.\n",
    "\n",
    "<b>CHECK</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc11ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:30.325293Z",
     "start_time": "2022-03-03T21:27:27.521181Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN Ridge()\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rr = Ridge()\n",
    "piperr = Pipeline(steps=[('scaler',scaler),('model',rr)])\n",
    "piperr.get_params()\n",
    "\n",
    "params = {'model__alpha': [0.5,1,5,50,5000],\n",
    "         'model__max_iter': [200],\n",
    "         'model__solver': ['auto'],\n",
    "         'model__tol': [0.001]}\n",
    "\n",
    "gridsearchrr = GridSearchCV(piperr, params, cv=5, verbose=1)\n",
    "gridsearchrr.fit(X_train, y_train)\n",
    "\n",
    "# RIDGE Model\n",
    "train_preds = gridsearchrr.predict(X_train)\n",
    "test_preds = gridsearchrr.predict(X_test)\n",
    "print('RIDGE')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_train), np.exp(train_preds)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_test), np.exp(test_preds)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_train), np.exp(train_preds)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_test), np.exp(test_preds)))))\n",
    "print('R2 train on log_price:',gridsearchrr.score(X_train, y_train))\n",
    "print('R2 test on log_price:',gridsearchrr.score(X_test, y_test))\n",
    "print('R2 train on price:',r2_score(np.exp(y_train), np.exp(train_preds)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_test), np.exp(test_preds)))\n",
    "print('\\n')\n",
    "print(gridsearchrr.best_estimator_)\n",
    "\n",
    "rrdict = {'Model': 'Ridge (L2) Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_train), np.exp(train_preds)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_test), np.exp(test_preds)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_train), np.exp(train_preds))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_test), np.exp(test_preds))), \n",
    "          'R2 Train': r2_score(np.exp(y_train), np.exp(train_preds)),\n",
    "          'R2 Test': r2_score(np.exp(y_test), np.exp(test_preds)),\n",
    "          'Params': gridsearchrr.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cf66c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:30.576795Z",
     "start_time": "2022-03-03T21:27:30.328259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "rr_resid_50 = np.exp(y_test) - np.exp(test_preds)\n",
    "rr_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af2548",
   "metadata": {},
   "source": [
    "## ElasticNet() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44843ebc",
   "metadata": {},
   "source": [
    "Why might I look to use a Elastic Net regression model? Or a linear regression with both L1 and L2 penalisation added to the loss function.\n",
    "\n",
    "This can combine the best of both worlds. Where the optimum regressor is neither ridge nor lasso, this can blend the two loss functions to find the sweet spot in the middle.  \n",
    "\n",
    "<b>CHECK - I don't think I really need to go into this detail for all these rapid fire models. Do I?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb45c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:59.046459Z",
     "start_time": "2022-03-03T21:27:30.583072Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN ElasticNet()\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "en = ElasticNet()\n",
    "pipeen = Pipeline(steps=[('scaler',scaler),('model',en)])\n",
    "pipeen.get_params()\n",
    "\n",
    "params = {'model__alpha': [0.0001], \n",
    "          'model__l1_ratio': [0,0.25,0.5,0.75, 1],#np.linspace(0.001,1,25),\n",
    "          'model__max_iter': [1000, 2000],#,1000,2000],\n",
    "          'model__random_state': [1],\n",
    "          'model__tol': [0.01]}\n",
    "\n",
    "# params = {'model__alpha': [0.0001], \n",
    "#           'model__l1_ratio': [ 1],#np.linspace(0.001,1,25),\n",
    "#           'model__max_iter': [2000],#,1000,2000],\n",
    "#           'model__random_state': [1],\n",
    "#           'model__tol': [0.01]}\n",
    "\n",
    "gridsearchen = GridSearchCV(pipeen, params, cv=5, verbose=0)\n",
    "gridsearchen.fit(X_train, y_train)\n",
    "\n",
    "# ELASTIC NET Model\n",
    "train_preds = gridsearchen.predict(X_train)\n",
    "test_preds = gridsearchen.predict(X_test)\n",
    "print('ELASTIC NET')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_train), np.exp(train_preds)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_test), np.exp(test_preds)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_train), np.exp(train_preds)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_test), np.exp(test_preds)))))\n",
    "print('R2 train on log_price:',gridsearchen.score(X_train, y_train))\n",
    "print('R2 test on log_price:',gridsearchen.score(X_test, y_test))\n",
    "print('R2 train on price:',r2_score(np.exp(y_train), np.exp(train_preds)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_test), np.exp(test_preds)))\n",
    "print('\\n')\n",
    "print(gridsearchen.best_estimator_)\n",
    "\n",
    "\n",
    "eldict = {'Model': 'Elastic Net Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_train), np.exp(train_preds)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_test), np.exp(test_preds)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_train), np.exp(train_preds))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_test), np.exp(test_preds))),\n",
    "          'R2 Train': r2_score(np.exp(y_train), np.exp(train_preds)),\n",
    "          'R2 Test': r2_score(np.exp(y_test), np.exp(test_preds)),\n",
    "          'Params': gridsearchen.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b28d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:27:59.292702Z",
     "start_time": "2022-03-03T21:27:59.049010Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "en_resid_50 = np.exp(y_test) - np.exp(test_preds)\n",
    "en_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0cfc8f",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:30:08.480969Z",
     "start_time": "2022-03-03T21:27:59.295985Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN DecisionTreeRegressor() \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=42)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "dt = DecisionTreeRegressor()\n",
    "#pipedt = Pipeline(steps=[('scaler',scaler),('model',dt)])\n",
    "pipedt = Pipeline(steps=[('model',dt)])\n",
    "pipedt.get_params()\n",
    "\n",
    "params = {'model__criterion': ['mse', 'friedman_mse', 'poisson'],\n",
    "         'model__max_depth': [15,50,100],\n",
    "         'model__max_leaf_nodes': [500,1000,2000],\n",
    "         'model__min_samples_leaf': [25,50,100],\n",
    "         'model__splitter': ['best']}\n",
    "\n",
    "gridsearchdt = GridSearchCV(pipedt, params, cv=5, verbose=1)\n",
    "gridsearchdt.fit(X_train, y_train)\n",
    "\n",
    "# DECISION TREE\n",
    "train_preds = gridsearchdt.predict(X_train)\n",
    "test_preds = gridsearchdt.predict(X_test)\n",
    "print('DECISION TREE REGRESSOR')\n",
    "print('MSE train:',mean_squared_error(y_train, train_preds))\n",
    "print('MSE test:',mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_train, train_preds))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_test, test_preds))))\n",
    "print('R2 train:',gridsearchdt.score(X_train, y_train))\n",
    "print('R2 test:',gridsearchdt.score(X_test, y_test))\n",
    "print('\\n')\n",
    "\n",
    "print(gridsearchdt.best_estimator_)\n",
    "\n",
    "dtdict = {'Model': 'Decision Tree Regressor', \n",
    "          'MSE Train': mean_squared_error(y_train, train_preds),\n",
    "          'MSE Test': mean_squared_error(y_test, test_preds),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_train, train_preds)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_test, test_preds)),\n",
    "          'R2 Train': gridsearchdt.score(X_train, y_train),\n",
    "          'R2 Test': gridsearchdt.score(X_test, y_test),\n",
    "          'Params': gridsearchdt.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72baa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:30:08.820453Z",
     "start_time": "2022-03-03T21:30:08.483599Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "dt_resid_50 = y_test - test_preds\n",
    "dt_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176fc5d",
   "metadata": {},
   "source": [
    "## RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f1293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:37:21.840303Z",
     "start_time": "2022-03-03T21:30:08.822688Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN RandomForestRegressor()) \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rf = RandomForestRegressor()\n",
    "#piperf = Pipeline(steps=[('scaler',scaler),('model',rf)])\n",
    "piperf = Pipeline(steps=[('model',rf)])\n",
    "piperf.get_params()\n",
    "\n",
    "params = {'model__max_depth': [3,5,8,15],\n",
    "          'model__n_estimators': [50,100,200],\n",
    "          'model__n_jobs': [3],\n",
    "          'model__max_features': [0.3, 0.5, 'auto']}\n",
    "\n",
    "gridsearchrf = GridSearchCV(piperf, params, cv=5, verbose=1)\n",
    "gridsearchrf.fit(X_train, y_train)\n",
    "\n",
    "# SKLEARN Model\n",
    "train_preds = gridsearchrf.predict(X_train)\n",
    "test_preds = gridsearchrf.predict(X_test)\n",
    "print('RANDOM FOREST REGRESSOR')\n",
    "print('MSE train:',mean_squared_error(y_train, train_preds))\n",
    "print('MSE test:',mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train:',np.sqrt(mean_squared_error(y_train, train_preds)))\n",
    "print('RMSE test:',np.sqrt(mean_squared_error(y_test, test_preds)))\n",
    "print('R2 train:',gridsearchrf.score(X_train, y_train))\n",
    "print('R2 test:',gridsearchrf.score(X_test, y_test))\n",
    "print('\\n')\n",
    "print(gridsearchrf.best_estimator_)\n",
    "\n",
    "rfdict = {'Model': 'Random Forrest Regressor', \n",
    "          'MSE Train': mean_squared_error(y_train, train_preds),\n",
    "          'MSE Test': mean_squared_error(y_test, test_preds), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_train, train_preds)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_test, test_preds)), \n",
    "          'R2 Train': gridsearchrf.score(X_train, y_train),\n",
    "          'R2 Test': gridsearchrf.score(X_test, y_test),\n",
    "          'Params': gridsearchrf.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7d208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:37:22.139078Z",
     "start_time": "2022-03-03T21:37:21.843381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "rf_resid_50 = y_test - test_preds\n",
    "rf_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7cac6d",
   "metadata": {},
   "source": [
    "## OLS() - Achieves same result as LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1a390",
   "metadata": {},
   "source": [
    "*Why might I look to use a linear regression model?*\n",
    "\n",
    "Having taken a log of the target variable (price) and the mileage predictor there now appears to be a number of linear relationships between the continuous predictors in the dataset. Although it comes loaded with assumptions, linear regression can be one of the most simple ML models to understand and so is a nice place to start. \n",
    "\n",
    "Linear regression within Sklearn implements an ordinary least squares regression, which works to minimise the residual sum of squares (RSS) to best fit the data. i.e. RSS is the loss function for linear regression.\n",
    "\n",
    "These sentiments are the same as before  - I used OLS to have a nosey at some p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9b5ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:37:22.144743Z",
     "start_time": "2022-03-03T21:37:22.141126Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# I don't actually intend to include this - it was just a sanity check for me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:37:22.616101Z",
     "start_time": "2022-03-03T21:37:22.147086Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - STATSMODELS LinearRegression() - No pipeline or gridsearch (ASK!) \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# smlr = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "# pipesmlr = Pipeline(steps=[('scaler',scaler),('model',smlr)])\n",
    "# pipesmlr.get_params()\n",
    "\n",
    "# params = {'model__copy_X': True,\n",
    "#           'model__fit_intercept': True,\n",
    "#           'model__n_jobs': [2],\n",
    "#           'model__normalize': False,\n",
    "#           'model__positive': False}\n",
    "\n",
    "# gridsearchsmlr = GridSearchCV(pipesmlr, params, cv=5, verbose=1)\n",
    "# gridsearchsmlr.fit(X_train, y_train)\n",
    "\n",
    "# Standardise\n",
    "sc=StandardScaler()\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "# STATSMODEL Model\n",
    "y_train = list(y_train)\n",
    "y_test = list(y_test)\n",
    "smlr = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "results = smlr.fit()\n",
    "train_predictions = results.predict(sm.add_constant(X_train))\n",
    "test_predictions = results.predict(sm.add_constant(X_test,has_constant='add'))\n",
    "print('STATSMODELS OLS')\n",
    "print(\"MSE train:\", mean_squared_error(y_train, train_predictions))\n",
    "print(\"MSE test:\", mean_squared_error(y_test, test_predictions))\n",
    "# print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_train), np.exp(train_preds)))))\n",
    "# print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_test), np.exp(test_preds)))))\n",
    "print(\"R2 train: \", r2_score(y_train, train_predictions))\n",
    "print(\"R2 test: \", r2_score(y_test, test_predictions))\n",
    "\n",
    "results.summary( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7eb53",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a1e7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:40:08.317908Z",
     "start_time": "2022-03-03T21:37:22.618876Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN GradientBoostingRegressor()) \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[100,200],\n",
    "#           'model__max_depth':[3,5,8],\n",
    "#           'model__learning_rate':[0.05,0.1,0.2],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[8],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb.fit(X_train, y_train)\n",
    "\n",
    "# SKLEARN Model\n",
    "train_preds = gridsearchgb.predict(X_train)\n",
    "test_preds = gridsearchgb.predict(X_test)\n",
    "print('GRADIENT BOOSTING REGRESSOR')\n",
    "print('MSE train:',mean_squared_error(y_train, train_preds))\n",
    "print('MSE test:',mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train:',np.sqrt(mean_squared_error(y_train, train_preds)))\n",
    "print('RMSE test:',np.sqrt(mean_squared_error(y_test, test_preds)))\n",
    "print('R2 train:',gridsearchgb.score(X_train, y_train))\n",
    "print('R2 test:',gridsearchgb.score(X_test, y_test))\n",
    "print('\\n')\n",
    "print(gridsearchgb.best_estimator_)\n",
    "\n",
    "gbdict = {'Model': 'Gradient Boosting Regressor', \n",
    "          'MSE Train': mean_squared_error(y_train, train_preds),\n",
    "          'MSE Test': mean_squared_error(y_test, test_preds), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_train, train_preds)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_test, test_preds)),\n",
    "          'R2 Train': gridsearchgb.score(X_train, y_train),\n",
    "          'R2 Test': gridsearchgb.score(X_test, y_test),\n",
    "          'Params': gridsearchgb.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823d2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:40:08.534759Z",
     "start_time": "2022-03-03T21:40:08.323278Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot resiudals\n",
    "gb_resid_50 = y_test - test_preds\n",
    "gb_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d486951",
   "metadata": {},
   "source": [
    "## AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37543af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:42:12.657763Z",
     "start_time": "2022-03-03T21:40:08.537685Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN AdaBoostRegressor()) \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "modelab = AdaBoostRegressor()\n",
    "#pipeab = Pipeline(steps=[('scaler',scaler),('model',modelab)]\n",
    "pipeab = Pipeline(steps=[('model',modelab)])\n",
    "pipeab.get_params()\n",
    "\n",
    "# params = {'model__base_estimator':[gridsearchdt.best_estimator_.named_steps[\"model\"]],\n",
    "#           'model__n_estimators':[50,100, 200],\n",
    "#           'model__learning_rate':[0.5,1.0,2.0],\n",
    "#           'model__loss':['linear', 'square', 'exponential'],\n",
    "#           'model__random_state':[1]}\n",
    "\n",
    "params = {'model__base_estimator':[gridsearchdt.best_estimator_.named_steps[\"model\"]],\n",
    "          'model__n_estimators':[100],\n",
    "          'model__learning_rate':[0.5],\n",
    "          'model__loss':['exponential'],\n",
    "          'model__random_state':[1]}\n",
    "\n",
    "gridsearchab = GridSearchCV(pipeab, params, cv=5, verbose=1)\n",
    "gridsearchab.fit(X_train, y_train)\n",
    "\n",
    "train_preds = gridsearchab.predict(X_train)\n",
    "test_preds = gridsearchab.predict(X_test)\n",
    "print('ADA BOOST')\n",
    "print('MSE train:',mean_squared_error(y_train, train_preds))\n",
    "print('MSE test:',mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train:',np.sqrt(mean_squared_error(y_train, train_preds)))\n",
    "print('RMSE test:',np.sqrt(mean_squared_error(y_test, test_preds)))\n",
    "print('R2 train:',gridsearchab.score(X_train, y_train))\n",
    "print('R2 test:',gridsearchab.score(X_test, y_test))\n",
    "print(gridsearchab.best_estimator_)\n",
    "\n",
    "abdict = {'Model': 'Ada Boosting Regressor', \n",
    "          'MSE Train': mean_squared_error(y_train, train_preds),\n",
    "          'MSE Test': mean_squared_error(y_test, test_preds),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_train, train_preds)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_test, test_preds)),\n",
    "          'R2 Train': gridsearchab.score(X_train, y_train),\n",
    "          'R2 Test': gridsearchab.score(X_test, y_test),\n",
    "          'Params': gridsearchab.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fd51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T21:42:12.863390Z",
     "start_time": "2022-03-03T21:42:12.660300Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "ab_resid_50 = y_test - test_preds\n",
    "ab_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6dbec",
   "metadata": {},
   "source": [
    "## XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae26307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:05:37.476992Z",
     "start_time": "2022-03-03T21:42:12.866353Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - XGBOOST()) \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = dfsample[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=42)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "xgb = XGBRegressor()\n",
    "#pipexgb = Pipeline(steps=[('scaler',scaler),('model',xgb)])\n",
    "pipexgb = Pipeline(steps=[('model',xgb)])\n",
    "pipexgb.get_params()\n",
    "\n",
    "params = {'model__n_estimators':[50,100,200],\n",
    "          'model__max_depth':[3,5,8],\n",
    "          'model__learning_rate':[0.05,0.1,0.2],\n",
    "          'model__random_state':[1],\n",
    "          'model__n_jobs':[3]}\n",
    "\n",
    "# params = {'model__n_estimators':[100,200],\n",
    "#           'model__max_depth':[3,5,8],\n",
    "#           'model__learning_rate':[0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__n_jobs':[3]}\n",
    "\n",
    "\n",
    "gridsearchxgb = GridSearchCV(pipexgb, params, cv=5, verbose=1)\n",
    "gridsearchxgb.fit(X_train, y_train)\n",
    "\n",
    "# XGBOOST Model\n",
    "train_preds = gridsearchxgb.predict(X_train)\n",
    "test_preds = gridsearchxgb.predict(X_test)\n",
    "print('XGBOOSTING REGRESSOR')\n",
    "print('MSE train:',mean_squared_error(y_train, train_preds))\n",
    "print('MSE test:',mean_squared_error(y_test, test_preds))\n",
    "print('RMSE train:',np.sqrt(mean_squared_error(y_train, train_preds)))\n",
    "print('RMSE test:',np.sqrt(mean_squared_error(y_test, test_preds)))\n",
    "print('R2 train:',gridsearchxgb.score(X_train, y_train))\n",
    "print('R2 test:',gridsearchxgb.score(X_test, y_test))\n",
    "print('\\n')\n",
    "print(gridsearchxgb.best_estimator_)\n",
    "\n",
    "xgbdict = {'Model': 'XGBOOST Regressor', \n",
    "          'MSE Train': mean_squared_error(y_train, train_preds),\n",
    "          'MSE Test': mean_squared_error(y_test, test_preds),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_train, train_preds)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_test, test_preds)),\n",
    "          'R2 Train': gridsearchxgb.score(X_train, y_train),\n",
    "          'R2 Test': gridsearchxgb.score(X_test, y_test),\n",
    "          'Params': gridsearchxgb.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378724a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:05:37.675828Z",
     "start_time": "2022-03-03T22:05:37.479477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "xgb_resid_50 = y_test - test_preds\n",
    "xgb_resid_50.hist(bins=50, figsize=(5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075bd1e",
   "metadata": {},
   "source": [
    "## Summary of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebeaba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:12:43.237271Z",
     "start_time": "2022-03-03T22:12:42.964158Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([lrdict,ladict,rrdict,eldict,dtdict,rfdict,gbdict,abdict,xgbdict])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2fe66b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We have lots of very good R2 scores here - the price of a car must be well described by the predictors that were gathered from AutoTrader.\n",
    "\n",
    "I think that the R2 scores for models 1-3 is actually flawed - this is explained variance in the log-price rather than price. All other scores have been converted to price... maybe I can do the same here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b95a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:12:47.394038Z",
     "start_time": "2022-03-03T22:12:44.379305Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ambitious Residuals plot - needs work on X-axis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Make the input data - really clumsy.\n",
    "lr_resid50_df = pd.DataFrame(lr_resid_50)\n",
    "lr_resid50_df['model']='LinearRegression()  R2 = 0.877'\n",
    "lr_resid50_df.columns = ['price', 'model']\n",
    "la_resid50_df = pd.DataFrame(la_resid_50)\n",
    "la_resid50_df['model']='Ridge()  R2 = 0.877'\n",
    "la_resid50_df.columns = ['price', 'model']\n",
    "rr_resid50_df = pd.DataFrame(rr_resid_50)\n",
    "rr_resid50_df['model']='Lasso()  R2 = 0.877'\n",
    "rr_resid50_df.columns = ['price', 'model']\n",
    "en_resid50_df = pd.DataFrame(en_resid_50)\n",
    "en_resid50_df['model']='ElasticNet() R2 = 0.877'\n",
    "en_resid50_df.columns = ['price', 'model']\n",
    "dt_resid50_df = pd.DataFrame(dt_resid_50)\n",
    "dt_resid50_df['model']='DecisionTreeRegressor()  R2 = 0.905'\n",
    "rf_resid50_df = pd.DataFrame(rf_resid_50)\n",
    "rf_resid50_df['model']='RandomForestRegressor()  R2 = 0.952'\n",
    "gb_resid50_df = pd.DataFrame(gb_resid_50)\n",
    "gb_resid50_df['model']='GradientBoostingRegressor()  R2 = 0.956'\n",
    "ab_resid50_df = pd.DataFrame(ab_resid_50)\n",
    "ab_resid50_df['model']='AdaBoostingRegressor()  R2 = 0.941'\n",
    "xgb_resid50_df = pd.DataFrame(xgb_resid_50)\n",
    "xgb_resid50_df['model']='XGBoostRegressor()  R2 = 0.958'\n",
    "\n",
    "tocat=[lr_resid50_df,la_resid50_df,rr_resid50_df,en_resid50_df,dt_resid50_df,\n",
    "       ab_resid50_df,rf_resid50_df,gb_resid50_df,xgb_resid50_df]\n",
    "residplotdf = pd.concat(tocat)\n",
    "residplotdf.columns = ['Residual Price (£)', 'model']\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(10, rot=-.1, light=.5)\n",
    "g = sns.FacetGrid(residplotdf, row=\"model\", hue=\"model\", aspect=10, height=1, palette=pal)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Residual Price (£)\",\n",
    "      bw_adjust=.5, clip_on=True,\n",
    "      fill=True, alpha=1, linewidth=1)\n",
    "g.map(sns.kdeplot, \"Residual Price (£)\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "#g.refline(y=0, linewidth=2,linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "g.map(label, \"Residual Price (£)\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.25)\n",
    "#setting xticks\n",
    "\n",
    "ticks = [-10000, 0, 10000]\n",
    "labels = [i for i in ticks]\n",
    "g.set(xticks = ticks, xticklabels = labels)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)\n",
    "plt.title('Summary plot of tested models with R2 and residual distribution',x=0.32, y=6.75, fontsize=14)\n",
    "plt.savefig('modelsummary.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dcc3b8",
   "metadata": {},
   "source": [
    "# Modeling on all used cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34738ff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:02.089798Z",
     "start_time": "2022-03-03T22:13:57.581881Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "df = pd.read_csv(abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "# Save copy for reference later\n",
    "refdf = df.copy()\n",
    "\n",
    "# Select used cars only\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop columns not used in modelling\n",
    "df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "                     'href0','dealer_city','dealer_area','year_reg',\n",
    "                     'orig_name','e_engine_kWh','dealer_lat',\n",
    "                     'dealer_lon','ULEZ','id','used'], axis=1)\n",
    "\n",
    "print('used_without_extra_columns', df.shape)\n",
    "\n",
    "# Drop under populated car brands\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "\n",
    "print('used_without_little_makes', df.shape)\n",
    "\n",
    "# carnumsyear = df.groupby(by='year')['price'].count().sort_values().reset_index()\n",
    "# carsyearnum = carnumsyear[carnumsyear.price>100].year.to_list()\n",
    "# df = df[df.year.isin(carsyearnum)].copy()\n",
    "\n",
    "# print('used_without_little_years', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4fa94",
   "metadata": {},
   "source": [
    "### LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775679a9",
   "metadata": {},
   "source": [
    "*Why might I look to use a linear regression model?*\n",
    "\n",
    "Having taken a log of the target variable (price) and the mileage predictor there now appears to be a number of linear relationships between the continuous predictors in the dataset. Although it comes loaded with assumptions, linear regression can be one of the most simple ML models to understand and so is a nice place to start. \n",
    "\n",
    "Linear regression within Sklearn implements an ordinary least squares regression, which works to minimise the residual sum of squares (RSS) to best fit the data. i.e. RSS is the loss function for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6623b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:02.153480Z",
     "start_time": "2022-03-03T22:14:02.092329Z"
    }
   },
   "outputs": [],
   "source": [
    "dfsample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8d41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:18.023925Z",
     "start_time": "2022-03-03T22:14:02.155353Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Pairplot \n",
    "g = sns.pairplot(dfsample[['log_price','log_mileage','year','BHP']], kind=\"reg\", corner=True, height=2,\n",
    "                 plot_kws={'line_kws':{'color':'red'}, 'scatter_kws':{'s':1}},\n",
    "                 grid_kws={'diag_sharey':False}, \n",
    "                 diag_kws={'bins':26});\n",
    "g.fig.suptitle(\"Pairplot of continuous features within the dataset\", y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968cb52",
   "metadata": {},
   "source": [
    "<b>Linear regression assumptions</b>\n",
    "\n",
    "We make the following assumptions in linear regression:\n",
    "* Y must have an approximately linear relationship with each independent Xi.\n",
    "* Errors (residuals) ϵi and ϵj must be independent of one another for any i≠j.\n",
    "* Errors (residuals) follow a normal distribution\n",
    "* Errors (residuals) should have a roughly consistent pattern, regardless of the value of the Xi predictors. No discernible relationship between the X predictors and the residuals.\n",
    "* Independent variables Xi and Xj must be independent of one another for any i≠j.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b>Cross Validation</b>\n",
    "\n",
    "Cross validation will be carried out using both train_test_split and the CV component within GridSearchCV. The is to ensure that any produced models generalise well and do not over-fit the data.\n",
    "* For train_test_split I employ a 80/20 train/test split. I also shuffle the target variable and use a random_state to ensure that each model being tested uses the same input data.\n",
    "* Using a cv parameter of 5 within the GridSearchCV tool for each model build ensures that the optimal model parameters are validated by a 5-fold cross validation before being recommended. This again works to prevent over-fitting of data.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b>Standardisation</b>\n",
    "\n",
    "Standard scaling is applied to the predictor variables, manipulating them to be of a comparable magnitude before input to modelling. For every predictor the mean value is subtracted from each value before dividing by the standard deviation. This allows for the influence of all predictors to be interpreted equally without influence from magnitude.\n",
    "\n",
    "Note that Standard scaling is only applied for the linear regression based models. Scaling is not required for decision tree based models.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b>Model Scoring</b>\n",
    "\n",
    "In order to meet linear regression assumptions, some continuous variables within the modelling process have been log transformed to obtain a normal distribution. As such, the target variable for linear regression models is log-price rather than price. In order to attain comparability between linear regression models and decision tree models (which have no log-transform required), all model scoring attributes have been computed on the price variable rather than the log-price variable.  \n",
    "\n",
    "* R2 score will be the primary metric by which models are evaluated. The R2 score represents the fraction of unexplained variance above the baseline which can be explained by the model.\n",
    "* RMSE (or RMSD) represents the quadratic mean of the difference between predicted values and true values. It is the square root of the average of squared errors. The effect of each error on RMSE is proportional to the size of the squared error - thus larger errors have disproportionately large effect on RMSE! RMSE has the same units as the quantity being estimated. \n",
    "* MSE represents the average squared difference between predicted values and true values. It is the average of the squares of errors. MSE is described in square units of the quantity being estimated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543e240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:25.356431Z",
     "start_time": "2022-03-03T22:14:18.027323Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# Dummify necessary columns - I had initially intended to use MPG but it caused numerous issues and the\n",
    "# results are better without it.\n",
    "X = df[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_trainlr, X_testlr, y_trainlr, y_testlr = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LinearRegression()\n",
    "pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "#pipelr.get_params()\n",
    "\n",
    "params = {'model__copy_X': [True],\n",
    "          'model__fit_intercept': [True],\n",
    "          'model__n_jobs': [2],\n",
    "          'model__normalize': [False],\n",
    "          'model__positive': [False]}\n",
    "\n",
    "gridsearchlr = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "gridsearchlr.fit(X_trainlr, y_trainlr)\n",
    "\n",
    "# LinearRegression Model\n",
    "lrtrain_preds = gridsearchlr.predict(X_trainlr)\n",
    "lrtest_preds = gridsearchlr.predict(X_testlr)\n",
    "printmd('**LINEAR REGRESSION**')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds)))))\n",
    "print('R2 train on log_price:',gridsearchlr.score(X_trainlr, y_trainlr))\n",
    "print('R2 test on log_price:',gridsearchlr.score(X_testlr, y_testlr))\n",
    "print('R2 train on price:',r2_score(np.exp(y_trainlr), np.exp(lrtrain_preds)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_testlr), np.exp(lrtest_preds)))\n",
    "print('\\n')\n",
    "print(gridsearchlr.best_estimator_)\n",
    "\n",
    "lrdict2 = {'Model': 'Linear Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds))),\n",
    "          'R2 Train': r2_score(np.exp(y_trainlr), np.exp(lrtrain_preds)),\n",
    "          'R2 Test': r2_score(np.exp(y_testlr), np.exp(lrtest_preds)),\n",
    "          'Params': gridsearchlr.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbf86c",
   "metadata": {},
   "source": [
    "I don't much like the R2 train score on price! will investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97dc2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:25.647451Z",
     "start_time": "2022-03-03T22:14:25.358560Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate coefficients form linear regression \n",
    "lr_coefs = pd.DataFrame({'variable': X_trainlr.columns,\n",
    "                            'coef': gridsearchlr.best_estimator_.named_steps['model'].coef_,\n",
    "                            'abs_coef': np.abs(gridsearchlr.best_estimator_.named_steps['model'].coef_),\n",
    "                            'std_dev': np.std(gridsearchlr.best_estimator_.named_steps['model'].coef_),\n",
    "                            '1 std dev increase in variable causes X percent change on price':(np.exp(gridsearchlr.best_estimator_.named_steps['model'].coef_)-1)*100})\n",
    "lr_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "#lr_coefs.loc[0,'1 std dev increase in variable causes X percent change on price'] = np.nan\n",
    "lr_coefs['Percentage increase in price for every 20% increase X'] = np.nan\n",
    "lr_coefs.loc[0,'Percentage increase in price for every 20% increase X'] = ((1.20**(lr_coefs.loc[0,'coef'])-1)*100)\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/#:~:text=Interpret%20the%20coefficient%20as%20the,variable%20increases%20by%20about%200.20%25.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "lr_coefs.coef[:15].plot(kind='barh', color = 'skyblue', ax=ax, alpha=0.5, title='Linear Regression coefficients')\n",
    "ax.set_yticklabels(lr_coefs.variable[:15].values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88139b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:17:10.532471Z",
     "start_time": "2022-03-03T22:17:08.373904Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot test predicted vs actual price in both log-space and non. NEEDS LEGEND FIXED\n",
    "fig, ax = plt.subplots(ncols=2,figsize=(16,8))\n",
    "ax[0].scatter(y_testlr, lrtest_preds, color='skyblue', alpha=0.8, s=1, label = 'y_true - y_hat')\n",
    "ax[0].plot([y_testlr.min(), y_testlr.max()], [y_testlr.min(), y_testlr.max()], c='b',label = 'Perfect model')\n",
    "ax[0].set_title('Actual vs Predicted price')\n",
    "ax[0].set_xlabel(\"Actual price (£)\")\n",
    "ax[0].set_ylabel(\"Predicted price(£)\")\n",
    "ax[0].plot([y_testlr.min(), y_testlr.max()], [y_testlr.mean(), y_testlr.mean()], c='r', label = 'Baseline prediction')\n",
    "ax[1].scatter(np.exp(y_testlr), np.exp(lrtest_preds), color='skyblue', alpha=0.8, s=2,  label = 'y_true - y_hat')\n",
    "ax[1].plot([np.exp(y_testlr).min(), np.exp(y_testlr).max()], [np.exp(y_testlr).min(), np.exp(y_testlr).max()], \n",
    "           c='b', label = 'Perfect model')\n",
    "ax[1].set_title('Actual vs Predicted log-price')\n",
    "ax[1].set_xlabel(\"Actual log-price (£)\")\n",
    "ax[1].set_ylabel(\"Predicted log-price (£)\")\n",
    "ax[1].plot([np.exp(y_testlr).min(), np.exp(y_testlr).max()], [np.exp(y_testlr).mean(), np.exp(y_testlr).mean()], \n",
    "           c='r', label = 'Baseline prediction')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.suptitle('Test dataset residual evaluation')\n",
    "for i in range(2):\n",
    "    legend = ax[i].legend()\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db389d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:17:29.858922Z",
     "start_time": "2022-03-03T22:17:24.294124Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot train predicted vs actual price in both log-space and non. NEEDS LEGEND FIXED\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2,figsize=(16,8))\n",
    "ax[0].scatter(y_trainlr, lrtrain_preds, color='skyblue', alpha=0.8, s=1, label = 'y_true - y_hat')\n",
    "ax[0].plot([y_trainlr.min(), y_trainlr.max()], [y_trainlr.min(), y_trainlr.max()], c='b',label = 'Perfect model')\n",
    "ax[0].set_title('Actual vs Predicted price')\n",
    "ax[0].set_xlabel(\"Actual price (£)\")\n",
    "ax[0].set_ylabel(\"Predicted price(£)\")\n",
    "ax[0].plot([y_trainlr.min(), y_trainlr.max()], [y_trainlr.mean(), y_trainlr.mean()], c='r', label = 'Baseline prediction')\n",
    "ax[1].scatter(np.exp(y_trainlr), np.exp(lrtrain_preds), color='skyblue', alpha=0.8, s=2,  label = 'y_true - y_hat')\n",
    "ax[1].plot([np.exp(y_trainlr).min(), np.exp(y_trainlr).max()], [np.exp(y_trainlr).min(), np.exp(y_trainlr).max()], \n",
    "           c='b', label = 'Perfect model')\n",
    "ax[1].set_title('Actual vs Predicted log-price')\n",
    "ax[1].set_xlabel(\"Actual log-price (£)\")\n",
    "ax[1].set_ylabel(\"Predicted log-price (£)\")\n",
    "ax[1].plot([np.exp(y_trainlr).min(), np.exp(y_trainlr).max()], [np.exp(y_trainlr).mean(), np.exp(y_trainlr).mean()], \n",
    "           c='r', label = 'Baseline prediction')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "for i in range(2):\n",
    "    legend = ax[i].legend()\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('white')\n",
    "plt.suptitle('Train dataset residual evaluation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5e317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:32.947277Z",
     "start_time": "2022-03-03T22:14:32.932278Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot coefficients and interpret to real life implications\n",
    "lr_coefs.sort_values(by='abs_coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0cb14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:14:32.954999Z",
     "start_time": "2022-03-03T22:14:32.950238Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define top_lr_factors for later\n",
    "top_lr_factors = lr_coefs.sort_values(by='abs_coef', ascending=False).head(10).variable.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd9eac",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c816d",
   "metadata": {},
   "source": [
    "*Why might I look to use a gradient boosting model?*\n",
    "\n",
    "Where linear regression modelling started with a range of assumptions, gradient boosting methods only assume that the target variable is real-valued. This lack of assumptions can make it an appealing method for machine learning. \n",
    "\n",
    "Gradient boosting is a tree based ensemble technique in which the predictors are not made independently, but sequentially. The sequential method works in a way which allows subsequent predictors to learn from mistakes of their previous predictors.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b>Gradient boosting explained</b>\n",
    "\n",
    "* Gradient boosting starts with a base prediction by adopting the average value for the target variable before generating sequential predictors which aim to minimise the residuals between the base prediction and the actual values. \n",
    "* Each sequential predictor is scaled by a 'learning factor' before being added to the ensemble. This is usually some small fraction like 0.1 which forces the gradient boosting ensemble model to iteratively take small steps towards a better model with minimised residuals. \n",
    "* Taking many small steps in the right direction results in better predictions with a testing dataset. i.e. lower variance. \n",
    "* The model is considered optimised when adding new scaled predictors to the ensemble fails to reduce the residuals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3f6ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:31.550756Z",
     "start_time": "2022-03-03T22:18:11.843041Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN GradientBoostingRegressor()) \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_traingb, X_testgb, y_traingb, y_testgb = train_test_split(X,y,test_size=0.2, shuffle=y, random_state =2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[3,5],\n",
    "#           'model__learning_rate':[0.05, 0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "# criterion{‘friedman_mse’, ‘squared_error’, ‘mse’, ‘mae’}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[5],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb.fit(X_traingb, y_traingb)\n",
    "\n",
    "# SKLEARN Model\n",
    "gbtrain_preds = gridsearchgb.predict(X_traingb)\n",
    "gbtest_preds = gridsearchgb.predict(X_testgb)\n",
    "printmd('**GRADIENT BOOSTING REGRESSOR**')\n",
    "print('MSE train:',mean_squared_error(y_traingb, gbtrain_preds))\n",
    "print('MSE test:',mean_squared_error(y_testgb, gbtest_preds))\n",
    "print('R2 train:',gridsearchgb.score(X_traingb, y_traingb))\n",
    "print('R2 test:',gridsearchgb.score(X_testgb, y_testgb))\n",
    "print('\\n')\n",
    "print(gridsearchgb.best_estimator_)\n",
    "\n",
    "gbdict2 = {'Model': 'Gradient Boosting Regressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb, gbtrain_preds),\n",
    "          'MSE Test': mean_squared_error(y_testgb, gbtest_preds), \n",
    "          'R2 Train': gridsearchgb.score(X_traingb, y_traingb),\n",
    "          'R2 Test': gridsearchgb.score(X_testgb, y_testgb),\n",
    "          'Params': gridsearchgb.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d56a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:33.939321Z",
     "start_time": "2022-03-03T22:40:31.553688Z"
    }
   },
   "outputs": [],
   "source": [
    "printmd('**GRADIENT BOOSTING REGRESSOR**')\n",
    "print('MSE train:',mean_squared_error(y_traingb, gbtrain_preds))\n",
    "print('MSE test:',mean_squared_error(y_testgb, gbtest_preds))\n",
    "print('RMSE train:',np.sqrt(mean_squared_error(y_traingb, gbtrain_preds)))\n",
    "print('RMSE test:',np.sqrt(mean_squared_error(y_testgb, gbtest_preds)))\n",
    "print('R2 train:',gridsearchgb.score(X_traingb, y_traingb))\n",
    "print('R2 test:',gridsearchgb.score(X_testgb, y_testgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78b000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T13:47:03.491267Z",
     "start_time": "2022-03-03T13:47:03.485248Z"
    }
   },
   "outputs": [],
   "source": [
    "pipegb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87955ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:34.416723Z",
     "start_time": "2022-03-03T22:40:33.941610Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature importance plot for gradient boosting \n",
    "\n",
    "# FROM SKLEARN\n",
    "# feature_importances_\n",
    "# The impurity-based feature importances.\n",
    "# The higher, the more important the feature. The importance of a feature is computed as the \n",
    "# (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.\n",
    "# Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values)\n",
    "\n",
    "\n",
    "\n",
    "gb_coefs = pd.DataFrame({'variable': X_traingb.columns,\n",
    "                            'Feature Importance': gridsearchgb.best_estimator_.named_steps[\"model\"].feature_importances_})\n",
    "\n",
    "plot = gb_coefs.sort_values(by='Feature Importance', ascending=False).head(30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot['Feature Importance'][:10].plot(kind='barh', color = 'darkblue', ax=ax, alpha=0.9 )\n",
    "ax.set_yticklabels(plot.variable[:10].values)\n",
    "ax.set_title('Gradient Boosting Feature Importance', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig('featimp.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c375124",
   "metadata": {},
   "source": [
    "The plot above describes feature importance from Sklearn\n",
    "\n",
    "Decision tree methods can give us feature importances to illuminate what's happening under the hood. The higher the number the more important the predictor was for deciding splits at nodes. Technically, the importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. In this case, the criterion is friedman_mse. \n",
    "\n",
    "That means a feature is more important...\n",
    "\n",
    "- if it is used in many different nodes,\n",
    "- if the difference in the measures of Gini or entropy are before and after the split is high\n",
    "\n",
    "Feature importances are normalized in the sense of summing up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf42fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:34.431087Z",
     "start_time": "2022-03-03T22:40:34.420586Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compare top coefficients from LogisticRegression() against top feature importances from GradientBoostingRegressor()\n",
    "top_gb_factors = gb_coefs.sort_values(by='Feature Importance', ascending=False).head(10).variable.to_list()\n",
    "\n",
    "topfeaturedf = pd.DataFrame({'Top Linear Regression coefficients':top_lr_factors,'Top Gradient Boosting Feature Importances':top_gb_factors})\n",
    "topfeaturedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d62948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:37.965948Z",
     "start_time": "2022-03-03T22:40:34.432724Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot test actual vs predicted price \n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot([y_testgb.min(), y_testgb.max()], [y_testgb.min(), y_testgb.max()], c='darkblue',label = 'Perfect model')\n",
    "ax.set_title('Actual vs Predicted price',fontsize=12)\n",
    "ax.set_xlabel(\"Actual price (£)\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted price(£)\", fontsize=12)\n",
    "plt.hlines(y=y_testgb.mean(), xmin=y_testgb.min(), xmax=y_testgb.max(), linewidth=2, color='skyblue', label = 'Baseline prediction')\n",
    "ax.scatter(y_testgb, gbtest_preds, color='darkred', alpha=0.8, s=1, label = 'True price vs Predicted price')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "legend = plt.legend()\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "plt.savefig('actpred.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470833a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:37.997512Z",
     "start_time": "2022-03-03T22:40:37.967725Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the biggest residuals!\n",
    "resid = np.abs(y_testgb - gbtest_preds)\n",
    "resid.sort_values(ascending=False)\n",
    "\n",
    "sorted_resid = resid.sort_values(ascending=False).reset_index()\n",
    "investigate1 = sorted_resid.iloc[0,0]\n",
    "investigate2 = sorted_resid.iloc[1,0]\n",
    "investigate3 = sorted_resid.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f04134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:38.049790Z",
     "start_time": "2022-03-03T22:40:38.000203Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Print structured report of larges residual cars\n",
    "\n",
    "count=0\n",
    "for residual in [investigate1,investigate2,investigate3]:\n",
    "    count+=1\n",
    "    printmd(f'**Bad prediction {count}**')\n",
    "    print('Predicted price (£) \\t',round(gridsearchgb.predict(X_testgb.loc[residual,:].array.reshape(1, -1))[0],2))\n",
    "    print('Actual price (£)\\t',refdf.loc[residual,'price'])\n",
    "    print(refdf.loc[residual,'name':'county'])\n",
    "    print(refdf.loc[residual,'link'])\n",
    "    print('-'*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae9959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:40:40.973456Z",
     "start_time": "2022-03-03T22:40:38.052555Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot train actual vs predicted price \n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(y_traingb, gbtrain_preds, color='skyblue', alpha=0.8, s=1, label = 'y_true - y_hat')\n",
    "ax.plot([y_traingb.min(), y_traingb.max()], [y_traingb.min(), y_traingb.max()], c='b',label = 'Perfect model')\n",
    "ax.set_title('Actual vs Predicted price')\n",
    "ax.set_xlabel(\"Actual price (£)\")\n",
    "ax.set_ylabel(\"Predicted price(£)\")\n",
    "plt.axhline(y=y_traingb.mean(), linewidth = 2, c='r',label = 'Baseline prediction')\n",
    "legend = plt.legend()\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44417b6",
   "metadata": {},
   "source": [
    "Nice residual plots all round. Much better than the Linear regression ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe8122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.240816Z",
     "start_time": "2022-03-03T22:40:40.975623Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Use permutation importance from ELI5 package to obtain a weight to assign to each predictor\n",
    "perm = PermutationImportance(gridsearchgb).fit(X_testgb, y_testgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099c50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.290941Z",
     "start_time": "2022-03-03T22:43:01.246433Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Feature importance from PermutationImportance package\n",
    "\n",
    "# https://stats.stackexchange.com/questions/555949/how-to-interpret-the-feature-importances-for-eli5-show-weights-for-regressio\n",
    "# For a high level overview of how the produced model works, we look at the weights from PermutationImportance\n",
    "# I show the top 63 - That's them all. The eli5.show_weights function outputs a HTML table\n",
    "eli5.show_weights(perm, feature_names = X_testgb.columns.values, top= 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c223d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.308443Z",
     "start_time": "2022-03-03T22:43:01.292683Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Zip together top coefficients for best LR model and best GB model using FI&PI\n",
    "top_gb_factors_pi = pd.DataFrame((zip(X_testgb.columns.tolist(), perm.feature_importances_)), columns= ['variable','fi']).sort_values(by='fi', ascending=False).head(10).variable.to_list()\n",
    "top_gb_factors = gb_coefs.sort_values(by='Feature Importance', ascending=False).head(10).variable.to_list()\n",
    "\n",
    "\n",
    "featurecomp = pd.DataFrame({'rank':range(1,11),'LinearRegression top coefficients':top_lr_factors,'GradientBoostingRegression top features':top_gb_factors, 'GradientBoostingRegression top features from permutation importance':top_gb_factors_pi})\n",
    "featurecomp.set_index('rank', drop=True, inplace=True)\n",
    "featurecomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade52c8c",
   "metadata": {},
   "source": [
    "Linear regression coefficients and Gradient boosting feature importance have 6 common predictors in their top 10.\n",
    "\n",
    "- year, BHP, body_Hatchback, make_Land_Rover, transmission_Manual and log_mileage \n",
    "\n",
    "Linear regression coefficients and Gradient boosting feature importance from permutation importance have 6 common predictors in their top 10.\n",
    "\n",
    "- year, BHP, make_Mercedez-Benz, make_Land_Rover, transmission_Manual and log_mileage \n",
    "\n",
    "\n",
    "Gradient boosting feature importance and Gradient boosting feature importance from permutation importance have 8 common predictors in their top 10.\n",
    "\n",
    "- year, BHP, body_SUV, make_Porsche, make_Land_Rover, transmission_Manual, fuel_petrol and log_mileage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37715e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.326097Z",
     "start_time": "2022-03-03T22:43:01.310753Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Have a quick look at the feature importance and standard deviation from permutation importance \n",
    "df_fi = pd.DataFrame(dict(feature_names=X_testgb.columns.tolist(),\n",
    "                          feat_imp=perm.feature_importances_, \n",
    "                          std=perm.feature_importances_std_,\n",
    "                          ))\n",
    "df_fi = df_fi.round(4)\n",
    "df_fi.sort_values('feat_imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec00e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.690017Z",
     "start_time": "2022-03-03T22:43:01.328266Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Look at feature importances for a individual car. This is the granular breakdown of why it costs what it costs.\n",
    "\n",
    "# For a look at how a single car has been processed by the model, I can use the eli5.show_prediction utility.\n",
    "# It takes the model as input, and a sample row, in this case I use row 5 from X_test and return the top 10 features\n",
    "show_prediction(gridsearchgb.best_estimator_.named_steps[\"model\"], X_testgb.iloc[32, :], top =13, show_feature_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb979c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.730737Z",
     "start_time": "2022-03-03T22:43:01.692307Z"
    },
    "code_folding": [
     2,
     31,
     60,
     175
    ]
   },
   "outputs": [],
   "source": [
    "# Define functions for ELI5 car analysis \n",
    "\n",
    "def make_groupby_col(feature):\n",
    "    \"\"\"ADD DESCRIPTION IN HERE\n",
    "    This function is used to help make an informative table in the car_summary function output\n",
    "    \"\"\"\n",
    "    if 'BHP' in feature:\n",
    "        return 'BHP'\n",
    "    if 'BIAS' in feature:\n",
    "        return 'BIAS'\n",
    "    if 'year' in feature:\n",
    "        return 'year'\n",
    "#     if 'log_mileage' in feature:\n",
    "#         return 'log_mileage'\n",
    "    if 'transmission' in feature:\n",
    "        return 'transmission'\n",
    "    if 'body' in feature:\n",
    "        return 'body'\n",
    "    if 'drivertrain' in feature:\n",
    "        return 'drivertrain'\n",
    "    if 'mpg' in feature:\n",
    "        return 'mpg'\n",
    "    if 'make' in feature:\n",
    "        return 'make'\n",
    "    if 'doors' in feature:\n",
    "        return 'doors'\n",
    "    if 'fuel' in feature:\n",
    "        return 'fuel'\n",
    "    if 'mileage' in feature:\n",
    "        return 'mileage'\n",
    "    \n",
    "def generate_summary(model, car_details, verbose=False):\n",
    "    \"\"\"ADD DESCRIPTION IN HERE\n",
    "    The key point is that I can use eli5.explain_prediction_df to obtain a dataframe of weights\n",
    "    and contributions for each row.\n",
    "    \"\"\"\n",
    "    spiel = str(refdf.loc[pd.DataFrame(car_details).columns[0],'orig_name']+' '+refdf.loc[pd.DataFrame(car_details).columns[0],'name_subtitle'])\n",
    "    printmd(f'**Car Summary:  {spiel}**')\n",
    "    if verbose==True:\n",
    "        # Print out details of the original car\n",
    "        print('Original car')\n",
    "        print(df.loc[pd.DataFrame(car_details).columns[0],:])\n",
    "        print('\\n')\n",
    "    # Print out the predicted car price\n",
    "    print('Predicted price \\t\\t True price')\n",
    "    print('£', round(gridsearchgb.best_estimator_.named_steps[\"model\"].predict(pd.DataFrame(car_details).T)[0],2), \\\n",
    "          '\\t\\t\\t £',df.loc[pd.DataFrame(car_details).columns[0],:][1],'\\n')\n",
    "    print(refdf.loc[pd.DataFrame(car_details).columns[0],'link'])\n",
    "\n",
    "    eli5df = eli5.explain_prediction_df(estimator=model, doc=car_details)    \n",
    "    eli5df['absweight']=eli5df.weight.apply(lambda x: np.abs(x))\n",
    "    eli5df['Predictor']=eli5df.feature.apply(lambda x: make_groupby_col(x))\n",
    "    eli5df = eli5df.groupby(by='Predictor').sum().sort_values(by='absweight', ascending=False)\n",
    "    eli5df['price']=eli5df.weight.cumsum()\n",
    "    eli5df['attribute']=0\n",
    "    for att in ['transmission','body','mileage','BHP','make','year','drivertrain','doors','fuel']:\n",
    "        eli5df.loc[att,'attribute']=df.loc[pd.DataFrame(car_details).columns[0],att]\n",
    "    eli5df.columns =['Price Contribution (£)','value','absweight','Cumulative Car Price (£)','Attribute']\n",
    "    return eli5df[['Attribute','Price Contribution (£)','Cumulative Car Price (£)']]\n",
    "\n",
    "def make_fake_car(year = 2018,\n",
    "                  mileage = 40000,\n",
    "                  BHP = 120,\n",
    "                  body = 'Hatchback', \n",
    "                  transmission = 'Mmanual', \n",
    "                  make = 'Ford', \n",
    "                  drivetrain = 'Front Wheel Drive',\n",
    "                  drs = '5dr', \n",
    "                  fuel = 'Petrol'):\n",
    "    sample = pd.DataFrame(X_testgb.iloc[20, :]).T\n",
    "    makes=[]\n",
    "    bodys=[]\n",
    "    drivertrains=[]\n",
    "    fuels=[]\n",
    "    doors=[]\n",
    "    transmissions=[]\n",
    "    for x in sample.columns:\n",
    "        if 'make' in x:\n",
    "            makes.append(x)\n",
    "        if 'body' in x:\n",
    "            bodys.append(x)\n",
    "        if 'drivertrain' in x:\n",
    "            drivertrains.append(x)\n",
    "        if 'fuel' in x:\n",
    "            fuels.append(x)\n",
    "        if 'door' in x:\n",
    "            doors.append(x)\n",
    "        if 'transmission' in x:\n",
    "            transmissions.append(x)\n",
    "\n",
    "    dummy_cols = [makes + bodys + drivertrains + fuels + doors + transmissions + ['log_mileage','year','BHP']]\n",
    "    for x in dummy_cols:\n",
    "        sample.loc[:,x]=0\n",
    "\n",
    "    sample['year'] = year\n",
    "    sample['BHP'] = BHP\n",
    "    sample['log_mileage'] = np.log(mileage)\n",
    "    sample[f'body_{body}'] = 1\n",
    "    sample[f'transmission_{transmission}'] = 1\n",
    "    sample[f'make_{make}'] = 1\n",
    "    sample[f'drivertrain_{drivetrain}'] = 1\n",
    "    sample[f'fuel_{fuel}'] = 1\n",
    "    sample[f'doors_{drs}'] = 1\n",
    "    return sample.iloc[0,:]\n",
    "\n",
    "def make_and_predict_describe_fake_car(year = 2018,\n",
    "                              mileage = 40000,\n",
    "                              BHP = 120,\n",
    "                              body = 'Hatchback', \n",
    "                              transmission = 'Manual', \n",
    "                              make = 'Ford', \n",
    "                              drivetrain = 'Front Wheel Drive',\n",
    "                              drs = '5dr', \n",
    "                              fuel = 'Petrol',\n",
    "                              model = gridsearchgb.best_estimator_.named_steps[\"model\"]):\n",
    "    sample = pd.DataFrame(X_testgb.iloc[20, :]).T\n",
    "    makes=[]\n",
    "    bodys=[]\n",
    "    drivertrains=[]\n",
    "    fuels=[]\n",
    "    doors=[]\n",
    "    transmissions=[]\n",
    "    for x in sample.columns:\n",
    "        if 'make' in x:\n",
    "            makes.append(x)\n",
    "        if 'body' in x:\n",
    "            bodys.append(x)\n",
    "        if 'drivertrain' in x:\n",
    "            drivertrains.append(x)\n",
    "        if 'fuel' in x:\n",
    "            fuels.append(x)\n",
    "        if 'door' in x:\n",
    "            doors.append(x)\n",
    "        if 'transmission' in x:\n",
    "            transmissions.append(x)\n",
    "\n",
    "    dummy_cols = [makes + bodys + drivertrains + fuels + doors + transmissions + ['log_mileage','year','BHP']]\n",
    "    for x in dummy_cols:\n",
    "        sample.loc[:,x]=0\n",
    "\n",
    "    sample['year'] = year\n",
    "    sample['BHP'] = BHP\n",
    "    sample['log_mileage'] = np.log(mileage)\n",
    "    sample[f'body_{body}'] = 1\n",
    "    if transmission == 'Manual':\n",
    "        sample[f'transmission_Manual'] = 1\n",
    "    else:\n",
    "        sample[f'transmission_Manual'] = 0\n",
    "    sample[f'make_{make}'] = 1\n",
    "    sample[f'drivertrain_{drivetrain}'] = 1\n",
    "    sample[f'fuel_{fuel}'] = 1\n",
    "    sample[f'doors_{drs}'] = 1\n",
    "\n",
    "    printmd(f'**Car Summary for synthetic {make}**')\n",
    "    print('£', round(gridsearchgb.best_estimator_.named_steps[\"model\"].predict(sample.iloc[0,:].array.reshape(1, -1))[0],2))\n",
    "    eli5df = eli5.explain_prediction_df(estimator=model, doc=sample.iloc[0,:])    \n",
    "    eli5df['absweight']=eli5df.weight.apply(lambda x: np.abs(x))\n",
    "    eli5df['Predictor']=eli5df.feature.apply(lambda x: make_groupby_col(x))\n",
    "    eli5df = eli5df.groupby(by='Predictor').sum().sort_values(by='absweight', ascending=False)\n",
    "    eli5df['price']=eli5df.weight.cumsum()\n",
    "    eli5df['attribute'] = 0\n",
    "    eli5df.loc['BHP','attribute'] = BHP\n",
    "    eli5df.loc['year','attribute'] = year\n",
    "    eli5df.loc['mileage','attribute'] = mileage\n",
    "    eli5df.loc['transmission','attribute'] = transmission\n",
    "    eli5df.loc['make','attribute'] = make\n",
    "    eli5df.loc['drivertrain','attribute'] = drivetrain\n",
    "    eli5df.loc['doors','attribute'] = drs\n",
    "    eli5df.loc['fuel','attribute'] = fuel  \n",
    "    eli5df.loc['body','attribute'] = body \n",
    "    eli5df.columns=['Price contribution (£)','Attribute Into Model','Absolute Price Contribution','Cumulative Car Price (£)','Attribute']        \n",
    "    return eli5df[['Attribute','Price contribution (£)','Cumulative Car Price (£)']        ]\n",
    "\n",
    "def make_and_predict_fake_car(year = 2018,\n",
    "                              mileage = 40000,\n",
    "                              BHP = 120,\n",
    "                              body = 'Hatchback', \n",
    "                              transmission = 'Manual', \n",
    "                              make = 'Ford', \n",
    "                              drivetrain = 'Front Wheel Drive',\n",
    "                              drs = '5dr', \n",
    "                              fuel = 'Petrol',\n",
    "                              model = gridsearchgb.best_estimator_.named_steps[\"model\"]):\n",
    "    sample = pd.DataFrame(X_testgb.iloc[20, :]).T\n",
    "    makes=[]\n",
    "    bodys=[]\n",
    "    drivertrains=[]\n",
    "    fuels=[]\n",
    "    doors=[]\n",
    "    transmissions=[]\n",
    "    for x in sample.columns:\n",
    "        if 'make' in x:\n",
    "            makes.append(x)\n",
    "        if 'body' in x:\n",
    "            bodys.append(x)\n",
    "        if 'drivertrain' in x:\n",
    "            drivertrains.append(x)\n",
    "        if 'fuel' in x:\n",
    "            fuels.append(x)\n",
    "        if 'door' in x:\n",
    "            doors.append(x)\n",
    "        if 'transmission' in x:\n",
    "            transmissions.append(x)\n",
    "\n",
    "    dummy_cols = [makes + bodys + drivertrains + fuels + doors + transmissions + ['log_mileage','year','BHP']]\n",
    "    for x in dummy_cols:\n",
    "        sample.loc[:,x]=0\n",
    "\n",
    "    sample['year'] = year\n",
    "    sample['BHP'] = BHP\n",
    "    sample['log_mileage'] = np.log(mileage)\n",
    "    sample[f'body_{body}'] = 1\n",
    "    sample[f'transmission_{transmission}'] = 1\n",
    "    sample[f'make_{make}'] = 1\n",
    "    sample[f'drivertrain_{drivetrain}'] = 1\n",
    "    sample[f'fuel_{fuel}'] = 1\n",
    "    sample[f'doors_{drs}'] = 1\n",
    "   \n",
    "    return (round(gridsearchgb.best_estimator_.named_steps[\"model\"].predict(sample.iloc[0,:].array.reshape(1, -1))[0],2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947bca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:01.737736Z",
     "start_time": "2022-03-03T22:43:01.732487Z"
    }
   },
   "outputs": [],
   "source": [
    "X_testgb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bb235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:02.122466Z",
     "start_time": "2022-03-03T22:43:01.739312Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot my polo depreciate over time \n",
    "\n",
    "polo_price = []\n",
    "yr=2008\n",
    "mil=40000\n",
    "all_miles = []\n",
    "for i in range(0,21):\n",
    "    polo_price.append(make_and_predict_fake_car(year = yr, \n",
    "                                                mileage = mil,\n",
    "                                                BHP = 64,\n",
    "                                                body = 'Hatchback', \n",
    "                                                transmission = 'Manual', \n",
    "                                                make = 'Volkswagen', \n",
    "                                                drivetrain = 'Front Wheel Drive',\n",
    "                                                drs = '5dr', \n",
    "                                                fuel = 'Petrol'))\n",
    "    all_miles.append(mil)\n",
    "    yr-=1\n",
    "    mil+=7000\n",
    "    \n",
    "polodf = pd.DataFrame({'Year': range(2022,2043), 'Price (£)':polo_price , 'Mileage': all_miles})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "# ax.plot([y_testgb.min(), y_testgb.max()], [y_testgb.min(), y_testgb.max()], c='darkblue',label = 'Perfect model')\n",
    "ax.set_title('Predicted price of 2008 VW Polo over time',fontsize=14)\n",
    "ax.set_xlabel(\"Year\", fontsize=13)\n",
    "ax.set_ylabel(\"Predicted price (£)\", fontsize=12)\n",
    "ax.plot(polodf.Year, polodf['Price (£)'], c='darkblue',label = '2008 VW Polo Value')\n",
    "plt.xticks(polodf.Year, rotation=60)\n",
    "ax.set_ylim(1000,5000)\n",
    "plt.tight_layout()\n",
    "# plt.legend()\n",
    "# legend = plt.legend()\n",
    "# frame = legend.get_frame()\n",
    "# frame.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd2961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:02.506030Z",
     "start_time": "2022-03-03T22:43:02.124698Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot George's SAAB depreciate over time \n",
    "\n",
    "polo_price = []\n",
    "yr=2010\n",
    "mil=117000\n",
    "all_miles = []\n",
    "for i in range(0,21):\n",
    "    polo_price.append(make_and_predict_fake_car(year = yr, \n",
    "                                                mileage = mil,\n",
    "                                                BHP = 156,\n",
    "                                                body = 'Saloon', \n",
    "                                                transmission = 'Manual', \n",
    "                                                make = 'Saab', \n",
    "                                                drivetrain = 'Front Wheel Drive',\n",
    "                                                drs = '5dr', \n",
    "                                                fuel = 'Diesel'))\n",
    "    all_miles.append(mil)\n",
    "    yr-=1\n",
    "    mil+=7000\n",
    "    \n",
    "polodf = pd.DataFrame({'Year': range(2022,2043), 'Price (£)':polo_price , 'Mileage': all_miles})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,6))\n",
    "# ax.plot([y_testgb.min(), y_testgb.max()], [y_testgb.min(), y_testgb.max()], c='darkblue',label = 'Perfect model')\n",
    "ax.set_title(\"Predicted price of George's SAAB over time\",fontsize=14)\n",
    "ax.set_xlabel(\"Year\", fontsize=13)\n",
    "ax.set_ylabel(\"Predicted price (£)\", fontsize=13)\n",
    "ax.plot(polodf.Year, polodf['Price (£)'], c='darkblue',label = '2010 SAAB Value')\n",
    "plt.xticks(polodf.Year, rotation=60)\n",
    "ax.set_ylim(1000,4000)\n",
    "plt.tight_layout()\n",
    "# plt.legend()\n",
    "# legend = plt.legend()\n",
    "# frame = legend.get_frame()\n",
    "# frame.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21caa64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:02.862784Z",
     "start_time": "2022-03-03T22:43:02.507778Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at some car analysis for a random car\n",
    "generate_summary(gridsearchgb.best_estimator_.named_steps[\"model\"],X_testgb.iloc[10, :], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f913714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:03.222697Z",
     "start_time": "2022-03-03T22:43:02.864964Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Synthetic Dacia 2018, 30000miles, 120BHP\n",
    "\n",
    "make_and_predict_describe_fake_car(year = 2018,\n",
    "                      mileage = 30000,\n",
    "                      BHP = 120,\n",
    "                      body = 'Hatchback', \n",
    "                      transmission = 'Manual', \n",
    "                      make = 'Dacia', \n",
    "                      drivetrain = 'Front Wheel Drive',\n",
    "                      drs = '5dr', \n",
    "                      fuel = 'Petrol')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5deb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:03.570852Z",
     "start_time": "2022-03-03T22:43:03.225587Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Synthetic Volvo 2018, 30000miles, 120BHP\n",
    "\n",
    "make_and_predict_describe_fake_car(year = 2018,\n",
    "                      mileage = 40000,\n",
    "                      BHP = 120,\n",
    "                      body = 'Hatchback', \n",
    "                      transmission = 'Manual', \n",
    "                      make = 'Volvo', \n",
    "                      drivetrain = 'Front Wheel Drive',\n",
    "                      drs = '5dr', \n",
    "                      fuel = 'Petrol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d566c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:03.627533Z",
     "start_time": "2022-03-03T22:43:03.573037Z"
    }
   },
   "outputs": [],
   "source": [
    "refdf.groupby(by='make')['price'].mean().reset_index().sort_values('price').head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c2da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:03.634551Z",
     "start_time": "2022-03-03T22:43:03.629776Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_traingb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b23de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:04.780955Z",
     "start_time": "2022-03-03T22:43:03.636606Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Make dummy cars to test hypothesis and dummy car df \n",
    "options = ['Mercedes-Benz','Volvo','Volkswagen','SKODA','SEAT','Dacia','Audi','Ford','Citroen','Renault','Fiat','Nissan','Saab','Vauxhall','Hyundai', 'Land Rover']\n",
    "options = ['Alfa Romeo','Audi','BMW','Chevrolet','Citroen','DS Automobiles','Dacia','Fiat',\n",
    "           'Ford','Honda','Hyundai','Isuzu','Jaguar','Jeep','KIA','Land Rover','Lexus','MG',\n",
    "           'MINI','Mazda','Mercedes-Benz','Mitsubishi','Nissan','Peugeot','Porsche','Renault',\n",
    "           'SEAT','SKODA','Saab','Smart','Ssangyong','Subaru','Suzuki','Tesla','Toyota',\n",
    "           'Vauxhall','Volkswagen','Volvo']  \n",
    "equiv_cars = []\n",
    "for make in options:\n",
    "    equiv_cars.append(make_and_predict_fake_car(year = 2018, mileage = 30000, BHP = 100, make = make))\n",
    "\n",
    "equiv_cars_df = pd.DataFrame({'Make':options,'Price (£)':equiv_cars})\n",
    "equiv_cars_df = equiv_cars_df.sort_values(by='Price (£)', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "ax.bar(equiv_cars_df.Make, equiv_cars_df['Price (£)'], label = 'Predicted price for equivalent car', \n",
    "        width = 0.8, color = 'darkblue', alpha=0.8)\n",
    "barlist = ax.bar(equiv_cars_df.Make, equiv_cars_df['Price (£)'], label = 'Predicted price for equivalent car', \n",
    "        width = 0.8, color = 'darkblue', alpha=0.8)\n",
    "barlist[9].set_color('darkred')\n",
    "barlist[-3].set_color('darkred')\n",
    "ax.set_title('Predicted price of a standardised car when all attributes are the same but car brand',fontsize=12)\n",
    "ax.set_xlabel(\"Car brand\", fontsize=14)\n",
    "ax.set_ylabel(\"Predicted price (£)\", fontsize=14)\n",
    "ax.set_ylim(4000,30000)\n",
    "plt.tight_layout()\n",
    "plt.xticks(equiv_cars_df.Make, rotation=90)\n",
    "# plt.legend()\n",
    "# legend = plt.legend()\n",
    "# frame = legend.get_frame()\n",
    "# frame.set_facecolor('white')\n",
    "plt.savefig('fakecarbrand.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21e53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:04.789819Z",
     "start_time": "2022-03-03T22:43:04.784152Z"
    }
   },
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f2138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:05.164919Z",
     "start_time": "2022-03-03T22:43:04.791952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Look at some car analysis for a random car\n",
    "generate_summary(gridsearchgb.best_estimator_.named_steps[\"model\"],X_traingb.loc[123824, :], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d9733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:43:05.206700Z",
     "start_time": "2022-03-03T22:43:05.167464Z"
    }
   },
   "outputs": [],
   "source": [
    "X_testgb.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e21632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:45:44.819626Z",
     "start_time": "2022-03-03T22:45:44.158797Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def red_or_blue(x):\n",
    "    if x>0:\n",
    "        return 'darkblue'\n",
    "    else:\n",
    "        return 'darkred'\n",
    "\n",
    "breakdowndf = generate_summary(gridsearchgb.best_estimator_.named_steps[\"model\"],X_testgb.iloc[40, :], verbose=False)\n",
    "breakdowndf #= breakdowndf.sort_values(by=)\n",
    "breakdowndf['sort']=breakdowndf['Price Contribution (£)'].apply(lambda x: np.abs(x))\n",
    "breakdowndf = breakdowndf.sort_values(by='sort', ascending=False)\n",
    "breakdowndf['colour'] = breakdowndf['Price Contribution (£)'].apply(lambda x: red_or_blue(x))\n",
    "\n",
    "# edgecolor : color or list of color, optional\n",
    "#     The colors of the bar edges.\n",
    "\n",
    "# linewidth : float or array-like, optional\n",
    "#     Width of the bar edge(s). If 0, don't draw edges.\n",
    "\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(breakdowndf.index, breakdowndf['Price Contribution (£)'], color='darkblue', edgecolor= 'white', linewidth=2000)\n",
    "barlist = ax.barh(breakdowndf.index, breakdowndf['Price Contribution (£)'], color='darkblue')\n",
    "for i in range(0,10):\n",
    "    barlist[i].set_color(breakdowndf.colour[i])\n",
    "ax.set_xlim(-10000,29000)\n",
    "#ax.set_yticklabels(breakdowndf.index)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Value attributed (£)')\n",
    "ax.set_title('Car Value Breakdown', fontsize=16)\n",
    "ax.axvline(x=0,linewidth=1, color='k')\n",
    "shift=[500,-4500,500,-5000,-4500,500,-4500,500,500,400]\n",
    "for i, v in enumerate(round(breakdowndf['Price Contribution (£)'],2)):\n",
    "    ax.text(v + shift[i], i + 00.15, str(v), color='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "breakdowndf[['Attribute','Price Contribution (£)','Cumulative Car Price (£)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26b22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:46:35.245532Z",
     "start_time": "2022-03-03T22:46:34.845356Z"
    }
   },
   "outputs": [],
   "source": [
    "# George's SAAB\n",
    "\n",
    "make_and_predict_describe_fake_car(year = 2010,\n",
    "                      mileage = 117000,\n",
    "                      BHP = 137,\n",
    "                      body = 'Saloon', \n",
    "                      transmission = 'Automatic', \n",
    "                      make = 'Saab', \n",
    "                      drivetrain = 'Front Wheel Drive',\n",
    "                      drs = '5dr', \n",
    "                      fuel = 'Diesel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab3f40",
   "metadata": {},
   "source": [
    "\n",
    "## Used cars - All data - varying predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ba6e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:35:16.465755Z",
     "start_time": "2022-02-17T09:35:16.460971Z"
    }
   },
   "source": [
    "### LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bd2db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:46:50.224094Z",
     "start_time": "2022-03-03T22:46:45.118463Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling on data without dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# Prep test/train for modelling without dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "df = pd.read_csv(abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "# Save copy for later if needed\n",
    "refdf = df.copy()\n",
    "\n",
    "# Select used cars only\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop columns not needed\n",
    "df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "                     'href0','dealer_city','dealer_area','year_reg',\n",
    "                     'orig_name','e_engine_kWh','dealer_lat',\n",
    "                     'dealer_lon','ULEZ','id','used'], axis=1)\n",
    "print('used_without_extra_columns', df.shape)\n",
    "\n",
    "# Drop under represented car makes\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "print('used_without_little_makes', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['log_price','log_mileage','year','BHP']]\n",
    "y = X.pop('log_price')\n",
    "print('Df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_trainlr_cont, X_testlr_cont, y_trainlr_cont, y_testlr_cont = train_test_split(X,y,test_size=0.2, shuffle=y, random_state = 2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LinearRegression()\n",
    "pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "#pipelr.get_params()\n",
    "\n",
    "params = {'model__copy_X': [True],\n",
    "          'model__fit_intercept': [True],\n",
    "          'model__n_jobs': [2],\n",
    "          'model__normalize': [False],\n",
    "          'model__positive': [False]}\n",
    "\n",
    "gridsearchlr_cont = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "gridsearchlr_cont.fit(X_trainlr_cont, y_trainlr_cont)\n",
    "\n",
    "# LinearRegression Model\n",
    "lrtrain_preds_cont = gridsearchlr_cont.predict(X_trainlr_cont)\n",
    "lrtest_preds_cont = gridsearchlr_cont.predict(X_testlr_cont)\n",
    "printmd('**LINEAR REGRESSION WITH CONTINUOUS VARIABLES ONLY**')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_trainlr_cont), np.exp(lrtrain_preds_cont)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_testlr_cont), np.exp(lrtest_preds_cont)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_trainlr_cont), np.exp(lrtrain_preds_cont)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_testlr_cont), np.exp(lrtest_preds_cont)))))\n",
    "print('R2 train on log_price:',gridsearchlr_cont.score(X_trainlr_cont, y_trainlr_cont))\n",
    "print('R2 test on log_price:',gridsearchlr_cont.score(X_testlr_cont, y_testlr_cont))\n",
    "print('R2 train on price:',r2_score(np.exp(y_trainlr_cont), np.exp(lrtrain_preds_cont)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_testlr_cont), np.exp(lrtest_preds_cont)))\n",
    "print('\\n')\n",
    "print(gridsearchlr_cont.best_estimator_)\n",
    "\n",
    "lrdict_cont = {'Model': 'Linear Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_trainlr_cont), np.exp(lrtrain_preds_cont)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_testlr_cont), np.exp(lrtest_preds_cont)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_trainlr_cont), np.exp(lrtrain_preds_cont))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_testlr_cont), np.exp(lrtest_preds_cont))),\n",
    "          'R2 Train': r2_score(np.exp(y_trainlr_cont), np.exp(lrtrain_preds_cont)),\n",
    "          'R2 Test': r2_score(np.exp(y_testlr_cont), np.exp(lrtest_preds_cont)),\n",
    "          'Params': gridsearchlr_cont.best_estimator_\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43d0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:47:01.776692Z",
     "start_time": "2022-03-03T22:46:50.227321Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "df = pd.read_csv(abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "refdf = df.copy()\n",
    "\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop not needed columns\n",
    "df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "                     'href0','dealer_city','dealer_area','year_reg',\n",
    "                     'orig_name','e_engine_kWh','dealer_lat',\n",
    "                     'dealer_lon','ULEZ','id','used'], axis=1)\n",
    "print('used_without_extra_columns', df.shape)\n",
    "\n",
    "# Drop under represented car makes\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "\n",
    "print('used_without_little_makes', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_trainlr, X_testlr, y_trainlr, y_testlr = train_test_split(X,y,test_size=0.2, shuffle=y,random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LinearRegression()\n",
    "pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "#pipelr.get_params()\n",
    "\n",
    "params = {'model__copy_X': [True],\n",
    "          'model__fit_intercept': [True],\n",
    "          'model__n_jobs': [2],\n",
    "          'model__normalize': [False],\n",
    "          'model__positive': [False]}\n",
    "\n",
    "gridsearchlr = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "gridsearchlr.fit(X_trainlr, y_trainlr)\n",
    "\n",
    "# LinearRegression Model\n",
    "lrtrain_preds = gridsearchlr.predict(X_trainlr)\n",
    "lrtest_preds = gridsearchlr.predict(X_testlr)\n",
    "printmd('**LINEAR REGRESSION WITH CONTINUOUS VARIABLES AND DUMMIES**')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds)))))\n",
    "print('R2 train on log_price:',gridsearchlr.score(X_trainlr, y_trainlr))\n",
    "print('R2 test on log_price:',gridsearchlr.score(X_testlr, y_testlr))\n",
    "print('R2 train on price:',r2_score(np.exp(y_trainlr), np.exp(lrtrain_preds)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_testlr), np.exp(lrtest_preds)))\n",
    "print('\\n')\n",
    "print(gridsearchlr.best_estimator_)\n",
    "\n",
    "lrdict2 = {'Model': 'Linear Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_trainlr), np.exp(lrtrain_preds))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_testlr), np.exp(lrtest_preds))),\n",
    "          'R2 Train': r2_score(np.exp(y_trainlr), np.exp(lrtrain_preds)),\n",
    "          'R2 Test': r2_score(np.exp(y_testlr), np.exp(lrtest_preds)),\n",
    "          'Params': gridsearchlr.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48318db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:47:13.606770Z",
     "start_time": "2022-03-03T22:47:01.779208Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Modelling on data with dummies and latlon - SKLEARN LinearRegression() \n",
    "\n",
    "# Prep test/train for modelling with latlon and dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "df = pd.read_csv(abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "# Save a copy of the data for later\n",
    "refdf = df.copy()\n",
    "\n",
    "# Select used cars only\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop not needed columns\n",
    "df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "                     'href0','dealer_city','dealer_area','year_reg',\n",
    "                     'orig_name','e_engine_kWh',\n",
    "                     'ULEZ','id','used'], axis=1)\n",
    "print('used_without_extra_columns', df.shape)\n",
    "\n",
    "# Drop under represented car makes\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "print('used_without_little_makes', df.shape)\n",
    "\n",
    "# Drop cars without lat/lon\n",
    "df.dropna(subset = ['dealer_lat'], inplace=True)\n",
    "print('used_without_nan_latlon', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','dealer_lat','dealer_lon']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_trainlr_ll, X_testlr_ll, y_trainlr_ll, y_testlr_ll = train_test_split(X,y,test_size=0.2, shuffle=y,random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LinearRegression()\n",
    "pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "#pipelr.get_params()\n",
    "\n",
    "params = {'model__copy_X': [True],\n",
    "          'model__fit_intercept': [True],\n",
    "          'model__n_jobs': [2],\n",
    "          'model__normalize': [False],\n",
    "          'model__positive': [False]}\n",
    "\n",
    "gridsearchlr_ll = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "gridsearchlr_ll.fit(X_trainlr_ll, y_trainlr_ll)\n",
    "\n",
    "# LinearRegression Model\n",
    "lrtrain_preds_ll = gridsearchlr_ll.predict(X_trainlr_ll)\n",
    "lrtest_preds_ll = gridsearchlr_ll.predict(X_testlr_ll)\n",
    "printmd('**LINEAR REGRESSION WITH CONTINUOUS VARIABLES, DUMMIES AND LAT-LON**')\n",
    "print('MSE train:',mean_squared_error(np.exp(y_trainlr_ll), np.exp(lrtrain_preds_ll)))\n",
    "print('MSE test:',mean_squared_error(np.exp(y_testlr_ll), np.exp(lrtest_preds_ll)))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_trainlr_ll), np.exp(lrtrain_preds_ll)))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_testlr_ll), np.exp(lrtest_preds_ll)))))\n",
    "print('R2 train on log_price:',gridsearchlr_ll.score(X_trainlr_ll, y_trainlr_ll))\n",
    "print('R2 test on log_price:',gridsearchlr_ll.score(X_testlr_ll, y_testlr_ll))\n",
    "print('R2 train on price:',r2_score(np.exp(y_trainlr_ll), np.exp(lrtrain_preds_ll)))\n",
    "print('R2 test on price:',r2_score(np.exp(y_testlr_ll), np.exp(lrtest_preds_ll)))\n",
    "print('\\n')\n",
    "print(gridsearchlr_ll.best_estimator_)\n",
    "\n",
    "lrdict_ll = {'Model': 'Linear Regression', \n",
    "          'MSE Train': mean_squared_error(np.exp(y_trainlr_ll), np.exp(lrtrain_preds_ll)),\n",
    "          'MSE Test': mean_squared_error(np.exp(y_testlr_ll), np.exp(lrtest_preds_ll)),\n",
    "          'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_trainlr_ll), np.exp(lrtrain_preds_ll))),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_testlr_ll), np.exp(lrtest_preds_ll))),\n",
    "          'R2 Train': r2_score(np.exp(y_trainlr_ll), np.exp(lrtrain_preds_ll)),\n",
    "          'R2 Test': r2_score(np.exp(y_testlr_ll), np.exp(lrtest_preds_ll)),\n",
    "          'Params': gridsearchlr_ll.best_estimator_\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a9553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:47:13.619924Z",
     "start_time": "2022-03-03T22:47:13.611963Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Prep test/train for modelling with area and dummies - SKLEARN LinearRegression() - Needs work if I get time \n",
    "\n",
    "# # Read clean used cars data, drop columns not useful in modelling and drop under populated areas\n",
    "\n",
    "# abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "# df = pd.read_csv(abspath)\n",
    "# print('all',df.shape)\n",
    "\n",
    "# refdf = df.copy()\n",
    "\n",
    "# df = df[df['used']==1]\n",
    "# print('used',df.shape)\n",
    "\n",
    "# mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_outliers',df.shape)\n",
    "\n",
    "# df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "#                      'href0','dealer_city','year_reg',\n",
    "#                      'orig_name','e_engine_kWh','dealer_lat',\n",
    "#                      'dealer_lon','ULEZ','id','used'], axis=1)\n",
    "\n",
    "# print('used_without_extra_columns', df.shape)\n",
    "\n",
    "# df.dropna(subset = ['dealer_area'], inplace=True)\n",
    "# print('used_without_nan_dealer_area', df.shape)\n",
    "\n",
    "# tempdf = df.groupby(by='dealer_area')[['price']].count().sort_values(by='price')\n",
    "# tempdf = tempdf[tempdf.price>100].reset_index()\n",
    "# templist = tempdf.dealer_area.to_list()\n",
    "\n",
    "# areas = []\n",
    "# for a in templist:\n",
    "#     if '/' in a:\n",
    "#         pass\n",
    "# #        print(a)\n",
    "#     if '#' in a:\n",
    "#         pass\n",
    "# #        print(a)\n",
    "# #     elif a=='essex-':\n",
    "# #         a='essex'\n",
    "# #         areas.append(a)\n",
    "#     else:\n",
    "#         areas.append(a)\n",
    "\n",
    "# df = df[df.dealer_area.isin(areas)].copy()\n",
    "# print('used_without_dealer_area<100', df.shape)\n",
    "\n",
    "# # Dummify necessary columns \n",
    "# X = df[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "#         'make','body','transmission','fuel','doors','dealer_area']]\n",
    "# y = X.pop('log_price')\n",
    "# to_dummy=['drivertrain','make','body','transmission','fuel','doors','dealer_area']\n",
    "# X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "# print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# # Train test split\n",
    "# X_trainlr_a, X_testlr_a, y_trainlr_a, y_testlr_a = train_test_split(X,y,test_size=0.2, shuffle=y,random_state = 42)\n",
    "\n",
    "# # Modelling on data with dummies and latlon - SKLEARN LinearRegression() \n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# lr = LinearRegression()\n",
    "# pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "# #pipelr.get_params()\n",
    "\n",
    "# params = {'model__copy_X': [True],\n",
    "#           'model__fit_intercept': [True],\n",
    "#           'model__n_jobs': [2],\n",
    "#           'model__normalize': [False],\n",
    "#           'model__positive': [False]}\n",
    "\n",
    "# gridsearchlr_a = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "# gridsearchlr_a.fit(X_trainlr_a, y_trainlr_a)\n",
    "\n",
    "# # LinearRegression Model\n",
    "# lrtrain_preds_a = gridsearchlr_a.predict(X_trainlr_a)\n",
    "# lrtest_preds_a = gridsearchlr_a.predict(X_testlr_a)\n",
    "# printmd('**LINEAR REGRESSION WITH CONTINUOUS VARIABLES, DUMMIES AND AREA**')\n",
    "# print('MSE train:',mean_squared_error(np.exp(y_trainlr_a), np.exp(lrtrain_preds_a)))\n",
    "# print('MSE test:',mean_squared_error(np.exp(y_testlr_a), np.exp(lrtest_preds_a)))\n",
    "# print('RMSE train:',np.sqrt((mean_squared_error(np.exp(y_trainlr_a), np.exp(lrtrain_preds_a)))))\n",
    "# print('RMSE test:',np.sqrt((mean_squared_error(np.exp(y_testlr_a), np.exp(lrtest_preds_a)))))\n",
    "# print('R2 train:',gridsearchlr_a.score(X_trainlr_a, y_trainlr_a))\n",
    "# print('R2 test:',gridsearchlr_a.score(X_testlr_a, y_testlr_a))\n",
    "# print('\\n')\n",
    "# print(gridsearchlr_a.best_estimator_)\n",
    "\n",
    "# lrdict_a = {'Model': 'Linear Regression', \n",
    "#           'MSE Train': mean_squared_error(np.exp(y_trainlr_a), np.exp(lrtrain_preds_a)),\n",
    "#           'MSE Test': mean_squared_error(np.exp(y_testlr_a), np.exp(lrtest_preds_a)),\n",
    "#           'RMSE Train': np.sqrt(mean_squared_error(np.exp(y_trainlr_a), np.exp(lrtrain_preds_a))),\n",
    "#           'RMSE Test': np.sqrt(mean_squared_error(np.exp(y_testlr_a), np.exp(lrtest_preds_a))),\n",
    "#           'R2 Train': gridsearchlr_a.score(X_trainlr_a, y_trainlr_a),\n",
    "#           'R2 Test': gridsearchlr_a.score(X_testlr_a, y_testlr_a),\n",
    "#           'Params': gridsearchlr_a.best_estimator_\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4faa2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:47:13.630035Z",
     "start_time": "2022-03-03T22:47:13.623026Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Modelling with bootsize and dummies - SKLEARN LinearRegression() - Not got round to this yet\n",
    "\n",
    "# # Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "\n",
    "# abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/00_all_cars.csv'\n",
    "# df = pd.read_csv(abspath)\n",
    "# print('all',df.shape)\n",
    "\n",
    "# refdf = df.copy()\n",
    "\n",
    "# df = df[df['used']==1]\n",
    "# print('used',df.shape)\n",
    "\n",
    "# mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_outliers',df.shape)\n",
    "\n",
    "# df = df.drop(labels=['name','name_subtitle','link','seller1',\n",
    "#                      'href0','dealer_city','dealer_area','year_reg',\n",
    "#                      'orig_name','e_engine_kWh','dealer_lat',\n",
    "#                      'dealer_lon','ULEZ','id','used'], axis=1)\n",
    "\n",
    "# print('used_without_extra_columns', df.shape)\n",
    "\n",
    "# carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "# carmakes = carnums[carnums.price>200].make.to_list()\n",
    "# df = df[df.make.isin(carmakes)].copy()\n",
    "\n",
    "# print('used_without_little_makes', df.shape)\n",
    "\n",
    "# # Dummify necessary columns \n",
    "# X = df[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "#         'make','body','transmission','fuel','doors']]\n",
    "# y = X.pop('log_price')\n",
    "# to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "# X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "# print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# # Train test split\n",
    "# X_trainlr, X_testlr, y_trainlr, y_testlr = train_test_split(X,y,test_size=0.2, shuffle=y,)\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # lr = LinearRegression()\n",
    "# # pipelr = Pipeline(steps=[('scaler',scaler),('model',lr)])\n",
    "# # #pipelr.get_params()\n",
    "\n",
    "# # params = {'model__copy_X': [True],\n",
    "# #           'model__fit_intercept': [True],\n",
    "# #           'model__n_jobs': [2],\n",
    "# #           'model__normalize': [False],\n",
    "# #           'model__positive': [False]}\n",
    "\n",
    "# # gridsearchlr = GridSearchCV(pipelr, params, cv=5, verbose=1)\n",
    "# # gridsearchlr.fit(X_trainlr, y_trainlr)\n",
    "\n",
    "# # # LinearRegression Model\n",
    "# # lrtrain_preds = gridsearchlr.predict(X_trainlr)\n",
    "# # lrtest_preds = gridsearchlr.predict(X_testlr)\n",
    "# # printmd('**LINEAR REGRESSION WITH CONTINUOUS VARIABLES AND DUMMIES**')\n",
    "# # print('MSE train:',mean_squared_error(y_trainlr, lrtrain_preds))\n",
    "# # print('MSE test:',mean_squared_error(y_testlr, lrtest_preds))\n",
    "# # print('R2 train:',gridsearchlr.score(X_trainlr, y_trainlr))\n",
    "# # print('R2 test:',gridsearchlr.score(X_testlr, y_testlr))\n",
    "# # print('\\n')\n",
    "# # print(gridsearchlr.best_estimator_)\n",
    "\n",
    "# # lrdict2 = {'Model': 'Linear Regression', \n",
    "# #           'MSE Train': mean_squared_error(y_trainlr, lrtrain_preds),\n",
    "# #           'MSE Test': mean_squared_error(y_testlr, lrtest_preds), \n",
    "# #           'R2 Train': gridsearchlr.score(X_trainlr, y_trainlr),\n",
    "# #           'R2 Test': gridsearchlr.score(X_testlr, y_testlr),\n",
    "# #           'Params': gridsearchlr.best_estimator_\n",
    "# #          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775cb6a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:47:13.657862Z",
     "start_time": "2022-03-03T22:47:13.633619Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Summary dataframe of results \n",
    "lrdict2['Input data'] = 'Continuous plus dummies'\n",
    "lrdict_cont['Input data'] = 'Continuous only'\n",
    "lrdict_ll['Input data'] = 'Continuous plus dummies plus lat/lon'\n",
    "#lrdict_a['Input data'] = 'Continuous plus dummies plus county'\n",
    "pd.DataFrame([lrdict_cont,lrdict2,lrdict_ll])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7405b",
   "metadata": {},
   "source": [
    "*This is a bit disappointing! Adding latitude and longitude hasn't really helped much. Adding county info seems a little better, but still not earth shattering. If I had more time I'd try to better engineer these into counties but no time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aeba26",
   "metadata": {},
   "source": [
    "### GradientBoostingRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043aa6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:48:01.686176Z",
     "start_time": "2022-03-03T22:47:57.561822Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Prep data, called df\n",
    "\n",
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "df = pd.read_csv(cars_abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "# Save copy for later if needed\n",
    "refdf = df.copy()\n",
    "\n",
    "# Select used cars only\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop under represented car makes\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "print('used_without_little_makes', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0798ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T22:52:36.931889Z",
     "start_time": "2022-03-03T22:48:01.689001Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling on data without dummies - SKLEARN GradientBoostingRegression() \n",
    "\n",
    "# Prep test/train for modelling without dummies - SKLEARN GradientBoostingRegression() \n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['price','mileage','year','BHP']]\n",
    "y = X.pop('price')\n",
    "print('Df shape',X.shape,'\\n')\n",
    "\n",
    "X_traingb_cont, X_testgb_cont, y_traingb_cont, y_testgb_cont = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[3,5],\n",
    "#           'model__learning_rate':[0.05, 0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "# criterion{‘friedman_mse’, ‘squared_error’, ‘mse’, ‘mae’}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[5],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb_cont = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb_cont.fit(X_traingb_cont, y_traingb_cont)\n",
    "\n",
    "# GradientBoostingRegressor() Model\n",
    "gbtrain_preds_cont = gridsearchgb_cont.predict(X_traingb_cont)\n",
    "gbtest_preds_cont = gridsearchgb_cont.predict(X_testgb_cont)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH CONTINUOUS VARIABLES ONLY**')\n",
    "print('MSE train:',mean_squared_error(y_traingb_cont, gbtrain_preds_cont))\n",
    "print('MSE test:',mean_squared_error(y_testgb_cont, gbtest_preds_cont))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb_cont, gbtrain_preds_cont))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb_cont, gbtest_preds_cont))))\n",
    "print('R2 train on price:',gridsearchgb_cont.score(X_traingb_cont, y_traingb_cont))\n",
    "print('R2 test on price:',gridsearchgb_cont.score(X_testgb_cont, y_testgb_cont))\n",
    "\n",
    "print('\\n')\n",
    "print(gridsearchgb_cont.best_estimator_)\n",
    "\n",
    "gbdict_cont = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb_cont, gbtrain_preds_cont),\n",
    "          'MSE Test': mean_squared_error(y_testgb_cont, gbtest_preds_cont), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb_cont, gbtrain_preds_cont)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb_cont, gbtest_preds_cont)),\n",
    "          'R2 Train': gridsearchgb_cont.score(X_traingb_cont, y_traingb_cont),\n",
    "          'R2 Test': gridsearchgb_cont.score(X_testgb_cont, y_testgb_cont),\n",
    "          'Params': gridsearchgb_cont.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a531e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T23:09:17.308273Z",
     "start_time": "2022-03-03T22:52:36.934518Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling with dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# # Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "# cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "# df = pd.read_csv(cars_abspath)\n",
    "# print('all',df.shape)\n",
    "\n",
    "# # Save copy for later if needed\n",
    "# refdf = df.copy()\n",
    "\n",
    "# # Select used cars only\n",
    "# df = df[df['used']==1]\n",
    "# print('used',df.shape)\n",
    "\n",
    "# # Drop outliers in log-price\n",
    "# mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in log-mileage\n",
    "# mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in BHP\n",
    "# mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "# df= df[~mask]\n",
    "# print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# # Drop under represented car makes\n",
    "# carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "# carmakes = carnums[carnums.price>200].make.to_list()\n",
    "# df = df[df.make.isin(carmakes)].copy()\n",
    "# print('used_without_little_makes', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_traingb2, X_testgb2, y_traingb2, y_testgb2 = train_test_split(X,y,test_size=0.2, shuffle=y,random_state = 2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb2 = Pipeline(steps=[('model',model)])\n",
    "pipegb2.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[3,5],\n",
    "#           'model__learning_rate':[0.05, 0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "# criterion{‘friedman_mse’, ‘squared_error’, ‘mse’, ‘mae’}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[5],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb2 = GridSearchCV(pipegb2, params, cv=5, verbose=1)\n",
    "gridsearchgb2.fit(X_traingb2, y_traingb2)\n",
    "\n",
    "# GradientBoostingRegressor() Model\n",
    "gbtrain_preds2 = gridsearchgb2.predict(X_traingb2)\n",
    "gbtest_preds2 = gridsearchgb2.predict(X_testgb2)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH CONTINUOUS VARIABLES AND DUMMIES**')\n",
    "print('MSE train:',mean_squared_error(y_traingb2, gbtrain_preds2))\n",
    "print('MSE test:',mean_squared_error(y_testgb2, gbtest_preds2))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb2, gbtrain_preds2))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb2, gbtest_preds2))))\n",
    "print('R2 train on price:',gridsearchgb2.score(X_traingb2, y_traingb2))\n",
    "print('R2 test on price:',gridsearchgb2.score(X_testgb2, y_testgb2))\n",
    "print('\\n')\n",
    "print(gridsearchgb.best_estimator_)\n",
    "\n",
    "gbdict2 = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb2, gbtrain_preds2),\n",
    "          'MSE Test': mean_squared_error(y_testgb2, gbtest_preds2), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb2, gbtrain_preds2)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb2, gbtest_preds2)),\n",
    "          'R2 Train': gridsearchgb2.score(X_traingb2, y_traingb2),\n",
    "          'R2 Test': gridsearchgb2.score(X_testgb2, y_testgb2),\n",
    "          'Params': gridsearchgb2.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69fbaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T10:55:55.504796Z",
     "start_time": "2022-03-04T10:36:55.163772Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling on data with dummies and latlon - SKLEARN LinearRegression() \n",
    "\n",
    "# Prep test/train for modelling with latlon and dummies - SKLEARN LinearRegression() \n",
    "\n",
    "# # Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "# cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "# df = pd.read_csv(cars_abspath)\n",
    "# print('all',df.shape)\n",
    "\n",
    "# # Save copy for later if needed\n",
    "# refdf = df.copy()\n",
    "\n",
    "# # Select used cars only\n",
    "# df = df[df['used']==1]\n",
    "# print('used',df.shape)\n",
    "\n",
    "# # Drop outliers in log-price\n",
    "# mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in log-mileage\n",
    "# mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in BHP\n",
    "# mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "# df= df[~mask]\n",
    "# print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# # Drop under represented car makes\n",
    "# carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "# carmakes = carnums[carnums.price>200].make.to_list()\n",
    "# df = df[df.make.isin(carmakes)].copy()\n",
    "# print('used_without_little_makes', df.shape)\n",
    "\n",
    "# # Drop cars without lat/lon\n",
    "# df.dropna(subset = ['dealer_lat'], inplace=True)\n",
    "# print('used_without_nan_latlon', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','dealer_lat','dealer_lon']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_traingb_ll, X_testgb_ll, y_traingb_ll, y_testgb_ll = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[3,5],\n",
    "#           'model__learning_rate':[0.05, 0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "# criterion{‘friedman_mse’, ‘squared_error’, ‘mse’, ‘mae’}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[5],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb_ll = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb_ll.fit(X_traingb_ll, y_traingb_ll)\n",
    "\n",
    "# GradientBoostingRegressor() Model\n",
    "gbtrain_preds_ll = gridsearchgb_ll.predict(X_traingb_ll)\n",
    "gbtest_preds_ll = gridsearchgb_ll.predict(X_testgb_ll)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH CONTINUOUS VARIABLES, LAT/LON AND DUMMIES**')\n",
    "print('MSE train:',mean_squared_error(y_traingb_ll, gbtrain_preds_ll))\n",
    "print('MSE test:',mean_squared_error(y_testgb_ll, gbtest_preds_ll))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb_ll, gbtrain_preds_ll))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb_ll, gbtest_preds_ll))))\n",
    "print('R2 train on price:',gridsearchgb_ll.score(X_traingb_ll, y_traingb_ll))\n",
    "print('R2 test on price:',gridsearchgb_ll.score(X_testgb_ll, y_testgb_ll))\n",
    "print('\\n')\n",
    "print(gridsearchgb_ll.best_estimator_)\n",
    "\n",
    "gbdict_ll = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb_ll, gbtrain_preds_ll),\n",
    "          'MSE Test': mean_squared_error(y_testgb_ll, gbtest_preds_ll), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb_ll, gbtrain_preds_ll)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb_ll, gbtest_preds_ll)),\n",
    "          'R2 Train': gridsearchgb_ll.score(X_traingb_ll, y_traingb_ll),\n",
    "          'R2 Test': gridsearchgb_ll.score(X_testgb_ll, y_testgb_ll),\n",
    "          'Params': gridsearchgb_ll.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035f69d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T09:50:04.813398Z",
     "start_time": "2022-03-04T08:57:38.333627Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Modelling on data with dummies and county - SKLEARN GradientBoostingRegression() \n",
    "\n",
    "# Prep test/train for modelling without dummies - SKLEARN GradientBoostingRegression() \n",
    "\n",
    "# # Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "# cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "# df = pd.read_csv(cars_abspath)\n",
    "# print('all',df.shape)\n",
    "\n",
    "# # Save copy for later if needed\n",
    "# refdf = df.copy()\n",
    "\n",
    "# # Select used cars only\n",
    "# df = df[df['used']==1]\n",
    "# print('used',df.shape)\n",
    "\n",
    "# # Drop outliers in log-price\n",
    "# mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in log-mileage\n",
    "# mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in BHP\n",
    "# mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "# df= df[~mask]\n",
    "# print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# # Drop under represented car makes\n",
    "# carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "# carmakes = carnums[carnums.price>200].make.to_list()\n",
    "# df = df[df.make.isin(carmakes)].copy()\n",
    "# print('used_without_little_makes', df.shape)\n",
    "\n",
    "# # Drop cars without lat/lon\n",
    "# df.dropna(subset = ['dealer_lat'], inplace=True)\n",
    "# print('used_without_nan_latlon', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','county']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors','county']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "X_traingb_county, X_testgb_county, y_traingb_county, y_testgb_county = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[3,5],\n",
    "#           'model__learning_rate':[0.05, 0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "# criterion{‘friedman_mse’, ‘squared_error’, ‘mse’, ‘mae’}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[5],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb_county = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb_county.fit(X_traingb_county, y_traingb_county)\n",
    "\n",
    "# GradientBoostingRegressor() Model\n",
    "gbtrain_preds_county = gridsearchgb_county.predict(X_traingb_county)\n",
    "gbtest_preds_county = gridsearchgb_county.predict(X_testgb_county)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH COUNTY**')\n",
    "print('MSE train:',mean_squared_error(y_traingb_county, gbtrain_preds_county))\n",
    "print('MSE test:',mean_squared_error(y_testgb_county, gbtest_preds_county))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb_county, gbtrain_preds_county))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb_county, gbtest_preds_county))))\n",
    "print('R2 train on price:',gridsearchgb_county.score(X_traingb_county, y_traingb_county))\n",
    "print('R2 test on price:',gridsearchgb_county.score(X_testgb_county, y_testgb_county))\n",
    "print('\\n')\n",
    "print(gridsearchgb_county.best_estimator_)\n",
    "\n",
    "gbdict_county = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb_county, gbtrain_preds_county),\n",
    "          'MSE Test': mean_squared_error(y_testgb_county, gbtest_preds_county), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb_county, gbtrain_preds_county)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb_county, gbtest_preds_county)),\n",
    "          'R2 Train': gridsearchgb_county.score(X_traingb_county, y_traingb_county),\n",
    "          'R2 Test': gridsearchgb_county.score(X_testgb_county, y_testgb_county),\n",
    "          'Params': gridsearchgb_county.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcff65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T10:06:09.137727Z",
     "start_time": "2022-03-04T09:50:04.833606Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelling on data with dummies and cargo_vol_L - SKLEARN GradientBoostingRegression() \n",
    "\n",
    "# Prep test/train for modelling without dummies - SKLEARN GradientBoostingRegression() \n",
    "\n",
    "# # Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "# cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "# df = pd.read_csv(cars_abspath)\n",
    "# print('all',df.shape)\n",
    "\n",
    "# # Save copy for later if needed\n",
    "# refdf = df.copy()\n",
    "\n",
    "# # Select used cars only\n",
    "# df = df[df['used']==1]\n",
    "# print('used',df.shape)\n",
    "\n",
    "# # Drop outliers in log-price\n",
    "# mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in log-mileage\n",
    "# mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "# df= df[~mask]\n",
    "# print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# # Drop outliers in BHP\n",
    "# mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "# df= df[~mask]\n",
    "# print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# # Drop under represented car makes\n",
    "# carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "# carmakes = carnums[carnums.price>200].make.to_list()\n",
    "# df = df[df.make.isin(carmakes)].copy()\n",
    "# print('used_without_little_makes', df.shape)\n",
    "\n",
    "# # Drop cars without lat/lon\n",
    "# df.dropna(subset = ['dealer_lat'], inplace=True)\n",
    "# print('used_without_nan_latlon', df.shape)\n",
    "\n",
    "# Dummify necessary columns \n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','cargo_volume_L']]\n",
    "y = X.pop('price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "X_traingb_boot, X_testgb_boot, y_traingb_boot, y_testgb_boot = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = GradientBoostingRegressor()\n",
    "#pipegb = Pipeline(steps=[('scaler',scaler),('model',model)])\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "# params = {'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[3,5],\n",
    "#           'model__learning_rate':[0.05, 0.1],\n",
    "#           'model__random_state':[1],\n",
    "#           'model__validation_fraction':[0.1],\n",
    "#           'model__n_iter_no_change':[20]}\n",
    "\n",
    "# criterion{‘friedman_mse’, ‘squared_error’, ‘mse’, ‘mae’}\n",
    "\n",
    "params = {'model__n_estimators':[200],\n",
    "          'model__max_depth':[5],\n",
    "          'model__learning_rate':[0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb_boot = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb_boot.fit(X_traingb_boot, y_traingb_boot)\n",
    "\n",
    "# GradientBoostingRegressor() Model\n",
    "gbtrain_preds_boot = gridsearchgb_boot.predict(X_traingb_boot)\n",
    "gbtest_preds_boot = gridsearchgb_boot.predict(X_testgb_boot)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH CARGO VOLUME**')\n",
    "print('MSE train:',mean_squared_error(y_traingb_boot, gbtrain_preds_boot))\n",
    "print('MSE test:',mean_squared_error(y_testgb_boot, gbtest_preds_boot))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb_boot, gbtrain_preds_boot))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb_boot, gbtest_preds_boot))))\n",
    "print('R2 train on price:',gridsearchgb_boot.score(X_traingb_boot, y_traingb_boot))\n",
    "print('R2 test on price:',gridsearchgb_boot.score(X_testgb_boot, y_testgb_boot))\n",
    "print('\\n')\n",
    "print(gridsearchgb_boot.best_estimator_)\n",
    "\n",
    "gbdict_boot = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb_boot, gbtrain_preds_boot),\n",
    "          'MSE Test': mean_squared_error(y_testgb_boot, gbtest_preds_boot), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb_boot, gbtrain_preds_boot)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb_boot, gbtest_preds_boot)),\n",
    "          'R2 Train': gridsearchgb_boot.score(X_traingb_boot, y_traingb_boot),\n",
    "          'R2 Test': gridsearchgb_boot.score(X_testgb_boot, y_testgb_boot),\n",
    "          'Params': gridsearchgb_boot.best_estimator_\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fcc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T11:42:38.609434Z",
     "start_time": "2022-03-04T11:42:38.119544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summary dataframe of results \n",
    "gbdict2['Input data'] = 'Continuous plus dummies'\n",
    "gbdict_cont['Input data'] = 'Continuous only'\n",
    "gbdict_ll['Input data'] = 'Continuous plus dummies plus lat/lon'\n",
    "gbdict_county['Input data'] = 'Continuous plus dummies plus county'\n",
    "gbdict_boot['Input data'] = 'Continuous plus dummies plus boot volume'\n",
    "\n",
    "pd.DataFrame([gbdict_cont,gbdict2,gbdict_ll,gbdict_county,gbdict_boot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbe560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T11:42:39.784542Z",
     "start_time": "2022-03-04T11:42:39.760776Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_resid_cont = y_testgb_cont - gbtest_preds_cont\n",
    "gb_resid2 = y_testgb2 - gbtest_preds2\n",
    "gb_resid_ll = y_testgb_ll - gbtest_preds_ll\n",
    "gb_resid_county = y_testgb_county - gbtest_preds_county\n",
    "gb_resid_boot = y_testgb_boot - gbtest_preds_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20c4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T11:42:46.456444Z",
     "start_time": "2022-03-04T11:42:44.513918Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Ambitious Residuals plot - needs work on X-axis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Make the input data - really clumsy.\n",
    "gb_resid_cont_df = pd.DataFrame(gb_resid_cont)\n",
    "gb_resid_cont_df['model']='Continuous Predictors Only  R2 = 0.877'\n",
    "gb_resid_df2 = pd.DataFrame(gb_resid2)\n",
    "gb_resid_df2['model']='Original Predictors:   R2 = 0.954'\n",
    "gb_resid_county_df = pd.DataFrame(gb_resid_county)\n",
    "gb_resid_county_df['model']='Original Predictors + County:    R2 = 0.956'\n",
    "gb_resid_boot_df = pd.DataFrame(gb_resid_boot)\n",
    "gb_resid_boot_df['model']='Original Predictors + Boot Size:    R2 = 0.968'\n",
    "\n",
    "\n",
    "tocat=[gb_resid_df2,gb_resid_county_df,gb_resid_boot_df,]\n",
    "residplotdf = pd.concat(tocat)\n",
    "residplotdf.columns = ['Residual Price (£)', 'model']\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(10, rot=-.1, light=.5)\n",
    "g = sns.FacetGrid(residplotdf, row=\"model\", hue=\"model\", aspect=15, height=1.5, palette=pal)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Residual Price (£)\",\n",
    "      bw_adjust=.5, clip_on=True,\n",
    "      fill=True, alpha=1, linewidth=1)\n",
    "g.map(sns.kdeplot, \"Residual Price (£)\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "#g.refline(y=0, linewidth=2,linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "g.map(label, \"Residual Price (£)\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.25)\n",
    "#setting xticks\n",
    "\n",
    "ticks = [-10000, 0, 10000]\n",
    "labels = [i for i in ticks]\n",
    "g.set(xticks = ticks, xticklabels = labels)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "plt.title('Summary plot of tested models with R2 and residual distribution',x=0.14, y=2.45, fontsize=14)\n",
    "g.despine(bottom=True, left=True)\n",
    "plt.savefig('furthermodelsummary.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ee43a",
   "metadata": {},
   "source": [
    "# Neural Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58eb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:12:34.744930Z",
     "start_time": "2022-02-24T14:12:34.739628Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer as Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d192f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:14:00.104831Z",
     "start_time": "2022-02-24T14:13:56.164873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prep data, called df\n",
    "\n",
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "df = pd.read_csv(cars_abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "# Save copy for later if needed\n",
    "refdf = df.copy()\n",
    "\n",
    "# Select used cars only\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop under represented car makes\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "print('used_without_little_makes', df.shape)\n",
    "\n",
    "dfsample = df.sample(50000, random_state=1)\n",
    "carnums = dfsample.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>50].make.to_list()\n",
    "dfsample = dfsample[dfsample.make.isin(carmakes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a4a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:18:38.207564Z",
     "start_time": "2022-02-24T14:18:38.203026Z"
    }
   },
   "outputs": [],
   "source": [
    "dfsample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d2a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd66fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f80d2766",
   "metadata": {},
   "source": [
    "### Copying lesson exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeab22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:14:00.111043Z",
     "start_time": "2022-02-24T14:14:00.107296Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create a helper class to extract features one by one in a pipeline \n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7934d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:18:59.738105Z",
     "start_time": "2022-02-24T14:18:59.719325Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Train test split \n",
    "\n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','cargo_volume_L']]\n",
    "y = X.pop('log_price')\n",
    "\n",
    "X.columns\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf8e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:19:00.264988Z",
     "start_time": "2022-02-24T14:19:00.257151Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a pipeline to binarize labels and impute missing values with an appropriate method \n",
    "\n",
    "logmileage_pipe = make_pipeline(\n",
    "    FeatureExtractor('log_mileage'),\n",
    "    Imputer(strategy='mean'),\n",
    "    StandardScaler()\n",
    ")\n",
    "year_pipe = make_pipeline(\n",
    "    FeatureExtractor('year'),\n",
    "    Imputer(strategy='mean'),\n",
    "    StandardScaler()\n",
    ")\n",
    "BHP_pipe = make_pipeline(\n",
    "    FeatureExtractor('BHP'),\n",
    "    Imputer(strategy='mean'),\n",
    "    StandardScaler()\n",
    ")\n",
    "drivetrain_pipe = make_pipeline(\n",
    "    FeatureExtractor('drivertrain'),\n",
    "    Imputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', sparse=False),\n",
    "    StandardScaler()\n",
    ")\n",
    "make_pipe = make_pipeline(\n",
    "    FeatureExtractor('make'),\n",
    "    Imputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', sparse=False),\n",
    "    StandardScaler()\n",
    ")\n",
    "body_pipe = make_pipeline(\n",
    "    FeatureExtractor('body'),\n",
    "    Imputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', sparse=False),\n",
    "    StandardScaler()\n",
    ")\n",
    "transmission_pipe = make_pipeline(\n",
    "    FeatureExtractor('transmission'),\n",
    "    Imputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', sparse=False),\n",
    "    StandardScaler()\n",
    ")\n",
    "fuel_pipe = make_pipeline(\n",
    "    FeatureExtractor('fuel'),\n",
    "    Imputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', sparse=False),\n",
    "    StandardScaler()\n",
    ")\n",
    "doors_pipe = make_pipeline(\n",
    "    FeatureExtractor('doors'),\n",
    "    Imputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', sparse=False),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "fu = make_union(logmileage_pipe, year_pipe,\n",
    "                BHP_pipe, drivetrain_pipe, make_pipe, body_pipe,\n",
    "                transmission_pipe, fuel_pipe, doors_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025e856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:19:00.869193Z",
     "start_time": "2022-02-24T14:19:00.628866Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Apply transforms to the train and test data \n",
    "\n",
    "train_X = fu.fit_transform(X_train)\n",
    "test_X = fu.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f970c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:19:00.927298Z",
     "start_time": "2022-02-24T14:19:00.924528Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Not required - I was trying to troubleshoot an error \n",
    "\n",
    "# y_train = y_train.to_numpy()\n",
    "# y_test = y_test.to_numpy()\n",
    "\n",
    "# y_train=y_train.astype('float')\n",
    "# y_test=y_test.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d230a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:19:01.376545Z",
     "start_time": "2022-02-24T14:19:01.372137Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Sanity check input data shapes \n",
    "\n",
    "train_X.shape, test_X.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871dea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:19:15.760364Z",
     "start_time": "2022-02-24T14:19:01.972368Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MLPRegressor modelling \n",
    "\n",
    "clf = MLPRegressor(solver='adam',\n",
    "                    alpha=10**(0),\n",
    "                    hidden_layer_sizes=(4, 4, 4, 4),\n",
    "                    activation='relu',\n",
    "                    random_state=42,\n",
    "                    batch_size=50,\n",
    "                    max_iter=5000)\n",
    "clf.fit(train_X, y_train)\n",
    "print('Train R2',metrics.r2_score(y_train, clf.predict(train_X)))\n",
    "print('Test R2',metrics.r2_score(y_test, clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bf853",
   "metadata": {},
   "source": [
    "### Blending lesson and capstone preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f1996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:20:17.152538Z",
     "start_time": "2022-02-24T14:20:16.954048Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Dummify necessary columns \n",
    "X = dfsample[['log_price','log_mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "y = X.pop('log_price')\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=y, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "train_X = pd.DataFrame(sc.fit_transform(X_train), columns = X_train.columns)\n",
    "test_X = pd.DataFrame(sc.fit_transform(X_test), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc91b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:20:20.949845Z",
     "start_time": "2022-02-24T14:20:20.945292Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Sanity check input data shapes\n",
    "\n",
    "train_X.shape, test_X.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb972c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:20:36.896764Z",
     "start_time": "2022-02-24T14:20:21.861395Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#MLPRegressor modelling\n",
    "\n",
    "clf = MLPRegressor(solver='adam',\n",
    "                    alpha=10**(0),\n",
    "                    hidden_layer_sizes=(4, 4, 4, 4),\n",
    "                    activation='relu',\n",
    "                    random_state=42,\n",
    "                    batch_size=50,\n",
    "                    max_iter=5000)\n",
    "clf.fit(train_X, y_train)\n",
    "print('Train R2',metrics.r2_score(y_train, clf.predict(train_X)))\n",
    "print('Test R2',metrics.r2_score(y_test, clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22a01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "used_cars_env",
   "language": "python",
   "name": "used_cars_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "377.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
