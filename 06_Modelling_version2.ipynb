{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69115211",
   "metadata": {},
   "source": [
    "# Notebook Context\n",
    "\n",
    "This is 6 of 6 Jupyter Notebooks associated with the used car project.\n",
    "\n",
    "This covers further modelling using additional predictors which have been specifically obtained with a view to enhancing model performance.\n",
    "\n",
    "* `dealer_county` has been obtained and merged with the dataset as described in Notebooks 03_GeoCoding and 04_Data_Cleaning_and_EDA.\n",
    "* `cargo_volume_L` or car boot size has been obtained and merged with the dataset as described in Notebooks 02_Carsized_scrape and 04_Data_Cleaning_and_EDA.\n",
    "\n",
    "I'm going to lift the best GradientBoostingRegressor() parameters from Notebook 05_Modelling_version1 and use them to test whether or not these additional predictors enhance model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830b6570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:27:41.578208Z",
     "start_time": "2022-03-09T19:27:38.222231Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import modelling libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score \n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5 import show_prediction\n",
    "import eli5\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aeba26",
   "metadata": {},
   "source": [
    "# GradientBoostingRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41040baa",
   "metadata": {},
   "source": [
    "## Prepare the input data - 311,000 used cars with all predictors populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fab49b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:27:45.508912Z",
     "start_time": "2022-03-09T19:27:41.580281Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all (335824, 41)\n",
      "used (319631, 41)\n",
      "used_without_price_outliers (315124, 41)\n",
      "used_without_mileage_outliers (311864, 41)\n",
      "used_without_BHP_outliers (311741, 41)\n",
      "used_without_little_makes (311348, 41)\n"
     ]
    }
   ],
   "source": [
    "# Prep data, called df\n",
    "\n",
    "# Read clean used cars data, drop columns not useful in modelling and drop under populated makes\n",
    "cars_abspath = r'/Users/robertdavies/Desktop/DSI/GA_P2/LargeDatasets/02_cars_with_location_and_size.csv'\n",
    "\n",
    "df = pd.read_csv(cars_abspath)\n",
    "print('all',df.shape)\n",
    "\n",
    "# Save copy for later if needed\n",
    "refdf = df.copy()\n",
    "\n",
    "# Select used cars only\n",
    "df = df[df['used']==1]\n",
    "print('used',df.shape)\n",
    "\n",
    "# Drop outliers in log-price\n",
    "mask = np.abs((df.log_price - df.log_price.mean()) / df.log_price.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_price_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in log-mileage\n",
    "mask = np.abs((df.log_mileage - df.log_mileage.mean()) / df.log_mileage.std()) > 3\n",
    "df= df[~mask]\n",
    "print('used_without_mileage_outliers',df.shape)\n",
    "\n",
    "# Drop outliers in BHP\n",
    "mask = np.abs((df.BHP - df.BHP.mean()) / df.BHP.std()) > 6\n",
    "df= df[~mask]\n",
    "print('used_without_BHP_outliers',df.shape)\n",
    "\n",
    "# Drop under represented car makes\n",
    "carnums = df.groupby(by='make')['price'].count().sort_values().reset_index()\n",
    "carmakes = carnums[carnums.price>200].make.to_list()\n",
    "df = df[df.make.isin(carmakes)].copy()\n",
    "print('used_without_little_makes', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb016a",
   "metadata": {},
   "source": [
    "## Modelling as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2200412b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:46.670953Z",
     "start_time": "2022-03-09T19:27:45.511779Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummified df shape (311348, 55) \n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('model', GradientBoostingRegressor())]),\n",
       "             param_grid={'model__learning_rate': [0.05, 0.1],\n",
       "                         'model__max_depth': [3, 5],\n",
       "                         'model__n_estimators': [50, 100, 200],\n",
       "                         'model__n_iter_no_change': [20],\n",
       "                         'model__random_state': [1],\n",
       "                         'model__validation_fraction': [0.1]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns of interest\n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors']]\n",
    "# Pop target \n",
    "y = X.pop('price')\n",
    "\n",
    "# Dummify necessary columns\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "# Train test split\n",
    "X_traingb2, X_testgb2, y_traingb2, y_testgb2 = train_test_split(X,y,test_size=0.2, shuffle=y,random_state = 2)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "pipegb2 = Pipeline(steps=[('model',model)])\n",
    "pipegb2.get_params()\n",
    "\n",
    "params = {'model__n_estimators':[50, 100, 200],\n",
    "          'model__max_depth':[3,5],\n",
    "          'model__learning_rate':[0.05, 0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb2 = GridSearchCV(pipegb2, params, cv=5, verbose=1)\n",
    "gridsearchgb2.fit(X_traingb2, y_traingb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422e7ff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:50:41.243654Z",
     "start_time": "2022-03-09T20:50:34.693445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**GRADIENT BOOSTING REGRESSION AS ORIGINAL**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 5539525.602949724\n",
      "MSE test: 6074025.654177332\n",
      "RMSE train: 2353.6196810338165\n",
      "RMSE test: 2464.5538448525185\n",
      "R2 train on price: 0.9584105341491927\n",
      "R2 test on price: 0.954770512855652\n",
      "\n",
      "\n",
      "Pipeline(steps=[('model',\n",
      "                 GradientBoostingRegressor(max_depth=5, n_estimators=200,\n",
      "                                           n_iter_no_change=20,\n",
      "                                           random_state=1))])\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor() Model evaluation scores\n",
    "gbtrain_preds2 = gridsearchgb2.predict(X_traingb2)\n",
    "gbtest_preds2 = gridsearchgb2.predict(X_testgb2)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION AS ORIGINAL**')\n",
    "print('MSE train:',mean_squared_error(y_traingb2, gbtrain_preds2))\n",
    "print('MSE test:',mean_squared_error(y_testgb2, gbtest_preds2))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb2, gbtrain_preds2))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb2, gbtest_preds2))))\n",
    "print('R2 train on price:',gridsearchgb2.score(X_traingb2, y_traingb2))\n",
    "print('R2 test on price:',gridsearchgb2.score(X_testgb2, y_testgb2))\n",
    "print('\\n')\n",
    "print(gridsearchgb2.best_estimator_)\n",
    "\n",
    "# Save for later comparison\n",
    "gbdict2 = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb2, gbtrain_preds2),\n",
    "          'MSE Test': mean_squared_error(y_testgb2, gbtest_preds2), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb2, gbtrain_preds2)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb2, gbtest_preds2)),\n",
    "          'R2 Train': gridsearchgb2.score(X_traingb2, y_traingb2),\n",
    "          'R2 Test': gridsearchgb2.score(X_testgb2, y_testgb2),\n",
    "          'Params': gridsearchgb2.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3ec89",
   "metadata": {},
   "source": [
    "## Modelling with dealer_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517b3c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.684254Z",
     "start_time": "2022-03-09T20:46:51.684239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select columns of interest - county included this time.\n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','county']]\n",
    "# Pop target\n",
    "y = X.pop('price')\n",
    "# Dummify necessary columns\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors','county']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "X_traingb_county, X_testgb_county, y_traingb_county, y_testgb_county = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=2)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "params = {'model__n_estimators':[50, 100, 200],\n",
    "          'model__max_depth':[3,5],\n",
    "          'model__learning_rate':[0.05, 0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb_county = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb_county.fit(X_traingb_county, y_traingb_county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fb658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.686584Z",
     "start_time": "2022-03-09T20:46:51.686562Z"
    }
   },
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor() Model evaluation scores\n",
    "gbtrain_preds_county = gridsearchgb_county.predict(X_traingb_county)\n",
    "gbtest_preds_county = gridsearchgb_county.predict(X_testgb_county)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH COUNTY**')\n",
    "print('MSE train:',mean_squared_error(y_traingb_county, gbtrain_preds_county))\n",
    "print('MSE test:',mean_squared_error(y_testgb_county, gbtest_preds_county))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb_county, gbtrain_preds_county))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb_county, gbtest_preds_county))))\n",
    "print('R2 train on price:',gridsearchgb_county.score(X_traingb_county, y_traingb_county))\n",
    "print('R2 test on price:',gridsearchgb_county.score(X_testgb_county, y_testgb_county))\n",
    "print('\\n')\n",
    "print(gridsearchgb_county.best_estimator_)\n",
    "\n",
    "# Save for later comparison\n",
    "gbdict_county = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb_county, gbtrain_preds_county),\n",
    "          'MSE Test': mean_squared_error(y_testgb_county, gbtest_preds_county), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb_county, gbtrain_preds_county)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb_county, gbtest_preds_county)),\n",
    "          'R2 Train': gridsearchgb_county.score(X_traingb_county, y_traingb_county),\n",
    "          'R2 Test': gridsearchgb_county.score(X_testgb_county, y_testgb_county),\n",
    "          'Params': gridsearchgb_county.best_estimator_\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6528902",
   "metadata": {},
   "source": [
    "That's a little disappointing. Adding `dealer_county` didn't really improve the model performance. That too such a long time to prepare!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36550ad9",
   "metadata": {},
   "source": [
    "## Modelling with cargo_volume_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cf6fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.690091Z",
     "start_time": "2022-03-09T20:46:51.690048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select columns of interest - cargo_volume_L included this time.\n",
    "X = df[['price','mileage','year','BHP','drivertrain',\n",
    "        'make','body','transmission','fuel','doors','cargo_volume_L']]\n",
    "# Pop target\n",
    "y = X.pop('price')\n",
    "\n",
    "# Dummify necessary columns\n",
    "to_dummy=['drivertrain','make','body','transmission','fuel','doors']\n",
    "X= pd.get_dummies(X, columns = to_dummy, drop_first=True)\n",
    "print('Dummified df shape',X.shape,'\\n')\n",
    "\n",
    "X_traingb_boot, X_testgb_boot, y_traingb_boot, y_testgb_boot = train_test_split(X,y,test_size=0.2, shuffle=y,random_state=2)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "pipegb = Pipeline(steps=[('model',model)])\n",
    "pipegb.get_params()\n",
    "\n",
    "params = {'model__n_estimators':[50, 100, 200],\n",
    "          'model__max_depth':[3,5],\n",
    "          'model__learning_rate':[0.05, 0.1],\n",
    "          'model__random_state':[1],\n",
    "          'model__validation_fraction':[0.1],\n",
    "          'model__n_iter_no_change':[20]}\n",
    "\n",
    "gridsearchgb_boot = GridSearchCV(pipegb, params, cv=5, verbose=1)\n",
    "gridsearchgb_boot.fit(X_traingb_boot, y_traingb_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f6168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.697292Z",
     "start_time": "2022-03-09T20:46:51.697251Z"
    }
   },
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor() Model evaluation score\n",
    "gbtrain_preds_boot = gridsearchgb_boot.predict(X_traingb_boot)\n",
    "gbtest_preds_boot = gridsearchgb_boot.predict(X_testgb_boot)\n",
    "printmd('**GRADIENT BOOSTING REGRESSION WITH CARGO VOLUME**')\n",
    "print('MSE train:',mean_squared_error(y_traingb_boot, gbtrain_preds_boot))\n",
    "print('MSE test:',mean_squared_error(y_testgb_boot, gbtest_preds_boot))\n",
    "print('RMSE train:',np.sqrt((mean_squared_error(y_traingb_boot, gbtrain_preds_boot))))\n",
    "print('RMSE test:',np.sqrt((mean_squared_error(y_testgb_boot, gbtest_preds_boot))))\n",
    "print('R2 train on price:',gridsearchgb_boot.score(X_traingb_boot, y_traingb_boot))\n",
    "print('R2 test on price:',gridsearchgb_boot.score(X_testgb_boot, y_testgb_boot))\n",
    "print('\\n')\n",
    "print(gridsearchgb_boot.best_estimator_)\n",
    "\n",
    "# Save for later comparison\n",
    "gbdict_boot = {'Model': 'GradientBoostingRegressor', \n",
    "          'MSE Train': mean_squared_error(y_traingb_boot, gbtrain_preds_boot),\n",
    "          'MSE Test': mean_squared_error(y_testgb_boot, gbtest_preds_boot), \n",
    "          'RMSE Train': np.sqrt(mean_squared_error(y_traingb_boot, gbtrain_preds_boot)),\n",
    "          'RMSE Test': np.sqrt(mean_squared_error(y_testgb_boot, gbtest_preds_boot)),\n",
    "          'R2 Train': gridsearchgb_boot.score(X_traingb_boot, y_traingb_boot),\n",
    "          'R2 Test': gridsearchgb_boot.score(X_testgb_boot, y_testgb_boot),\n",
    "          'Params': gridsearchgb_boot.best_estimator_\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb54f0",
   "metadata": {},
   "source": [
    "That's much more encouraging. Adding `cargo_volume_L` has improved all model scoring metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e2f57",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fcc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.700246Z",
     "start_time": "2022-03-09T20:46:51.700202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summary dataframe of results \n",
    "gbdict2['Input data'] = 'Continuous plus dummies'\n",
    "gbdict_cont['Input data'] = 'Continuous only'\n",
    "gbdict_ll['Input data'] = 'Continuous plus dummies plus lat/lon'\n",
    "gbdict_county['Input data'] = 'Continuous plus dummies plus county'\n",
    "gbdict_boot['Input data'] = 'Continuous plus dummies plus boot volume'\n",
    "\n",
    "pd.DataFrame([gbdict_cont,gbdict2,gbdict_ll,gbdict_county,gbdict_boot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbe560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.702870Z",
     "start_time": "2022-03-09T20:46:51.702823Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_resid_cont = y_testgb_cont - gbtest_preds_cont\n",
    "gb_resid2 = y_testgb2 - gbtest_preds2\n",
    "gb_resid_ll = y_testgb_ll - gbtest_preds_ll\n",
    "gb_resid_county = y_testgb_county - gbtest_preds_county\n",
    "gb_resid_boot = y_testgb_boot - gbtest_preds_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20c4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T20:46:51.706079Z",
     "start_time": "2022-03-09T20:46:51.706033Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Ambitious Residuals plot - needs work on X-axis\n",
    "\n",
    "gb_resid2 = y_testgb2 - gbtest_preds2\n",
    "gb_resid_county = y_testgb_county - gbtest_preds_county\n",
    "gb_resid_boot = y_testgb_boot - gbtest_preds_boot\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Make the input data - really clumsy.\n",
    "gb_resid_df2 = pd.DataFrame(gb_resid2)\n",
    "gb_resid_df2['model']='Original Predictors:   R2 = 0.954'\n",
    "gb_resid_county_df = pd.DataFrame(gb_resid_county)\n",
    "gb_resid_county_df['model']='Original Predictors + County:    R2 = 0.956'\n",
    "gb_resid_boot_df = pd.DataFrame(gb_resid_boot)\n",
    "gb_resid_boot_df['model']='Original Predictors + Boot Size:    R2 = 0.968'\n",
    "\n",
    "tocat=[gb_resid_df2,gb_resid_county_df,gb_resid_boot_df,]\n",
    "residplotdf = pd.concat(tocat)\n",
    "residplotdf.columns = ['Residual Price (£)', 'model']\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(10, rot=-.1, light=.5)\n",
    "g = sns.FacetGrid(residplotdf, row=\"model\", hue=\"model\", aspect=15, height=1.5, palette=pal)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Residual Price (£)\",\n",
    "      bw_adjust=.5, clip_on=True,\n",
    "      fill=True, alpha=1, linewidth=1)\n",
    "g.map(sns.kdeplot, \"Residual Price (£)\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "g.map(label, \"Residual Price (£)\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.25)\n",
    "#setting xticks\n",
    "\n",
    "ticks = [-10000, 0, 10000]\n",
    "labels = [i for i in ticks]\n",
    "g.set(xticks = ticks, xticklabels = labels)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "plt.title('Summary plot of tested models with R2 and residual distribution',x=0.14, y=2.45, fontsize=14)\n",
    "g.despine(bottom=True, left=True)\n",
    "plt.savefig('furthermodelsummary.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99152657",
   "metadata": {},
   "source": [
    "There are two very simple conclusions to make:\n",
    "\n",
    "* Adding `dealer_county` information did not improve model performance.\n",
    "* Adding `cargo_volume_L` information did improve model performance, with R<sup>2</sup> scores increasing from 0.954 to 0.968. \n",
    "\n",
    "This work took a very long time to complete and it was a little disappointing to find that the `dealer_county` doesn't measurably impact used car price. There was better news on the `cargo_volume_L` front though. Being able to increase model performance by 2% may seem small but that may be a highly profitable 2% in some circumstances - it's a shame I wasn't being paid for this! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc4ec7",
   "metadata": {},
   "source": [
    "This 2% increase in model R<sup>2</sup> score concludes Notebook 06_Modelling_version2. I'm now going to write all of these findings in a detailed README.md file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "377.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
